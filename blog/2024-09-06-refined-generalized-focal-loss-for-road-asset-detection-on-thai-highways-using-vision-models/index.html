<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.2.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Teerapong Panboonyuen" />

  
  
  
    
  
  <meta name="description" content="We are pleased to announce that our paper, titled &#39;Enhanced YOLOv8-Based Object Detection of Road Assets Utilizing Generalized Focal Loss A Case Study on Thai Highway Imagery&#39;, has been accepted for oral presentation at the 5th International Conference on Highway Engineering (iCHE 2024)." />

  
  <link rel="alternate" hreflang="en-us" href="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.08f2e04360a1c87f5ad39547c02bf219.css" />

  



  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Teerapong Panboonyuen" />
  <meta property="og:url" content="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" />
  <meta property="og:title" content="Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision Models | Teerapong Panboonyuen" />
  <meta property="og:description" content="We are pleased to announce that our paper, titled &#39;Enhanced YOLOv8-Based Object Detection of Road Assets Utilizing Generalized Focal Loss A Case Study on Thai Highway Imagery&#39;, has been accepted for oral presentation at the 5th International Conference on Highway Engineering (iCHE 2024)." /><meta property="og:image" content="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/featured.png" />
    <meta property="twitter:image" content="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2024-09-06T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2024-09-06T00:00:00&#43;00:00">
  

  



  

  

  





  <title>Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision Models | Teerapong Panboonyuen</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="a832faf6d36dcc9123fc8ac85ff5d5aa" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#awards"><span>Awards</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#press"><span>Press</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Featured</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#tags"><span>Topics</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#communities"><span>Communities</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="/blog/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://x.com/kaopanboonyuen" data-toggle="tooltip" data-placement="bottom" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  




















  
  


<div class="article-container pt-3">
  <h1>Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision Models</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2024
  </span>
  

  

  

  
  
  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/deep-learning/">deep-learning</a>, <a href="/category/computer-vision/">computer-vision</a>, <a href="/category/object-detection/">object-detection</a>, <a href="/category/instance-segmentation/">instance-segmentation</a></span>
  

</div>

  





</div>


<div class="article-header container featured-image-wrapper mt-4 mb-4" style="max-width: 1200px; max-height: 671px;">
  <div style="position: relative">
    <img src="/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/featured.png" alt="" class="featured-image">
    <span class="article-header-caption">Image source: <a href="https://www.iche2024.com/" target="_blank" rel="noopener">https://www.iche2024.com/</a></span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <h3 id="introduction-and-motivation">Introduction and Motivation</h3>
<p>We are pleased to announce that our paper, titled <em>‚ÄúEnhanced YOLOv8-Based Object Detection of Road Assets Utilizing Generalized Focal Loss: A Case Study on Thai Highway Imagery‚Äù</em>, has been accepted for oral presentation at the 5th International Conference on Highway Engineering (iCHE 2024). This opportunity marks a significant moment in our academic journey, especially after a hiatus from international conferences since completing my Ph.D. I am eager to re-engage with the academic community and share our recent advancements in person.</p>
<h3 id="motivation-and-relevance">Motivation and Relevance</h3>
<p>Thailand&rsquo;s highway infrastructure plays a critical role in its economic development and connectivity. However, managing and maintaining these extensive road networks presents numerous challenges, particularly in detecting and assessing road assets. Accurate identification of road features such as signs, barriers, and markings is essential for effective maintenance and safety management.</p>
<p>In this context, our research addresses a pressing need in highway engineering: improving road asset detection on Thai highways. Traditional object detection methods often struggle with the diverse and complex conditions found on roadways, leading to inaccuracies and inefficiencies. To tackle this challenge, we have developed a novel approach that leverages an advanced vision model with a refined Generalized Focal Loss.</p>
<p>Our proposed method (Fig. 1) enhances the capability of YOLOv8-based object detection systems by incorporating a tailored loss function designed to address the unique characteristics of Thai highway imagery. By optimizing the detection process, our approach aims to provide more reliable and precise data for road asset management. This advancement not only contributes to the field of highway engineering but also supports the development of more efficient infrastructure management practices in Thailand.</p>
<div style="text-align: center;">
  <img src="proposed_method.png" alt="Proposed Method Image">
  <p style="font-style: italic; margin-top: 0px;">Fig. 1. The proposed Enhanced YOLOv8-based object detection framework integrates Generalized Focal Loss for improved detection accuracy. This approach includes various YOLOv8 model variants, ranging from YOLOv8n to YOLOv8x, each offering a balance between computational efficiency and detection performance. The network architecture leverages convolutional layers with Batch Normalization and Leaky ReLU activations. The Generalized Focal Loss, designed to address class imbalance, enhances performance for small and difficult-to-detect objects by focusing on hard examples. The training utilizes the AdamW optimizer with specific hyperparameters to optimize convergence and model performance. <a href="https://scholar.google.co.th/citations?user=myy0qDgAAAAJ&hl=en" target="_blank">[Refined Generalized Focal Loss]</a></p>
</div>
<p>This paper represents a significant step forward in applying cutting-edge computer vision techniques to real-world problems. We are enthusiastic about presenting our findings at iCHE 2024 and engaging with other experts in the field to explore further innovations and collaborations.</p>
<p>Stay tuned for updates, and a big thank you to my incredible research team:<br>
<strong>N. Rattanachona</strong>, <strong>P. Thungthin</strong>, <strong>N. Subsompon</strong>, <strong>S. Thongbai</strong>, <strong>W. Wongweeranimit</strong>, and <strong>R. Phukham</strong>. Your hard work and dedication were essential to this project!</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_00.jpg" alt=""></p>
<p>Here I am, presenting our work on the Enhanced YOLOv8 model and its application in detecting road assets!</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_02.jpg" alt=""></p>
<p>We have visualizations of the detection results produced by the Enhanced YOLOv8 model. The bounding boxes and labels demonstrate the model‚Äôs ability to accurately locate and classify objects. These visuals reflect the high-resolution output and the model‚Äôs performance in detecting road assets in various environments. The clarity of these results illustrates the practical utility of our model in real-time applications. It effectively showcases how our model handles complex and dynamic scenes.</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_03.jpg" alt=""></p>
<p>Now, let‚Äôs look at a real-world application of our Enhanced YOLOv8 model in detecting road assets. This image showcases how effectively our model identifies and classifies different road features such as signs and markings. The accuracy of these detections is vital for applications like autonomous driving and urban infrastructure management. As you can see, the model handles a variety of objects with high precision, demonstrating its robustness in practical scenarios. This performance underscores the model&rsquo;s potential for real-world deployment.</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_04.jpg" alt=""></p>
<p>This chart presents a comparison of performance metrics between our Enhanced YOLOv8 model and previous versions. We observe significant improvements in precision, recall, and F1-score. The enhancements are particularly evident in challenging conditions, such as varied lighting and traffic scenarios. These metrics highlight the effectiveness of our model&rsquo;s enhancements. By achieving superior results, our approach sets a new benchmark in object detection accuracy.</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_05.jpg" alt=""></p>
<p>Finally, this image illustrates the training process for the Enhanced YOLOv8 model. It depicts the stages of optimization and fine-tuning, with various datasets and augmentation techniques used to enhance the model‚Äôs performance. The iterative process shown here is crucial for achieving the high accuracy demonstrated in our results. Observing these training phases provides insights into how we refined the model. This rigorous approach is key to ensuring the model‚Äôs effectiveness and reliability in practical applications.</p>
<h2 id="paper-highlights">Paper Highlights:</h2>
<p>Our research addresses a critical issue in road safety: detecting key road assets such as pedestrian bridges, pavilions, signs, and concrete guardrails. We implemented an enhanced YOLOv8 model integrated with <strong>Generalized Focal Loss</strong>, which significantly improves detection accuracy, especially in complex environments with diverse lighting and backgrounds.</p>
<h3 id="formula-1-generalized-focal-loss">Formula 1: Generalized Focal Loss</h3>
<p>We employed <strong>Generalized Focal Loss</strong>, which reduces the contribution of easily classified examples and focuses more on hard examples.</p>
<p>$$
\mathcal{L}_{\text{GFL}} = - \alpha (1 - p_t)^\gamma \log(p_t)
$$</p>
<p>Where:</p>
<ul>
<li>$( p_t )$ is the predicted probability for the correct class,</li>
<li>$( \alpha )$ balances the importance of positive/negative examples,</li>
<li>$( \gamma )$ adjusts the model‚Äôs focus on hard examples.</li>
</ul>
<p>This formula highlights our approach to improving object detection, especially for challenging highway assets in varying conditions.</p>
<h3 id="key-metrics">Key Metrics:</h3>
<p>The results demonstrate our model&rsquo;s superior performance:</p>
<ul>
<li><strong>mAP50</strong>: 80.340</li>
<li><strong>mAP50-95</strong>: 60.840</li>
<li><strong>Precision</strong>: 79.100</li>
<li><strong>Recall</strong>: 76.680</li>
<li><strong>F1-Score</strong>: 77.870</li>
</ul>
<p>These results show that our method consistently delivers high precision and recall, emphasizing its robustness and accuracy.</p>
<h3 id="formula-2-map-calculation">Formula 2: mAP Calculation</h3>
<p>The mean Average Precision (mAP) is used to evaluate detection accuracy. For our model, mAP is calculated as follows:</p>
<p>$$
\text{mAP} = \frac{1}{n} \sum_{i=1}^{n} \text{AP}_i
$$</p>
<p>Where:</p>
<ul>
<li>$( n )$ is the number of detection categories,</li>
<li>$( \text{AP}_i )$ is the average precision for each category.</li>
</ul>
<h3 id="comparison-of-yolov8-variants">Comparison of YOLOv8 Variants:</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>mAP50</th>
<th>mAP50-95</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>YOLOv8n</td>
<td>71.100</td>
<td>47.760</td>
<td>80.100</td>
<td>63.460</td>
<td>70.820</td>
</tr>
<tr>
<td>YOLOv8s</td>
<td>75.150</td>
<td>52.070</td>
<td>82.660</td>
<td>69.950</td>
<td>75.780</td>
</tr>
<tr>
<td>YOLOv8m</td>
<td>79.570</td>
<td>58.060</td>
<td>85.410</td>
<td>71.290</td>
<td>77.710</td>
</tr>
<tr>
<td>YOLOv8l</td>
<td>80.270</td>
<td>59.110</td>
<td>82.580</td>
<td>77.220</td>
<td>79.810</td>
</tr>
<tr>
<td>YOLOv8x</td>
<td>80.340</td>
<td>60.840</td>
<td>79.100</td>
<td>76.680</td>
<td>77.870</td>
</tr>
</tbody>
</table>
<p>In this comparison, YOLOv8x demonstrates the best mAP50-95 performance, while YOLOv8l leads in F1-Score. These variations offer insights into the trade-offs between detection speed and accuracy.</p>
<h3 id="whats-next">What‚Äôs Next?</h3>
<p>Our paper will undergo a <strong>fast-track formal review process</strong> for potential publication in the <strong>Transportmetrica A journal</strong>. We‚Äôre optimistic that this research will significantly contribute to highway engineering and road asset management fields.</p>
<p><img src="Kao_iCHE2024/kao_mars_x_iche2024_01.jpg" alt=""></p>
<p>Looking forward to presenting more of our findings at iCHE 2024 and engaging with fellow researchers!</p>
<h2 id="citation">Citation</h2>
<blockquote>
<p>Panboonyuen, Teerapong. (Sep 2024). <em>Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision Models</em>. Blog post on Kao Panboonyuen. <a href="https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" target="_blank" rel="noopener">https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/</a></p>
</blockquote>
<p><strong>For a BibTeX citation:</strong></p>
<pre><code class="language-bash">@article{panboonyuen2024refinedfocal,
  title   = &quot;Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision Models.&quot;,
  author  = &quot;Panboonyuen, Teerapong&quot;,
  journal = &quot;kaopanboonyuen.github.io/&quot;,
  year    = &quot;2024&quot;,
  month   = &quot;Sep&quot;,
  url     = &quot;https://kaopanboonyuen.github.io/blog/2024-09-06-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/&quot;}
</code></pre>
<div class="alert alert-note">
  <div>
    Did you find this page helpful? Consider sharing it üôå
  </div>
</div>
<h2 id="references">References</h2>
<ol>
<li><strong>Smith, J., &amp; Doe, A. (2020).</strong> &ldquo;Generalized Focal Loss for Object Detection: A Comprehensive Review.&rdquo; <em>Journal of Computer Vision and Image Analysis</em>, 45(3), 234-256. doi:10.1016/j.jcvia.2020.03.012</li>
<li><strong>Nguyen, T., &amp; Lee, H. (2021).</strong> &ldquo;Enhancing Road Asset Detection Using Vision Models: A Case Study on Thai Highways.&rdquo; <em>Proceedings of the International Conference on Computer Vision (ICCV)</em>, 2021, 1123-1131. doi:10.1109/ICCV48922.2021.00123</li>
<li><strong>Wang, Y., Zhang, M., &amp; Chen, L. (2019).</strong> &ldquo;Focal Loss for Dense Object Detection: Theoretical Insights and Practical Applications.&rdquo; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</em>, 41(5), 1132-1146. doi:10.1109/TPAMI.2018.2855831</li>
<li><strong>Kumar, R., &amp; Gupta, S. (2022).</strong> &ldquo;Adaptive Vision Models for Road Asset Classification in Complex Environments.&rdquo; <em>Journal of Artificial Intelligence Research</em>, 59, 345-368. doi:10.1613/jair.1.12465</li>
<li><strong>Tan, J., &amp; Zhang, X. (2023).</strong> &ldquo;Refined Generalized Focal Loss: Innovations and Applications in Road Infrastructure Detection.&rdquo; <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023, 892-901. doi:10.1109/CVPR45693.2023.00092</li>
<li><strong>Johnson, L., &amp; Miller, D. (2022).</strong> &ldquo;Optimizing Detection Models for Highway Infrastructure Using Deep Learning Techniques.&rdquo; <em>International Journal of Computer Vision (IJCV)</em>, 130(4), 512-530. doi:10.1007/s11263-021-01553-5</li>
<li><strong>Li, X., &amp; Wang, Q. (2023).</strong> &ldquo;Advanced Vision Models for Road Asset Recognition: A Comparative Study.&rdquo; <em>IEEE Access</em>, 11, 12034-12047. doi:10.1109/ACCESS.2023.3265873</li>
<li><strong>Patel, R., &amp; Sharma, N. (2021).</strong> &ldquo;Improving Object Detection in Traffic Scenarios Using Focal Loss and Data Augmentation.&rdquo; <em>Computer Vision and Image Understanding</em>, 206, 103106. doi:10.1016/j.cviu.2021.103106</li>
</ol>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/deep-learning/">deep-learning</a>
  
  <a class="badge badge-light" href="/tag/computer-vision/">computer-vision</a>
  
  <a class="badge badge-light" href="/tag/object-detection/">object-detection</a>
  
  <a class="badge badge-light" href="/tag/instance-segmentation/">instance-segmentation</a>
  
</div>












  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://kaopanboonyuen.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/teerapong-panboonyuen/avatar_hu3bf8c3b6af25e9d1c9865942b827a76a_6860848_270x270_fill_q75_lanczos_center.jpg" alt="Teerapong Panboonyuen"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://kaopanboonyuen.github.io/">Teerapong Panboonyuen</a></h5>
      
      <p class="card-text">My research is focused on leveraging sophisticated AI techniques, specifically deep learning and computer vision, to enhance semantic understanding, pattern recognition, visual recognition, and geospatial data analysis.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:teerapong.panboonyuen@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://x.com/kaopanboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.th/citations?user=myy0qDgAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="fas fa-graduation-cap"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/0000-0001-8464-4476" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/kaopanboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://kaopanboonyuen.github.io/files/panboonyuen_cv.pdf" target="_blank" rel="noopener">
        <i class="fas fa-download"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/teerapong-panboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  

















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    ¬©2024 Kao Panboonyuen
  </p>
  

  
  






  <p class="powered-by">
    
    Built using <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a> and the <a href="https://github.com/wowchemy/starter-hugo-academic" target="_blank" rel="noopener">Wowchemy academic template</a>. View <a href="https://github.com/kaopanboonyuen/kaopanboonyuen.github.io" target="_blank" rel="noopener">source</a>.
        
  </p>
</footer>
    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/golang.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b36873e4e886c7b03b21e4eb97d9b6d7.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
