<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.2.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Teerapong Panboonyuen" />

  
  
  
    
  
  <meta name="description" content="" />

  
  <link rel="alternate" hreflang="en-us" href="https://kaopanboonyuen.github.io/publication-type/1/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.08f2e04360a1c87f5ad39547c02bf219.css" />

  



  

  

  




  
  
  

  
    <link rel="alternate" href="/publication-type/1/index.xml" type="application/rss+xml" title="Teerapong Panboonyuen" />
  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://kaopanboonyuen.github.io/publication-type/1/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Teerapong Panboonyuen" />
  <meta property="og:url" content="https://kaopanboonyuen.github.io/publication-type/1/" />
  <meta property="og:title" content="1 | Teerapong Panboonyuen" />
  <meta property="og:description" content="" /><meta property="og:image" content="https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2024-09-09T00:00:00&#43;00:00" />
    
  

  



  

  





  <title>1 | Teerapong Panboonyuen</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#awards"><span>Awards</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#press"><span>Press</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Featured</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#tags"><span>Topics</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#communities"><span>Communities</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/blog/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://x.com/kaopanboonyuen" data-toggle="tooltip" data-placement="bottom" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    












  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>1</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/sea-vit-sea-surface-currents-forecasting/" >SEA-ViT: Sea Surface Currents Forecasting Using Vision Transformer and GRU-Based Spatio-Temporal Covariance Modeling</a>
      </div>

      
      <a href="/publication/sea-vit-sea-surface-currents-forecasting/"  class="summary-link">
        <div class="article-style">
          Forecasting sea surface currents is essential for applications such as maritime navigation, environmental monitoring, and climate analysis, particularly in regions like the Gulf of Thailand and the Andaman Sea. This paper introduces SEA-ViT, an advanced deep learning model that integrates Vision Transformer (ViT) with bidirectional Gated Recurrent Units (GRUs) to capture spatio-temporal covariance for predicting sea surface currents (U, V) using high-frequency radar (HF) data. The name SEA-ViT is derived from Sea Surface Currents Forecasting using Vision Transformer, highlighting the model&rsquo;s emphasis on ocean dynamics and its use of the ViT architecture to enhance forecasting capabilities. SEA-ViT is designed to unravel complex dependencies by leveraging a rich dataset spanning over 30 years and incorporating ENSO indices (El Niño, La Niña, and neutral phases) to address the intricate relationship between geographic coordinates and climatic variations. This development enhances the predictive capabilities for sea surface currents, supporting the efforts of the Geo-Informatics and Space Technology Development Agency (GISTDA) in Thailand&rsquo;s maritime regions. The code and pretrained models are available at <a href="https://github.com/kaopanboonyuen/gistda-ai-sea-surface-currents" target="_blank" rel="noopener">https://github.com/kaopanboonyuen/gistda-ai-sea-surface-currents</a>.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In 17th International Conference on Knowledge and Smart Technology (KST2025)
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/11003320" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/sea-vit-sea-surface-currents-forecasting/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen/gistda-ai-sea-surface-currents" target="_blank" rel="noopener">
  Code
</a>




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/gistda-ai-sea-surface-currents/" target="_blank" rel="noopener">
  Project
</a>










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2409.16313" target="_blank" rel="noopener">
    
    ArXiv
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/files/certificate/KST2025/Panboonyuen-Certificate-of-Contributions-56.pdf" target="_blank" rel="noopener">
    
    Certificate
  </a>

      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/sea-vit-sea-surface-currents-forecasting/" >
        <img src="/publication/sea-vit-sea-surface-currents-forecasting/compact_hu6dfea2a8864ffe6d781e9905895c9bc9_1453080_300x0_resize_lanczos_3.png" alt="SEA-ViT: Sea Surface Currents Forecasting Using Vision Transformer and GRU-Based Spatio-Temporal Covariance Modeling" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-based-detection-and-segmentation-models/" >REG: Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision-Based Detection and Segmentation Models</a>
      </div>

      
      <a href="/publication/refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-based-detection-and-segmentation-models/"  class="summary-link">
        <div class="article-style">
          This paper dives into the cutting-edge world of road asset detection on Thai highways, showcasing a novel approach that combines an upgraded REG model with Generalized Focal Loss. Our focus is on identifying key road elements—like pavilions, pedestrian bridges, information and warning signs, and concrete guardrails—to boost road safety and infrastructure management. While deep learning methods have shown promise, traditional models often struggle with accuracy in tricky conditions, such as cluttered backgrounds and variable lighting. To tackle these issues, we&rsquo;ve integrated REG with Generalized Focal Loss, enhancing its ability to detect road assets with greater precision. Our results are impressive, the REGx model led the way with a mAP50 of 80.340, mAP50-95 of 60.840, precision of 79.100, recall of 76.680, and an F1-score of 77.870. These findings highlight the REGx model’s superior performance, demonstrating the power of advanced deep learning techniques to improve highway safety and infrastructure maintenance, even in challenging conditions.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>, <span >N. Rattanachona</span>, <span >P. Thungthin</span>, <span >N. Subsompon</span>, <span >S. Thongbai</span>, <span >W. Wongweeranimit</span>, <span >R. Phukham</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>5th International Conference on Highway Engineering</em> <strong>ICHE 2024</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/11003314" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-based-detection-and-segmentation-models/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen/REG" target="_blank" rel="noopener">
  Code
</a>




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/REG/" target="_blank" rel="noopener">
  Project
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/REG/" target="_blank" rel="noopener">
  Poster
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/files/slides/20240906_Panboonyuen_AI_ThaiHighway.pdf" target="_blank" rel="noopener">
  Slides
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/blog/2024-09-07-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" target="_blank" rel="noopener">
  Source Document
</a>



  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/blog/2024-09-07-refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-models/" target="_blank" rel="noopener">
    
    Blog
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.arxiv.org/abs/2409.09877" target="_blank" rel="noopener">
    
    ArXiv
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/files/certificate/KST2025/Panboonyuen-Certificate-of-Contributions-57.pdf" target="_blank" rel="noopener">
    
    Certificate
  </a>

      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-based-detection-and-segmentation-models/" >
        <img src="/publication/refined-generalized-focal-loss-for-road-asset-detection-on-thai-highways-using-vision-based-detection-and-segmentation-models/compact_hu36f1f18a22f4ac4ee5bd7950f6fd263e_843865_300x0_resize_lanczos_3.png" alt="REG: Refined Generalized Focal Loss for Road Asset Detection on Thai Highways Using Vision-Based Detection and Segmentation Models" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/mars-mask-attention-refinement-with-sequential-quadtree-nodes/" >MARS: Mask Attention Refinement with Sequential Quadtree Nodes for Car Damage Instance Segmentation</a>
      </div>

      
      <a href="/publication/mars-mask-attention-refinement-with-sequential-quadtree-nodes/"  class="summary-link">
        <div class="article-style">
          Evaluating car damages is crucial for the car insurance industry, but current deep learning networks fall short in accuracy due to inadequacies in handling car damage images and producing fine segmentation masks. This paper introduces MARS (Mask Attention Refinement with Sequential quadtree nodes) for instance segmentation of car damages. MARS employs self-attention mechanisms to capture global dependencies within sequential quadtree nodes and a quadtree transformer to recalibrate channel weights, resulting in highly accurate instance masks. Extensive experiments show that MARS significantly outperforms state-of-the-art methods like Mask R-CNN, PointRend, and Mask Transfiner on three popular benchmarks, achieving a +1.3 maskAP improvement with the R50-FPN backbone and +2.3 maskAP with the R101-FPN backbone on the Thai car-damage dataset. Demos are available at <a href="https://github.com/kaopanboonyuen/MARS" target="_blank" rel="noopener">https://github.com/kaopanboonyuen/MARS</a>.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>, <span >N. Nithisopa</span>, <span >P. Pienroj</span>, <span >L. Jirachuphun</span>, <span >C. Watthanasirikrit</span>, <span >N. Pornwiriyakul</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>Image Analysis and Processing</em> <strong>ICIAP 2023</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-031-51023-6_3" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/mars-mask-attention-refinement-with-sequential-quadtree-nodes/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen/MARS" target="_blank" rel="noopener">
  Code
</a>




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/MARS" target="_blank" rel="noopener">
  Project
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/files/MARS/panboonyuen_MARS_ICIAP2023_Poster.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://kaopanboonyuen.github.io/files/MARS/panboonyuen_MARS_ICIAP2023_Poster.pdf" target="_blank" rel="noopener">
    
    ICIAP Poster
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://dl.acm.org/doi/10.1007/978-3-031-51023-6_3" target="_blank" rel="noopener">
    
    ACM
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2305.04743" target="_blank" rel="noopener">
    
    ArXiv
  </a>

      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/mars-mask-attention-refinement-with-sequential-quadtree-nodes/" >
        <img src="/publication/mars-mask-attention-refinement-with-sequential-quadtree-nodes/compact_hu2872fb430e8c008b7eed1ab9972290e6_1008939_300x0_resize_lanczos_3.png" alt="MARS: Mask Attention Refinement with Sequential Quadtree Nodes for Car Damage Instance Segmentation" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/real-time-polyps-segmentation-for-colonoscopy-video-frames/" >Real-Time Polyps Segmentation for Colonoscopy Video Frames Using Compressed Fully Convolutional Network</a>
      </div>

      
      <a href="/publication/real-time-polyps-segmentation-for-colonoscopy-video-frames/"  class="summary-link">
        <div class="article-style">
          Colorectal cancer is one of the leading causes of cancer death worldwide. As of now, colonoscopy is the most effective screening tool for diagnosing colorectal cancer by searching for polyps which can develop into colon cancer. The drawback of manual colonoscopy process is its high polyp miss rate. Therefore, polyp detection is a crucial issue in the development of colonoscopy application. Despite having high evaluation scores, the recently published methods based on fully convolutional network (FCN) require a very long inferring (testing) time that cannot be applied in a real clinical process due to a large number of parameters in the network. In this paper, we proposed a compressed fully convolutional network by modifying the FCN-8s network, so our network is able to detect and segment polyp from video images within a real-time constraint in a practical screening routine. Furthermore, our customized loss function allows our network to be more robust when compared to the traditional cross-entropy loss function. The experiment was conducted on CVC-EndoSceneStill database which consists of 912 video frames from 36 patients. Our proposed framework has obtained state-of-the-art results while running more than 7 times faster and requiring fewer weight parameters by more than 9 times. The experimental results convey that our system has the potential to support clinicians during the analysis of colonoscopy video by automatically indicating the suspicious polyps locations.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >I. Wichakam</span>, <span class="author-highlighted">Teerapong Panboonyuen</span>, <span >C. Udomcharoenchaikit</span>, <span >P. Vateekul</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>International Conference on Multimedia Modeling</em> <strong>MMM 2018</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-319-73603-7_32" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/real-time-polyps-segmentation-for-colonoscopy-video-frames/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen" target="_blank" rel="noopener">
  Code
</a>













      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/real-time-polyps-segmentation-for-colonoscopy-video-frames/" >
        <img src="/publication/real-time-polyps-segmentation-for-colonoscopy-video-frames/compact_hu3df151b013ef19e8db16ff9485f84888_309033_300x0_resize_lanczos_3.png" alt="Real-Time Polyps Segmentation for Colonoscopy Video Frames Using Compressed Fully Convolutional Network" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/semantic-segmentation-on-medium-resolution-satellite-images/" >Semantic Segmentation On Medium-Resolution Satellite Images Using Deep Convolutional Networks With Remote Sensing Derived Indices</a>
      </div>

      
      <a href="/publication/semantic-segmentation-on-medium-resolution-satellite-images/"  class="summary-link">
        <div class="article-style">
          Semantic Segmentation is a fundamental task in computer vision and remote sensing imagery. Many applications, such as urban planning, change detection, and environmental monitoring, require the accurate segmentation; hence, most segmentation tasks are performed by humans. Currently, with the growth of Deep Convolutional Neural Network (DCNN), there are many works aiming to find the best network architecture fitting for this task. However, all of the studies are based on very-high resolution satellite images, and surprisingly; none of them are implemented on medium resolution satellite images. Moreover, no research has applied geoinformatics knowledge. Therefore, we purpose to compare the semantic segmentation models, which are FCN, SegNet, and GSN using medium resolution images from Landsat-8 satellite. In addition, we propose a modified SegNet model that can be used with remote sensing derived indices. The results show that the model that achieves the highest accuracy RGB bands of medium resolution aerial imagery is SegNet. The overall accuracy of the model increases when includes Near Infrared (NIR) and Short-Wave Infrared (SWIR) band. The results showed that our proposed method (our modified SegNet model, named RGB-IR-IDX-MSN method) outperforms all of the baselines in terms of mean F1 scores.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >S. Chantharaj</span>, <span >K. Pornratthanapong</span>, <span >P. Chitsinpchayakun</span>, <span class="author-highlighted">Teerapong Panboonyuen</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In *15th International Joint Conference on Computer Science and Software Engineering * <strong>JCSSE 2018</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/8457378/" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/semantic-segmentation-on-medium-resolution-satellite-images/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen/" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.isprs.org/education/benchmarks/UrbanSemLab/2d-sem-label-vaihingen.aspx" target="_blank" rel="noopener">
  Dataset
</a>












      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/semantic-segmentation-on-medium-resolution-satellite-images/" >
        <img src="/publication/semantic-segmentation-on-medium-resolution-satellite-images/compact_hua87129e6e693cceff941178b50e40d9b_837150_300x0_resize_lanczos_3.png" alt="Semantic Segmentation On Medium-Resolution Satellite Images Using Deep Convolutional Networks With Remote Sensing Derived Indices" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/road-segmentation-on-aerial-imagery/" >An enhanced deep convolutional encoder-decoder network for road segmentation on aerial imagery</a>
      </div>

      
      <a href="/publication/road-segmentation-on-aerial-imagery/"  class="summary-link">
        <div class="article-style">
          In this paper, we introduce an improved deep convolutional encoder-decoder network (DCED) for segmenting road objects from aerial images. Enhancements include the use of ELU (exponential linear unit) instead of ReLU, dataset augmentation with incrementally-rotated images to increase training data by eight times, and the use of landscape metrics to remove false road objects. Tested on the Massachusetts Roads dataset, our method outperformed the SegNet benchmark and other baselines in precision, recall, and F1 scores.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>, <span >P. Vateekul</span>, <span >S. Lawawirojwong</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>International Conference on Computing and Information Technology (IC2IT)</em> <strong>Best Student Paper Honourable Mention (top 0.26% of submissions)</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-319-60663-7_18" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/road-segmentation-on-aerial-imagery/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen/" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/files/panboonyuen_IC2IT2017_BestPaperAward.pdf" target="_blank" rel="noopener">
  Slides
</a>






  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/chapter/10.1007/978-3-319-60663-7_18" target="_blank" rel="noopener">
    
    IC2IT 2017 Best Paper Award
  </a>

      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/road-segmentation-on-aerial-imagery/" >
        <img src="/publication/road-segmentation-on-aerial-imagery/compact_hua498d26fbf435a648e4226cf29584fa2_591805_300x0_resize_lanczos_3.png" alt="An enhanced deep convolutional encoder-decoder network for road segmentation on aerial imagery" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  
    
      







  







  


<div class="container">
  <div class="row media stream-item">
    <div class="col col-sm-12 col-lg-8 col-md-7 ml-3 media-body">

      <div class="section-subheading article-title mb-0 mt-0">
        <a href="/publication/road-map-extraction-from-satellite-imagery/" >Road map extraction from satellite imagery using connected component analysis and landscape metrics</a>
      </div>

      
      <a href="/publication/road-map-extraction-from-satellite-imagery/"  class="summary-link">
        <div class="article-style">
          Road map extraction is vital for GIS and underpins many location-based applications like GPS navigation, delivery route planning, tourist attraction locating, and location-based marketing. This research uses satellite imagery, though other remotely sensed images like aerial photographs, UAVs, or drones are also applicable. Despite various proposed methods focusing primarily on accuracy, completeness of results is equally important. We enhance accuracy by incorporating connected component analysis and improve completeness using landscape metrics, which describe spatial characteristics through shape and isolation indices. Evaluated on precision, recall, quality, and F1 scores, our method achieves over 90% performance in all criteria.
        </div>
      </a>
      

      <div class="stream-meta article-metadata">

        

        
          


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">Teerapong Panboonyuen</span>, <span >P. Vateekul</span>, <span >S. Lawawirojwong</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>IEEE International Conference on Big Data</em> <strong>Big Data 2017</strong>
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

        
      </div>

      
      <div class="btn-links">
        








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/document/8258330" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/road-map-extraction-from-satellite-imagery/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/kaopanboonyuen" target="_blank" rel="noopener">
  Code
</a>













      </div>
      

    </div>
    <div class="col col col-sm-12 col-lg-4 col-md-5 ml-3 mb-3">
      
      
      
      <a href="/publication/road-map-extraction-from-satellite-imagery/" >
        <img src="/publication/road-map-extraction-from-satellite-imagery/compact_hu97a7f026cf9c527f7189f7bb72e86721_577453_300x0_resize_lanczos_3.png" alt="Road map extraction from satellite imagery using connected component analysis and landscape metrics" loading="lazy">
      </a>
      
    </div>
  </div>
</div>  
    
  

  

</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    ©2025 Kao Panboonyuen
  </p>
  

  
  






  <p class="powered-by">
    
    Built using <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a> and the <a href="https://github.com/wowchemy/starter-hugo-academic" target="_blank" rel="noopener">Wowchemy academic template</a>. View <a href="https://github.com/kaopanboonyuen/kaopanboonyuen.github.io" target="_blank" rel="noopener">source</a>.
        
  </p>
</footer>
    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/golang.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b36873e4e886c7b03b21e4eb97d9b6d7.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
