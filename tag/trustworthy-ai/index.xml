<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>trustworthy-ai | Teerapong Panboonyuen</title>
    <link>https://kaopanboonyuen.github.io/tag/trustworthy-ai/</link>
      <atom:link href="https://kaopanboonyuen.github.io/tag/trustworthy-ai/index.xml" rel="self" type="application/rss+xml" />
    <description>trustworthy-ai</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â©2026 Kao Panboonyuen</copyright><lastBuildDate>Thu, 29 Jan 2026 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png</url>
      <title>trustworthy-ai</title>
      <link>https://kaopanboonyuen.github.io/tag/trustworthy-ai/</link>
    </image>
    
    <item>
      <title>HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models</title>
      <link>https://kaopanboonyuen.github.io/publication/hers-hidden-pattern-expert-learning-for-risk-specific-vehicle-damage-adaptation-in-diffusion-models/</link>
      <pubDate>Thu, 29 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/publication/hers-hidden-pattern-expert-learning-for-risk-specific-vehicle-damage-adaptation-in-diffusion-models/</guid>
      <description>&lt;!-- ![](featured.png) --&gt;
&lt;p&gt;HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation) is a diffusion-based framework that addresses a critical gap in deploying generative models within safety-critical domains such as auto insurance. While modern text-to-image diffusion models produce visually realistic outputs, they often fail to capture subtle, liability-relevant damage patternsâ€”such as faint dents, hairline cracks, asymmetric breakage, or signs of tamperingâ€”that are essential for fraud detection and claim validation. HERS reframes vehicle damage synthesis as a risk-specific adaptation problem rather than a generic image generation task.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The framework operates without manual annotation or human feedback by leveraging large language models to automatically generate diverse, damage-aware prompts paired with synthetic images from a pretrained diffusion backbone. From this self-supervised data, HERS trains lightweight LoRA-based experts, each specializing in a distinct damage category including dents, scratches, cracked paint, and broken lights. These experts learn hidden visual patterns that generic diffusion models typically overlook but that forensic assessment implicitly depends on.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To balance specialization and generalization, all damage-specific experts are merged into a single unified diffusion model, enabling zero-shot synthesis of complex, multi-damage scenarios without inference-time routing. Extensive experiments across multiple diffusion backbones demonstrate consistent improvements in textâ€“image alignment and human preference, alongside qualitative gains in damage localization, geometric coherence, and fine-grained artifact preservation. Beyond technical performance, HERS highlights the dual-use nature of generative models in insurance, underscoring the need for trustworthy, risk-aware diffusion systems for real-world, high-stakes deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;HERS_SHOWCASE_01.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;HERS_SHOWCASE_03.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;HERS_SHOWCASE_04.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Seeing Isn&#39;t Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification</title>
      <link>https://kaopanboonyuen.github.io/publication/seeing-isnt-always-believing-analysis-of-grad-cam-faithfulness-and-localization-reliability/</link>
      <pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/publication/seeing-isnt-always-believing-analysis-of-grad-cam-faithfulness-and-localization-reliability/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;compact_01.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;compact.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LymphAware: Domain-Aware Bias Disruption for Reliable Lymphoma Cancer AI Diagnosis</title>
      <link>https://kaopanboonyuen.github.io/publication/lymphaware-domain-aware-bias-disruption-for-reliable-lymphoma-cancer-ai-diagnosis/</link>
      <pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/publication/lymphaware-domain-aware-bias-disruption-for-reliable-lymphoma-cancer-ai-diagnosis/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;compact.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can explore the full &lt;strong&gt;LymphAware&lt;/strong&gt; project at
ðŸ‘‰ &lt;a href=&#34;https://kaopanboonyuen.github.io/LymphAware/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kaopanboonyuen.github.io/LymphAware/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The official implementation is publicly available at
ðŸ‘‰ &lt;a href=&#34;https://github.com/kaopanboonyuen/LymphAware&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/kaopanboonyuen/LymphAware&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Unlike conventional histopathology classifiers that implicitly rely on acquisition-specific shortcuts, LymphAware is designed from the ground up to disentangle morphology from scanner- and stain-induced bias. The repository includes reproducible training pipelines, artifact-shift perturbation modules, and evaluation protocols for cross-domain robustness. Our goal is not merely higher accuracy, but representation-level reliability under realistic domain shift â€” a necessary step toward clinically trustworthy AI systems.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
