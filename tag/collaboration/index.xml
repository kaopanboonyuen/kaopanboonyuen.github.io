<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Collaboration | Teerapong Panboonyuen</title>
    <link>https://kaopanboonyuen.github.io/tag/collaboration/</link>
      <atom:link href="https://kaopanboonyuen.github.io/tag/collaboration/index.xml" rel="self" type="application/rss+xml" />
    <description>Collaboration</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>©2026 Kao Panboonyuen</copyright><lastBuildDate>Mon, 13 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png</url>
      <title>Collaboration</title>
      <link>https://kaopanboonyuen.github.io/tag/collaboration/</link>
    </image>
    
    <item>
      <title>Global Young Scientists Summit (GYSS) 2025: Where Science Meets Inspiration</title>
      <link>https://kaopanboonyuen.github.io/blog/2025-01-11-where-science-meets-inspiration/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/blog/2025-01-11-where-science-meets-inspiration/</guid>
      <description>&lt;!-- &lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#presenting-my-work-to-her-royal-highness-princess-maha-chakri-sirindhorn&#34;&gt;Presenting My Work to Her Royal Highness Princess Maha Chakri Sirindhorn&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#understanding-the-basics-of-dnn-operations&#34;&gt;Understanding the Basics of DNN Operations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#challenges-in-parameter-recovery&#34;&gt;Challenges in Parameter Recovery&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#polynomial-time-parameter-extraction&#34;&gt;Polynomial Time Parameter Extraction&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#critical-points-and-linear-equations&#34;&gt;Critical Points and Linear Equations&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#practical-demonstration&#34;&gt;Practical Demonstration&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#comparison-with-cryptographic-systems&#34;&gt;Comparison with Cryptographic Systems&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#implications-of-randomness-and-alternative-activations&#34;&gt;Implications of Randomness and Alternative Activations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#broader-implications-and-future-directions&#34;&gt;Broader Implications and Future Directions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plenary-lecture-educability-prof-leslie-valiant&#34;&gt;Plenary Lecture: Educability (Prof Leslie Valiant)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#historical-foundations-of-intelligence-and-educability&#34;&gt;Historical Foundations of Intelligence and Educability&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#educability-vs-machine-learning&#34;&gt;Educability vs. Machine Learning&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#comparing-human-and-machine-learning&#34;&gt;Comparing Human and Machine Learning&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#cognitive-capabilities-as-civilization-enablers&#34;&gt;Cognitive Capabilities as Civilization Enablers&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ethical-implications-of-ai-development&#34;&gt;Ethical Implications of AI Development&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#addressing-concerns-about-ai&#34;&gt;Addressing Concerns About AI&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-future-of-ai-and-educability&#34;&gt;The Future of AI and Educability&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#a-call-to-action&#34;&gt;A Call to Action&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plenary-lecture-compressing-proofs-using-cryptography-prof-yael-kalai&#34;&gt;Plenary Lecture: Compressing Proofs using Cryptography (Prof Yael Kalai)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#what-are-succinct-proofs&#34;&gt;What Are Succinct Proofs?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#key-cryptographic-techniques&#34;&gt;Key Cryptographic Techniques&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#polynomial-commitments&#34;&gt;Polynomial Commitments&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#applications-of-succinct-proofs&#34;&gt;Applications of Succinct Proofs&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#ai-model-verification&#34;&gt;AI Model Verification&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#decentralized-identity&#34;&gt;Decentralized Identity&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#challenges-and-future-directions&#34;&gt;Challenges and Future Directions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#insights-from-prof-yael-tauman-kalais-research&#34;&gt;Insights from Prof. Yael Tauman Kalai’s Research&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#engaging-in-dialogues-on-the-ethics-of-ai&#34;&gt;Engaging in Dialogues on the Ethics of AI&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ethics-of-scientific-research-in-the-age-of-ai&#34;&gt;Ethics of Scientific Research in the Age of AI&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#client-concerns-about-ai&#34;&gt;Client Concerns About AI&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#opportunities-and-risks&#34;&gt;Opportunities and Risks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#public-engagement&#34;&gt;Public Engagement&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#accountability-and-regulation&#34;&gt;Accountability and Regulation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#future-directions&#34;&gt;Future Directions&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#visual-representation&#34;&gt;Visual Representation&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#expanding-my-network-and-building-new-collaborations&#34;&gt;Expanding My Network and Building New Collaborations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#a-day-ill-never-forget&#34;&gt;A Day I’ll Never Forget&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;
 --&gt;
&lt;p&gt;Attending &lt;strong&gt;GYSS2025 (Global Young Scientists Summit)&lt;/strong&gt; is an incredibly exciting opportunity. This prestigious gathering brings together brilliant young minds from all over the world, providing a platform to engage with leading experts, share innovative ideas, and immerse ourselves in the latest advancements in science and technology. It’s a momentous occasion for any researcher or scientist, and I’m thrilled to be part of this year’s summit.&lt;/p&gt;
&lt;p&gt;We’re living in an exciting era, where &lt;strong&gt;Large Language Models (LLMs)&lt;/strong&gt; are reshaping the landscape of artificial intelligence. The rapid strides AI has made in recent years, fueled by powerful architectures like GPT, are nothing short of revolutionary. As we explore the depths of these models, we are witnessing the dawn of new possibilities in natural language processing, conversational agents, and machine learning. Attending GYSS2025 during this transformative period in AI’s evolution promises to be a truly enriching experience, as it will allow me to explore these advancements and exchange ideas with some of the brightest minds in the field.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Being part of &lt;strong&gt;GYSS2025&lt;/strong&gt; is one of the most exciting and proud moments in my life. It’s a powerful gathering where the brightest young scientists from around the world come together to spark innovation and push the limits of what’s possible. This event is more than just a conference—it’s an electrifying experience that fills me with energy and inspiration. Sharing space with brilliant minds and world-class experts motivates me to keep challenging myself and driving meaningful change. It’s a milestone that I’ll remember forever, a moment that highlights how far hard work and passion can take you, and a reminder of the incredible impact we can make together.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Honored to have attended GYSS2025 in Singapore!  &lt;br&gt;.&lt;br&gt;An incredible experience connecting with global innovators, exchanging ideas, and gaining inspiration to shape the future. &lt;br&gt;.&lt;a href=&#34;https://t.co/LqTKodKSj3&#34;&gt;https://t.co/LqTKodKSj3&lt;/a&gt; &lt;a href=&#34;https://t.co/hJKWz6YTgy&#34;&gt;pic.twitter.com/hJKWz6YTgy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kao Panboonyuen (@kaopanboonyuen) &lt;a href=&#34;https://twitter.com/kaopanboonyuen/status/1878614389978472895?ref_src=twsrc%5Etfw&#34;&gt;January 13, 2025&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;



&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ZGXAT3bq7-c&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_01.jpg&#34; alt=&#34;Badge photo at GYSS2025 board&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 1: Photo with my event badge in front of the GYSS2025 board.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;presenting-my-work-to-her-royal-highness-princess-maha-chakri-sirindhorn&#34;&gt;Presenting My Work to Her Royal Highness Princess Maha Chakri Sirindhorn&lt;/h2&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;First, I would like to sincerely thank Her Royal Highness Princess Maha Chakri Sirindhorn for her gracious support and unwavering dedication to advancing science and education in Thailand. It is through her continued encouragement and vision that young researchers like myself are given extraordinary opportunities to grow, connect with global leaders, and proudly represent our country on the world stage. Her support made this once-in-a-lifetime experience at GYSS 2025 possible, and I am deeply honored and inspired by her commitment to nurturing the next generation of Thai scientists.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I feel truly honored and deeply grateful to be selected as one of only 15 young scientists from Thailand to attend the Global Young Scientists Summit (GYSS) 2025 in Singapore. I’m especially proud to be the sole representative from Thailand in the fields of computer engineering and artificial intelligence, and one of only three postdoctoral researchers selected this year. GYSS has inspired me to keep following my passion in research — it was incredibly exciting to meet world-class professors I’ve admired for years, including a legendary computer scientist who received the Turing Award. That moment truly meant the world to me.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;https://kaopanboonyuen.github.io/files/GYSS/panboonyuen_GYSS2025.jpg&#34; alt=&#34;Thailand representative at GYSS2025&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 2: Honored to represent Thailand at GYSS2025 with heartfelt gratitude to HRH Princess Maha Chakri Sirindhorn. I am one of only three postdoctoral researchers selected this year — and the sole delegate from Thailand in the fields of computer engineering and AI. (Reference Image: From official Facebook of NSTDA-GYSS: &lt;a href=&#34;https://www.facebook.com/photo.php?fbid=1061339665992254&amp;id=100063486913512&amp;set=a.529956069130619&#34; target=&#34;_blank&#34;&gt;source&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The highlight of the summit was, without a doubt, the moment I had the incredible honor of presenting my work to Her Royal Highness Princess Maha Chakri Sirindhorn.&lt;/p&gt;
&lt;p&gt;As a young scientist, I was deeply humbled to share my research titled &lt;em&gt;“MeViT: A Medium-Resolution Vision Transformer for Semantic Segmentation on Landsat Satellite Imagery for Agriculture in Thailand”&lt;/em&gt; with Her Royal Highness. My work focuses on addressing challenges in agricultural monitoring and resource management by leveraging cutting-edge advancements in artificial intelligence. Specifically, MeViT is designed for semantic segmentation of Landsat satellite imagery, targeting key economic crops in Thailand such as para rubber, corn, and pineapple. By enhancing Vision Transformers (ViTs) with a medium-resolution multi-branch architecture and incorporating mixed-scale convolutional feedforward networks (MixCFN), MeViT excels at extracting multi-scale local information critical for precise segmentation.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/tgcKR97Ea8I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Her Royal Highness listened with great interest, her graciousness reflecting her profound commitment to nurturing the next generation of scientists. She expressed encouragement for the practical applications of such research in addressing challenges critical to Thailand’s agricultural and environmental sustainability. Her unwavering support for young researchers is a testament to her dedication to fostering innovation for the betterment of society.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_06_2.jpg&#34; alt=&#34;Group photo with HRH Princess Maha Chakri Sirindhorn&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 3: Group photo with Her Royal Highness Princess Maha Chakri Sirindhorn.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_06.jpg&#34; alt=&#34;Close-up photo with HRH at GYSS2025&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 4: A truly special moment—standing right behind HRH Princess Maha Chakri Sirindhorn. A deeply proud and memorable experience.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_07.jpg&#34; alt=&#34;Photo with HRH and NSTDA staff&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 5: Group photo with HRH Princess Maha Chakri Sirindhorn and NSTDA staff members.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_03.jpg&#34; alt=&#34;Photo with HRH and Thai researchers&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 6: A proud moment with HRH and fellow Thai researchers selected for GYSS2025.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/Her_Royal_Highness_toGYSS2025_2.png&#34; alt=&#34;Photo with HRH and research team&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 7: With HRH Princess Maha Chakri Sirindhorn, fellow researchers, and NSTDA staff.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;It was a truly humbling and inspiring moment—one that I will carry with me for the rest of my life. The opportunity to share my work with Her Royal Highness not only reaffirmed my passion for pushing the boundaries of science and technology but also strengthened my resolve to contribute to meaningful advancements that serve the nation and the global community.&lt;/p&gt;
&lt;!-- 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/XzUmDPFHfc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 --&gt;
&lt;!-- &lt;div style=&#34;text-align: center;&#34;&gt;
    &lt;video controls width=&#34;800&#34;&gt;
        &lt;source src=&#34;https://kaopanboonyuen.github.io/GYSS2025_withHRH/GYSS_with_Her_Royal_Highnes_v1.mp4&#34; type=&#34;video/mp4&#34;&gt;
        Your browser does not support the video tag.
    &lt;/video&gt;
&lt;/div&gt; --&gt;
&lt;hr&gt;
&lt;h1 id=&#34;learning-from-icons-in-the-field&#34;&gt;Learning from Icons in the Field&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;The summit was filled with groundbreaking talks, and one of the most memorable was the Plenary Lecture by the renowned Professor Adi Shamir. As a Turing Award Laureate and an expert in cryptography and artificial intelligence, his lecture was truly thought-provoking. The topic, &lt;em&gt;“Can you recover a deep neural network from its answers?”&lt;/em&gt;, delved into one of the most critical questions of our time—how deep learning models, which are at the forefront of AI, can be understood and potentially reverse-engineered.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/3KNBME7f0VI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The lecture began with a discussion on the architecture of modern neural networks, emphasizing their complexity and overparameterization. Professor Shamir explored concepts like model inversion, adversarial attacks, and the limitations of current AI systems, while raising questions about privacy-preserving AI and ethical AI frameworks. His insights on adversarial robustness and explainable AI deeply resonated with my research interests, motivating me to reflect on these critical challenges.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/IMG_0218.jpg&#34; alt=&#34;Lecture with Professor Adi Shamir&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 8: Attending a lecture with Professor Adi Shamir at GYSS2025.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/IMG_0206.jpg&#34; alt=&#34;Lecture with Professor Adi Shamir&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 9: Learning from the legendary Professor Adi Shamir—co-inventor of RSA and Turing Award laureate.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Deep Neural Networks (DNNs) have become indispensable in modern AI applications, with billions of dollars and countless GPU hours invested in their training. These models are often deployed as &amp;ldquo;black boxes,&amp;rdquo; allowing users to interact with them without revealing their inner workings. However, this raises a critical question: &lt;em&gt;Can the parameters of a deep neural network be recovered using only its inputs and outputs?&lt;/em&gt; In a groundbreaking plenary lecture, Turing Award recipient Prof. Adi Shamir demonstrated that for ReLU-based DNNs, it is indeed possible to recover all parameters in polynomial time relative to the number of neurons. His findings, supported by practical experiments, highlight both the potential vulnerabilities of these systems and the need for robust defenses.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;understanding-the-basics-of-dnn-operations&#34;&gt;Understanding the Basics of DNN Operations&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;At the heart of Shamir&amp;rsquo;s analysis lies a detailed understanding of how DNNs function. A DNN comprises multiple layers of neurons, each performing a series of linear transformations followed by non-linear activations. Among these, the Rectified Linear Unit (ReLU) is a widely used activation function defined as:&lt;/p&gt;
&lt;p&gt;$$
\text{ReLU}(x) = \max(0, x).
$$&lt;/p&gt;
&lt;p&gt;This piecewise linear function introduces non-linearity while maintaining computational simplicity. Shamir emphasized that ReLU&amp;rsquo;s linear segments make it particularly susceptible to parameter extraction, as its outputs can be mathematically analyzed to reveal underlying weights and biases.&lt;/p&gt;
&lt;p&gt;In mathematical terms, the operation of a single layer in a DNN can be expressed as:&lt;/p&gt;
&lt;p&gt;$$
\mathbf{y} = \text{ReLU}(\mathbf{W}\mathbf{x} + \mathbf{b}),
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{x}$ represents the input vector,&lt;/li&gt;
&lt;li&gt;$\mathbf{W}$ is the weight matrix,&lt;/li&gt;
&lt;li&gt;$\mathbf{b}$ is the bias vector, and&lt;/li&gt;
&lt;li&gt;$\mathbf{y}$ is the output vector after applying ReLU.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stacking multiple such layers creates a complex mapping from inputs to outputs, making the network appear opaque to external observers.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenges-in-parameter-recovery&#34;&gt;Challenges in Parameter Recovery&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Recovering the parameters of a DNN—its weights and biases—is inherently an NP-hard problem. This complexity arises from the high dimensionality of the parameter space and the limited observability of internal computations. Traditional approaches to this problem relied on exhaustive searches, which scale exponentially with the number of parameters, rendering them impractical for large networks.&lt;/p&gt;
&lt;p&gt;Prof. Shamir highlighted that these challenges are exacerbated in scenarios where outputs are restricted to discrete or low-precision values. However, he proposed that by carefully designing input queries and analyzing output patterns, it is possible to significantly simplify the recovery process.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;polynomial-time-parameter-extraction&#34;&gt;Polynomial Time Parameter Extraction&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Shamir&amp;rsquo;s key contribution lies in demonstrating a polynomial-time attack for ReLU-based DNNs. His approach leverages the inherent linearity of ReLU segments to derive equations that describe the network&amp;rsquo;s behavior. By identifying &lt;strong&gt;critical points&lt;/strong&gt;—locations where ReLU outputs switch between active and inactive states—one can extract sufficient information to reconstruct the network&amp;rsquo;s parameters.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;critical-points-and-linear-equations&#34;&gt;Critical Points and Linear Equations&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Consider a single ReLU neuron with input $z$ and output $y = \text{ReLU}(z)$. The critical point for this neuron is $z = 0$, where the output transitions from 0 to a positive value. By probing the network with carefully chosen inputs that traverse these critical points, it becomes possible to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identify the active/inactive state of each neuron.&lt;/li&gt;
&lt;li&gt;Extract linear equations relating the input, weights, and biases.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For an $n$-layer network, these equations can be combined to solve for all parameters using standard techniques from linear algebra.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;practical-demonstration&#34;&gt;Practical Demonstration&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;In a practical demonstration, Shamir applied his method to an 8-layer DNN trained on the CIFAR-10 dataset. This network contained 1.2 million parameters, yet all were successfully recovered in polynomial time. The experiment underscores the real-world applicability of this attack and its implications for AI security.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;comparison-with-cryptographic-systems&#34;&gt;Comparison with Cryptographic Systems&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Drawing parallels between DNNs and cryptographic systems, Shamir likened the structure of a neural network to a block cipher, where each layer performs a distinct transformation. In cryptography, security often hinges on the infeasibility of reversing these transformations without a key. Similarly, DNNs rely on the assumption that their internal parameters cannot be deduced from external interactions.&lt;/p&gt;
&lt;p&gt;However, Shamir&amp;rsquo;s work demonstrates that this assumption does not hold for ReLU-based networks. By exploiting the deterministic nature of their operations, an adversary can effectively &amp;ldquo;decrypt&amp;rdquo; the network to reveal its parameters.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;implications-of-randomness-and-alternative-activations&#34;&gt;Implications of Randomness and Alternative Activations&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;To mitigate the risks posed by such attacks, Shamir explored potential defenses, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Randomness in Training and Inference&lt;/strong&gt;: Introducing stochasticity into the network&amp;rsquo;s operations, such as random noise or dropout, can obscure critical points and complicate parameter recovery.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alternative Activation Functions&lt;/strong&gt;: Functions like the sigmoid or hyperbolic tangent (tanh) introduce smoother transitions, reducing the linearity exploited in Shamir&amp;rsquo;s attack. The sigmoid function, for example, is defined as:&lt;/p&gt;
&lt;p&gt;$$
\sigma(x) = \frac{1}{1 + e^{-x}}.
$$&lt;/p&gt;
&lt;p&gt;Unlike ReLU, sigmoid outputs are continuous and bounded, making it harder to identify critical points.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;broader-implications-and-future-directions&#34;&gt;Broader Implications and Future Directions&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Shamir&amp;rsquo;s findings have profound implications for the field of AI security. As DNNs become integral to applications ranging from healthcare to autonomous systems, ensuring their robustness against parameter extraction attacks is paramount. Future research may focus on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designing architectures that are inherently resistant to such attacks.&lt;/li&gt;
&lt;li&gt;Developing formal metrics to quantify a network&amp;rsquo;s susceptibility to parameter recovery.&lt;/li&gt;
&lt;li&gt;Exploring the trade-offs between interpretability and security.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In conclusion, Prof. Adi Shamir&amp;rsquo;s lecture sheds light on a critical vulnerability in modern AI systems while providing a roadmap for addressing it. His innovative use of cryptographic techniques underscores the interdisciplinary nature of AI research and its potential to reshape our understanding of security in the digital age.&lt;/p&gt;
&lt;p&gt;But what truly stood out was the in-depth discussion I had with Professor Shamir. His monumental impact on the field of AI and his perspectives on current and future challenges was both a privilege and a learning experience that I will treasure forever.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_04.jpg&#34; alt=&#34;Photo with Professor Adi Shamir&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;
    Figure 10: A memorable moment meeting Professor Adi Shamir, co-inventor of RSA and recipient of the ACM A.M. Turing Award.
    (&lt;a href=&#34;https://amturing.acm.org/award_winners/shamir_2327856.cfm&#34; target=&#34;_blank&#34;&gt;Read more&lt;/a&gt;)
  &lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;plenary-lecture-educability-prof-leslie-valiant&#34;&gt;Plenary Lecture: Educability (Prof Leslie Valiant)&lt;/h2&gt;
&lt;hr&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/RT5LaVPEiyU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;In a captivating lecture, Prof. Leslie Valiant delved into the concept of educability, a framework that bridges the gap between human cognitive capabilities and machine learning. Drawing inspiration from Alan Turing’s groundbreaking insights, the discussion highlighted the interplay between intelligence, learning, and the ethical design of artificial intelligence systems.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;historical-foundations-of-intelligence-and-educability&#34;&gt;Historical Foundations of Intelligence and Educability&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;The quest to define human intelligence has long been fraught with challenges. Psychologists have struggled to agree on a single definition, revealing the complexity of human cognition. Prof. Valiant proposed that much of our understanding can be reframed through the lens of &lt;strong&gt;educability&lt;/strong&gt;, which encompasses three primary facets:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Learning from Experience&lt;/strong&gt; ($\mathcal{L}_{experience}$): The ability to generalize patterns and principles from observed phenomena.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reasoning with Acquired Knowledge&lt;/strong&gt; ($\mathcal{R}_{knowledge}$): Chaining learned concepts to make inferences.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Absorbing Explicit Instruction&lt;/strong&gt; ($\mathcal{I}_{instruction}$): Gaining knowledge through direct teaching or guidance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These components have enabled humanity to progress from rudimentary tools to advanced technological civilizations.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;educability-vs-machine-learning&#34;&gt;Educability vs. Machine Learning&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;A cornerstone of the lecture was the &lt;strong&gt;Church-Turing Thesis&lt;/strong&gt;, which posits that all forms of computation—whether in human brains or machines—are fundamentally equivalent. This foundational idea underpins modern efforts to replicate human cognition in artificial intelligence.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;comparing-human-and-machine-learning&#34;&gt;Comparing Human and Machine Learning&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Current AI systems excel in pattern recognition and data-driven learning. However, they fall short in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contextual Reasoning:&lt;/strong&gt; Humans can apply learned knowledge across diverse scenarios. For example, recognizing that if $A \implies B$ and $B \implies C$, then $A \implies C$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning from Minimal Examples:&lt;/strong&gt; Unlike humans, who can learn concepts from a few instances, AI often requires massive datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Instruction-Based Learning:&lt;/strong&gt; Humans thrive in environments with structured instruction, a capability that AI systems struggle to emulate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prof. Valiant argued that replicating these nuanced aspects of educability in AI could unlock new levels of machine intelligence.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cognitive-capabilities-as-civilization-enablers&#34;&gt;Cognitive Capabilities as Civilization Enablers&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Human educability is unique among species, enabling the creation of advanced civilizations. This capability hinges on the ability to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generalize Across Domains:&lt;/strong&gt; Applying principles learned in one context to solve problems in another.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accumulate Knowledge:&lt;/strong&gt; Building on the work of previous generations through explicit instruction and documentation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborate:&lt;/strong&gt; Combining cognitive efforts to achieve collective goals.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ethical-implications-of-ai-development&#34;&gt;Ethical Implications of AI Development&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Prof. Valiant emphasized the ethical considerations in designing AI systems that reflect positive human traits while avoiding the replication of human flaws. Key takeaways included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Avoiding Bias:&lt;/strong&gt; Ensuring that AI systems do not inherit societal biases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transparent Decision-Making:&lt;/strong&gt; Designing AI that can explain its reasoning processes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Augmenting Human Capabilities:&lt;/strong&gt; Building systems that complement rather than replace human intelligence.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;addressing-concerns-about-ai&#34;&gt;Addressing Concerns About AI&lt;/h3&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Accountability:&lt;/strong&gt; Who is responsible for decisions made by AI systems?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Safety:&lt;/strong&gt; How do we ensure AI systems act in the best interest of humanity?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Global Standards:&lt;/strong&gt; The need for international cooperation to establish ethical guidelines.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-future-of-ai-and-educability&#34;&gt;The Future of AI and Educability&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Prof. Valiant concluded with a vision for the future:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Interdisciplinary Collaboration:&lt;/strong&gt; Bringing together technologists, ethicists, and cognitive scientists to advance AI responsibly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formalizing Educability:&lt;/strong&gt; Developing mathematical models to encode human-like learning in machines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Human-Machine Collaboration:&lt;/strong&gt; Leveraging AI to enhance human cognitive abilities, leading to breakthroughs in science, medicine, and technology.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;a-call-to-action&#34;&gt;A Call to Action&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Understanding the parameters of educability is not just an academic pursuit; it is a moral imperative. By integrating insights from cognitive science, mathematics, and ethics, we can create AI systems that are not only intelligent but also aligned with human values.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This exploration of educability challenges us to rethink the foundations of intelligence and its implications for the future of artificial intelligence. As we navigate the complexities of AI development, let us be guided by the principles of transparency, accountability, and collaboration.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;plenary-lecture-compressing-proofs-using-cryptography-prof-yael-kalai&#34;&gt;Plenary Lecture: Compressing Proofs using Cryptography (Prof Yael Kalai)&lt;/h2&gt;
&lt;hr&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/bo67m5XyVWo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Cryptography has always been the backbone of secure systems, enabling trust in decentralized and distributed environments. As computation scales, the demand for efficient proof systems that ensure both correctness and privacy becomes increasingly important. Succinct proofs represent a groundbreaking development in this domain, offering compact, verifiable proofs that maintain efficiency and security.&lt;/p&gt;
&lt;p&gt;In a recent lecture, &lt;strong&gt;Prof. Yael Tauman Kalai&lt;/strong&gt; presented her advancements in succinct proofs, detailing their cryptographic foundations, practical implications, and applications in areas like blockchain and artificial intelligence (AI). This blog unpacks her insights and explores how these proofs address modern computational challenges.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-are-succinct-proofs&#34;&gt;What Are Succinct Proofs?&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Succinct proofs are cryptographic constructs designed to reduce the size and verification complexity of traditional proof systems. Instead of requiring a verifier to redo the entire computation to confirm its validity, succinct proofs enable verification with minimal computational effort. This efficiency is achieved without sacrificing security or trust, making them a critical tool for systems where scalability and privacy are paramount.&lt;/p&gt;
&lt;p&gt;Unlike traditional proof systems, which may involve large data sets and complex computations, succinct proofs achieve their compactness through advanced cryptographic techniques such as &lt;strong&gt;homomorphic encryption&lt;/strong&gt;, &lt;strong&gt;polynomial commitments&lt;/strong&gt;, and &lt;strong&gt;elliptic curve cryptography&lt;/strong&gt;. These techniques enable a prover to encode the essential details of a computation into a small, verifiable proof.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;key-cryptographic-techniques&#34;&gt;Key Cryptographic Techniques&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;One of the core building blocks of succinct proofs is the concept of zero-knowledge proofs (ZKPs). A ZKP allows a prover to convince a verifier that a statement is true without revealing any information beyond its validity. This ensures privacy while maintaining trust.&lt;/p&gt;
&lt;p&gt;For example, in a blockchain transaction, a ZKP can prove the correctness of the transaction without disclosing the sender, receiver, or amount. This is particularly critical in privacy-preserving protocols like &lt;strong&gt;zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge)&lt;/strong&gt; and &lt;strong&gt;zk-STARKs (Zero-Knowledge Scalable Transparent Arguments of Knowledge)&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;zk-SNARKs&lt;/strong&gt; rely on a trusted setup to initialize the system. They use elliptic curve pairings and polynomial arithmetic to achieve their compactness. Despite their efficiency, the trusted setup requirement introduces potential vulnerabilities if compromised.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zk-STARKs&lt;/strong&gt;, on the other hand, eliminate the need for a trusted setup by relying on hash functions and polynomial interpolation. While this makes them more transparent and secure, they often result in larger proof sizes compared to zk-SNARKs.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;polynomial-commitments&#34;&gt;Polynomial Commitments&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Another crucial technique in succinct proofs is the use of polynomial commitments. These commitments enable the prover to encode computations as polynomials, allowing the verifier to check their correctness without directly interacting with the underlying data. Polynomial commitments are a cornerstone of many cryptographic protocols, including zk-STARKs and modern succinct proof systems.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;applications-of-succinct-proofs&#34;&gt;Applications of Succinct Proofs&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;One of the most impactful applications of succinct proofs is in blockchain technology. Blockchains, by design, require every participant to validate transactions to maintain trust. However, as the number of transactions grows, this validation becomes a bottleneck.&lt;/p&gt;
&lt;p&gt;Succinct proofs offer a solution by enabling participants to verify the correctness of transactions without processing the full chain. Protocols like &lt;strong&gt;Ethereum&amp;rsquo;s Layer 2 solutions&lt;/strong&gt; and &lt;strong&gt;Zcash&lt;/strong&gt; leverage succinct proofs to improve scalability and maintain privacy.&lt;/p&gt;
&lt;p&gt;For instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Rollups&lt;/strong&gt; in Ethereum aggregate transactions off-chain and use succinct proofs to certify their correctness on-chain.&lt;/li&gt;
&lt;li&gt;Privacy-focused blockchains like Zcash use zk-SNARKs to enable shielded transactions, ensuring that details about the sender, receiver, and transaction amount remain confidential.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ai-model-verification&#34;&gt;AI Model Verification&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;In the realm of AI, succinct proofs are emerging as a tool to certify the correctness of model outputs. As AI systems grow more complex, the ability to verify their decisions becomes a challenge. Succinct proofs can be used to generate a compact, verifiable record of an AI model’s decision-making process.&lt;/p&gt;
&lt;p&gt;For example, in image classification tasks, a succinct proof could certify that the model correctly identified an object without requiring the verifier to process the entire dataset or model. This has profound implications for AI applications in critical domains like healthcare, where trust and accountability are paramount.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;decentralized-identity&#34;&gt;Decentralized Identity&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Decentralized identity systems aim to give individuals control over their personal data while allowing them to prove certain attributes (e.g., age, citizenship) without revealing unnecessary details. Succinct proofs enable such systems by providing compact, privacy-preserving verifications.&lt;/p&gt;
&lt;p&gt;Protocols like &lt;strong&gt;Verifiable Credentials (VCs)&lt;/strong&gt; and &lt;strong&gt;Decentralized Identifiers (DIDs)&lt;/strong&gt; rely on these cryptographic techniques to ensure that identity verification is both efficient and secure.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenges-and-future-directions&#34;&gt;Challenges and Future Directions&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;While succinct proofs offer significant advantages, they are not without challenges:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Trusted Setup&lt;/strong&gt;: zk-SNARKs require a trusted setup, which, if compromised, could undermine the security of the entire system. Research into transparent setups (as in zk-STARKs) aims to address this limitation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Computation Overhead&lt;/strong&gt;: Although succinct proofs reduce verification complexity, the prover&amp;rsquo;s computational requirements can be high. Optimizing the proving process is an active area of research.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: For widespread adoption, succinct proof systems must integrate seamlessly with existing technologies. This involves developing standards and protocols that ensure compatibility across platforms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Quantum Resistance&lt;/strong&gt;: As quantum computing advances, many cryptographic systems, including those used in succinct proofs, face potential vulnerabilities. Developing quantum-resistant proof systems is a critical area of ongoing research.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;insights-from-prof-yael-tauman-kalais-research&#34;&gt;Insights from Prof. Yael Tauman Kalai’s Research&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Prof. Kalai’s work pushes the boundaries of succinct proofs by exploring new cryptographic primitives and optimizing existing protocols. Her research emphasizes collaboration between academia and industry to address real-world challenges. Key areas of her focus include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Enhancing Transparency&lt;/strong&gt;: Developing protocols that eliminate the need for trusted setups while maintaining efficiency and scalability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improving Scalability&lt;/strong&gt;: Optimizing proof generation to reduce computational overhead for the prover.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expanding Applications&lt;/strong&gt;: Applying succinct proofs to emerging fields like decentralized finance (DeFi), secure voting systems, and federated learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Succinct proofs represent a paradigm shift in cryptography, enabling efficient, scalable, and privacy-preserving verification across various domains. From blockchain scalability to AI model verification, their potential applications are vast and transformative. However, realizing their full potential requires addressing challenges like computational overhead, interoperability, and quantum resistance.&lt;/p&gt;
&lt;p&gt;As cryptographic research evolves, the collaboration between researchers, industry, and policymakers will be essential to unlock the full potential of succinct proofs. Prof. Kalai’s groundbreaking work serves as a testament to the importance of pushing the boundaries of what cryptography can achieve.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;engaging-in-dialogues-on-the-ethics-of-ai&#34;&gt;Engaging in Dialogues on the Ethics of AI&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;The summit wasn’t just about science and innovation—it also provided a platform to engage in crucial discussions about the ethical implications of technological advancements. One such discussion was the Panel Huddle titled &lt;em&gt;“Ethics of Scientific Research in the Age of AI”&lt;/em&gt;, featuring prominent professors like Adi Shamir, Shafi Goldwasser, and Kalai.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/eZhOUtUIIQ8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The panel explored topics such as algorithmic bias, dual-use AI technologies, privacy-preserving AI, and the responsibilities of researchers in educating the public and policymakers. These discussions offered profound insights into the complexities of conducting ethical research in a rapidly evolving technological landscape, reminding me of the broader purpose of scientific innovation: to create a more equitable future.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/IMG_0305.jpg&#34; alt=&#34;Ethics of Scientific Research talk&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 11: Attending a talk on “Ethics of Scientific Research in the Age of AI”.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ethics-of-scientific-research-in-the-age-of-ai&#34;&gt;Ethics of Scientific Research in the Age of AI&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Artificial intelligence (AI) is revolutionizing scientific research, offering transformative tools to accelerate discovery, enhance accuracy, and expand the boundaries of human knowledge. However, these advancements also bring profound ethical challenges. At the recent panel moderated by &lt;strong&gt;Prof. Simon Chesterman&lt;/strong&gt; from the National University of Singapore, renowned experts &lt;strong&gt;Prof. Joan Rose&lt;/strong&gt; (2016 Stockholm Water Prize), &lt;strong&gt;Prof. Yael Kalai&lt;/strong&gt; (2022 ACM Prize in Computing), and &lt;strong&gt;Prof. Adi Shamir&lt;/strong&gt; (2002 Turing Award) delved into the critical ethical considerations of AI in scientific research.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;client-concerns-about-ai&#34;&gt;Client Concerns About AI&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;AI systems increasingly shape scientific discovery, yet their application necessitates robust ethical guidelines. Governance frameworks must:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define clear boundaries for AI use.&lt;/li&gt;
&lt;li&gt;Address biases inherent in data and algorithms.&lt;/li&gt;
&lt;li&gt;Ensure transparency and accountability in AI-driven research outcomes.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;human-interaction&#34;&gt;Human Interaction&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;The integration of AI into research workflows often alters the dynamic between human researchers and technology. Key considerations include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preventing over-reliance on AI outputs, which could lead to critical oversights.&lt;/li&gt;
&lt;li&gt;Mitigating risks of misinterpretation of AI-generated results.&lt;/li&gt;
&lt;li&gt;Balancing human intuition with machine precision.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;opportunities-and-risks&#34;&gt;Opportunities and Risks&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;AI holds immense potential to transform scientific methodologies:&lt;/p&gt;
&lt;p&gt;$$ \text{Efficiency Gain} = \frac{T_{\text{manual}}}{T_{\text{AI-assisted}}} $$&lt;/p&gt;
&lt;p&gt;Where $T_{\text{manual}}$ represents the time for traditional methods and $T_{\text{AI-assisted}}$ denotes AI-accelerated approaches. While this formula underscores AI’s ability to enhance efficiency, ethical concerns include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Misinformation propagation due to AI biases.&lt;/li&gt;
&lt;li&gt;Job displacement for researchers whose roles are increasingly automated.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;military-applications&#34;&gt;Military Applications&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;AI’s role in military research raises acute ethical dilemmas, particularly in autonomous weapons systems. Questions of accountability and decision-making in lethal scenarios must be urgently addressed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is accountable for errors in autonomous systems?&lt;/li&gt;
&lt;li&gt;How can ethical principles such as proportionality and necessity be encoded into AI?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;public-engagement&#34;&gt;Public Engagement&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;A significant gap exists between the scientific community and the public’s understanding of AI. To bridge this divide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Develop accessible communication strategies to explain AI technologies and their implications.&lt;/li&gt;
&lt;li&gt;Foster public trust through transparent disclosures of AI’s capabilities and limitations.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;proactive-education&#34;&gt;Proactive Education&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;Educating researchers and policymakers is vital to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Promote ethical awareness.&lt;/li&gt;
&lt;li&gt;Equip them to evaluate the societal impacts of their work.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;accountability-and-regulation&#34;&gt;Accountability and Regulation&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Regulating AI is a complex yet essential endeavor. Key areas of focus include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Warfare Applications:&lt;/strong&gt; Establishing international norms to prohibit unethical AI use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Public Safety:&lt;/strong&gt; Creating standards for AI deployment in sensitive domains such as healthcare and transportation.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;global-cooperation&#34;&gt;Global Cooperation&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;International collaboration is critical to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Develop shared standards for AI ethics.&lt;/li&gt;
&lt;li&gt;Address cross-border challenges, such as data privacy and AI governance.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;future-directions&#34;&gt;Future Directions&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Investing in research on AI risks enables policymakers to adopt informed, proactive measures rather than reactive regulations post-crisis. Proposed funding distribution can be modeled as:&lt;/p&gt;
&lt;p&gt;$$ \text{Allocation} = \frac{R_{\text{risk}}}{R_{\text{total}}} \times 100 % $$&lt;/p&gt;
&lt;p&gt;Where $R_{\text{risk}}$ represents research focused on AI risks, and $R_{\text{total}}$ is the total research budget.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;interdisciplinary-approach&#34;&gt;Interdisciplinary Approach&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;Addressing AI’s ethical challenges requires collaboration among:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Technologists:&lt;/strong&gt; To refine AI systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ethicists:&lt;/strong&gt; To integrate moral principles into AI development.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Policymakers:&lt;/strong&gt; To enact effective regulations and governance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The panel underscored that while AI offers unparalleled opportunities for scientific progress, its ethical integration requires foresight, collaboration, and accountability. By fostering interdisciplinary dialogue and committing to transparent, responsible practices, the scientific community can ensure AI serves as a force for good.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;visual-representation&#34;&gt;Visual Representation&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;A mind map summarizing these insights can help readers visualize the ethical considerations of AI in scientific research.&lt;/p&gt;
&lt;h2&gt;Visual Representation&lt;/h2&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/GRPAH_01.png&#34; alt=&#34;Mind map on AI ethics in scientific research&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;
    Figure 12: A mind map summarizing key ethical considerations in the use of AI for scientific research, discussed during GYSS2025.
  &lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;expanding-my-network-and-building-new-collaborations&#34;&gt;Expanding My Network and Building New Collaborations&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Beyond the lectures and discussions, GYSS 2025 was also a chance to meet fellow researchers from all over the globe. I had the pleasure of connecting with inspiring individuals from diverse fields of study, creating friendships that will last a lifetime. The exchange of ideas with these brilliant young scientists has already sparked new collaborations and research ideas that I can’t wait to explore further.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-day-ill-never-forget&#34;&gt;A Day I’ll Never Forget&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;All in all, my experience at GYSS 2025 was beyond what I could have imagined. It was a perfect blend of research, networking, and fun. It gave me the chance to engage with some of the brightest minds in science, learn from Nobel Laureates and Turing Award winners, and discuss pressing issues in AI and ethics. It was an unforgettable experience, and I’m leaving with new ideas, fresh perspectives, and the motivation to continue pushing the boundaries of my own research.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/5C-6bXuVq9Q&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;hr&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/IMG_0111.jpg&#34; alt=&#34;Lecture atmosphere at GYSS2025&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 13: Immersed in the vibrant academic atmosphere of GYSS2025.&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/KAO_GYSS2025_02.jpg&#34; alt=&#34;Photo with GYSS2025 banner&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 14: Standing proudly with the GYSS2025 banner—first time wearing a formal suit in years!&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;GYSS2025_withHRH/LECTURE/IMG_0238.jpg&#34; alt=&#34;NUS campus shot&#34;&gt;
  &lt;p style=&#34;font-style: italic; margin-top: 0px;&#34;&gt;Figure 15: Beautiful campus vibes at NUS, Singapore—a serene and inspiring place for learning.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;PS. This year, GYSS 2025 was hosted at the beautiful campus of the National University of Singapore (NUS), and I absolutely fell in love with the environment. The vibrant atmosphere, lush greenery, and modern architecture made it the perfect blend of nature and innovation—a truly ideal space for creativity and learning.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Panboonyuen, Teerapong. (Jan 2025). &lt;em&gt;Global Young Scientists Summit (GYSS) 2025: Where Science Meets Inspiration&lt;/em&gt;. Blog post on Kao Panboonyuen. &lt;a href=&#34;https://kaopanboonyuen.github.io/blog/2025-01-11-where-science-meets-inspiration/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kaopanboonyuen.github.io/blog/2025-01-11-where-science-meets-inspiration/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;For a BibTeX citation:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;@article{panboonyuen2025gyss,
  title   = &amp;quot;Global Young Scientists Summit (GYSS) 2025: Where Science Meets Inspiration&amp;quot;,
  author  = &amp;quot;Panboonyuen, Teerapong&amp;quot;,
  journal = &amp;quot;kaopanboonyuen.github.io/&amp;quot;,
  year    = &amp;quot;2025&amp;quot;,
  month   = &amp;quot;Jan&amp;quot;,
  url     = &amp;quot;https://kaopanboonyuen.github.io/blog/2025-01-11-where-science-meets-inspiration/&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Did you find this page helpful? Consider sharing it 🙌
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
