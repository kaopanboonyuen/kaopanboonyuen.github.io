<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.2.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Teerapong Panboonyuen" />

  
  
  
    
  
  <meta name="description" content="This dissertation introduces a new architecture for remote sensing, featuring Global Convolutional Network (GCN), channel attention, domain-specific transfer learning, Feature Fusion (FF), and Depthwise Atrous Convolution (DA). Tests on Landsat-8 and ISPRS Vaihingen datasets show that this model significantly outperforms the baseline." />

  
  <link rel="alternate" hreflang="en-us" href="https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.08f2e04360a1c87f5ad39547c02bf219.css" />

  



  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Teerapong Panboonyuen" />
  <meta property="og:url" content="https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/" />
  <meta property="og:title" content="Ph.D. Thesis Defense | Teerapong Panboonyuen" />
  <meta property="og:description" content="This dissertation introduces a new architecture for remote sensing, featuring Global Convolutional Network (GCN), channel attention, domain-specific transfer learning, Feature Fusion (FF), and Depthwise Atrous Convolution (DA). Tests on Landsat-8 and ISPRS Vaihingen datasets show that this model significantly outperforms the baseline." /><meta property="og:image" content="https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/featured.png" />
    <meta property="twitter:image" content="https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2020-07-31T14:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2020-07-31T14:00:00&#43;00:00">
  

  



  
    




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Event",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/"
  },
  "name": "Ph.D. Thesis Defense",
  
  "location": {
    "@type": "Place",
    "name": "Chulalongkorn University"
  },
  
  
  "image": [
    "https://kaopanboonyuen.github.io/talk/ph.d.-thesis-defense/featured.png"
  ],
  
  "startDate": "2020-07-31T14:00:00Z",
  
  
  "performer": {
    "@type": "Person",
    "name": "Teerapong Panboonyuen"
  },
  
  "description": "This dissertation introduces a new architecture for remote sensing, featuring Global Convolutional Network (GCN), channel attention, domain-specific transfer learning, Feature Fusion (FF), and Depthwise Atrous Convolution (DA). Tests on Landsat-8 and ISPRS Vaihingen datasets show that this model significantly outperforms the baseline."
}
</script>

  

  

  





  <title>Ph.D. Thesis Defense | Teerapong Panboonyuen</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="d7024594cc6cb801b6ae9f39b7862ecf" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#awards"><span>Awards</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#press"><span>Press</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Featured</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#tags"><span>Topics</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#communities"><span>Communities</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/blog/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://x.com/kaopanboonyuen" data-toggle="tooltip" data-placement="bottom" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <div class="pub">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Ph.D. Thesis Defense</h1>

  

  


<div class="article-metadata">

  
  

  

  

  

  
  
  
  
  
  

  
  

</div>

  




<div class="btn-links mb-3">
  
  








  









  
    
  










</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 450px;">
  <div style="position: relative">
    <img src="/talk/ph.d.-thesis-defense/featured_hu9ccf3f7a1b6dbc32658d8788de9ecd24_1799990_720x0_resize_lanczos_3.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    
      <h3>Abstract</h3>
      <p class="pub-abstract">My thesis defense at the Faculty of Engineering, Chulalongkorn University. This dissertation introduces a new architecture for remote sensing, featuring Global Convolutional Network (GCN), channel attention, domain-specific transfer learning, Feature Fusion (FF), and Depthwise Atrous Convolution (DA). Tests on Landsat-8 and ISPRS Vaihingen datasets show that this model significantly outperforms the baseline.</p>
    

    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Date</div>
          <div class="col-12 col-md-9">
            2020 2:00 PM
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Event</div>
          <div class="col-12 col-md-9">
            
            Chulalongkorn University Ph.D. Thesis Defense
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Location</div>
          <div class="col-12 col-md-9">Chulalongkorn University</div>
          
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style">
      <h2 id="-phd-dissertation-defense--triumphant">🎓 Ph.D. Dissertation Defense – Triumphant</h2>
<p>On <strong>July 9, 2020</strong>, I successfully defended my Ph.D. dissertation titled <em>&ldquo;Semantic Segmentation on Remotely Sensed Images Using Deep Convolutional Encoder-Decoder Neural Network&rdquo;</em> before a distinguished committee of Thai professors, each of whom earned their doctoral degrees from world-renowned international universities.</p>
<p><img src="panboonyuen_phd_defense_day_01.png" alt=""></p>
<p>The list below shows the names of those who submitted their final Ph.D. dissertations; considering I’m from the class of 2017 (student ID: 6071467821) and graduated in 2019, it took me just two years to complete this journey—an achievement that reflects my dedication and perseverance. I’m deeply proud and grateful to myself for the commitment I gave to this work.</p>
<p><img src="panboonyuen_phd_defense_day_02.png" alt=""></p>
<p>🧠 The research focused on applying deep learning techniques—specifically convolutional encoder-decoder architectures—for high-accuracy semantic segmentation in remotely sensed imagery, pushing the boundaries of geospatial AI.</p>
<p>🔗 <strong>Explore the full dissertation, source code, and project resources here:</strong><br>
👉 <a href="https://kaopanboonyuen.github.io/FusionNetGeoLabel/" target="_blank" rel="noopener">https://kaopanboonyuen.github.io/FusionNetGeoLabel/</a></p>
<p>🔗 <strong>Interested in the full presentation slides? You can view them here:</strong><br>
👉 <a href="https://kaopanboonyuen.github.io/files/panboonyuen_phd_defense_2020.pdf" target="_blank" rel="noopener">Ph.D. Defense Slides</a></p>
<hr>
<blockquote>
<p><strong>One word to define the journey:</strong> <code>Triumphant</code> 🚀</p>
</blockquote>
<h3 id="phd-journey-a-milestone-achieved">PhD Journey: A Milestone Achieved</h3>
<p>On May 19, 2022, I proudly completed my PhD at Chulalongkorn University, closing a remarkable chapter in my academic journey. This milestone was not just a moment of personal triumph, but also a time of reflection and deep gratitude. Graduating with a doctoral degree was a dream realized, filled with emotions that I will carry with me forever.</p>
<p>Throughout this journey, I was fortunate to have the unwavering support of incredible mentors, advisors, colleagues, and friends. Their guidance and encouragement were instrumental in my success, and having them by my side on this special day was a poignant reminder of the profound impact they&rsquo;ve had on both my academic and personal development.</p>
<p><img src="kaophd_002.png" alt="Kao_Panboonyuen_PhD">
<img src="kaophd_001.png" alt="Kao_Panboonyuen_PhD">
<img src="kaophd_003.png" alt="Kao_Panboonyuen_PhD">
<img src="kaophd_004.png" alt="Kao_Panboonyuen_PhD">
<img src="kaophd_005.png" alt="Kao_Panboonyuen_PhD"></p>
<!-- 
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/a-oWa2CS8jg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
 -->
<p>Completing a PhD is more than just an academic achievement; it&rsquo;s a journey of personal growth. It demands perseverance, resilience, and the ability to navigate and overcome numerous challenges. My passion for machine learning and my commitment to research were the driving forces that kept me moving forward, enabling me to make meaningful contributions to the field.</p>
<h3 id="phd-thesis-highlights">PhD Thesis Highlights</h3>
<h2 id="introduction">Introduction</h2>
<p>Semantic segmentation in remote sensing images plays a crucial role in applications such as land use classification, urban planning, and environmental monitoring. Remote sensing images often come from diverse sources, ranging from medium-resolution satellite imagery (such as Landsat-8) to high-resolution aerial images (such as those from the ISPRS Vaihingen Challenge). However, the task of semantic segmentation remains challenging due to the variety of image scales, the scarcity of labeled data, and the need for models capable of extracting both high-level and low-level features effectively.</p>
<p>In my PhD research, I propose a series of advancements in convolutional neural network (CNN)-based approaches to enhance the accuracy of semantic segmentation on remotely sensed data. Building upon the state-of-the-art methods, I introduce several innovations, including an enhanced <strong>Global Convolutional Network (GCN)</strong> with channel attention, <strong>domain-specific transfer learning</strong>, and the integration of <strong>feature fusion</strong> and <strong>depthwise atrous convolutions</strong>. These innovations aim to address the unique challenges of remote sensing datasets and push the boundaries of semantic segmentation performance.</p>
<h2 id="the-challenge-limitations-of-traditional-approaches">The Challenge: Limitations of Traditional Approaches</h2>
<p>Semantic segmentation models, particularly Deep Convolutional Encoder-Decoder (DCED) networks, have shown promise in image segmentation tasks. However, when applied to remote sensing imagery, these models face key limitations:</p>
<ol>
<li>
<p><strong>Resolution Differences</strong>: Remote sensing images span a wide range of resolutions, from very high-resolution (VHR) aerial images to medium-resolution satellite images. Traditional models, designed for single-resolution tasks, struggle to generalize across these diverse scales.</p>
</li>
<li>
<p><strong>Data Scarcity</strong>: Annotated datasets for training deep models are scarce, particularly for high-resolution satellite or aerial imagery. This leads to overfitting and poor generalization.</p>
</li>
<li>
<p><strong>Inability to Capture Global Context</strong>: Traditional CNN models focus on local features, which are insufficient for understanding global context in satellite images, such as large rivers, forests, or urban areas.</p>
</li>
</ol>
<h2 id="methodology">Methodology</h2>
<h3 id="global-convolutional-network-gcn-with-enhanced-backbone">Global Convolutional Network (GCN) with Enhanced Backbone</h3>
<p>The <strong>Global Convolutional Network (GCN)</strong> is a modern CNN architecture that addresses the limitations of traditional models. GCN overcomes the challenge of capturing both local and global features by using a multi-level architecture. Each level in the GCN extracts features at different resolutions, ensuring that both fine-grained and broad contextual information are captured.</p>
<p>This can be written as:</p>
<p>$$
\mathbf{F}_{\text{GCN}} = \sum \mathbf{W}_l \cdot \mathbf{X}_l
$$</p>
<p>Building on this architecture, I proposed an enhancement to the GCN backbone by modifying its structure and increasing the number of layers, making it more suitable for medium-resolution remote sensing imagery. Specifically, I employed the <strong>ResNet</strong> architecture with varying depths—ResNet50, ResNet101, and ResNet152—to adapt the model to different datasets and resolutions.</p>
<h4 id="key-contributions">Key Contributions:</h4>
<ul>
<li><strong>Multi-resolution Feature Extraction</strong>: By stacking multiple convolutional layers at different stages, the GCN captures features across multiple resolutions.</li>
<li><strong>Boundary Refinement</strong>: A boundary refinement module is introduced to improve the precision of segmentation boundaries, crucial for tasks like building or road detection.</li>
</ul>
<h3 id="channel-attention-mechanism">Channel Attention Mechanism</h3>
<p>One of the most significant advancements in my work is the introduction of the <strong>Channel Attention Block</strong>. Attention mechanisms, inspired by the human visual system, allow the model to focus on the most important features in the image. In the case of remote sensing images, this means highlighting key features such as roads, rivers, or vegetation, while suppressing irrelevant background information.</p>
<p>The attention mechanism is mathematically modeled as:</p>
<p>$$
\mathbf{z}_c = \sigma\left( W_c \cdot \text{AvgPool}(\mathbf{x}_c) + b_c \right)
$$</p>
<p>The <strong>channel attention block</strong> modifies the network&rsquo;s weights to prioritize the most discriminative channels during feature extraction, improving the network’s ability to differentiate between different land cover types. This is crucial in remote sensing, where the subtle difference between similar features (e.g., different vegetation types) can significantly impact segmentation accuracy.</p>
<h4 id="key-contributions-1">Key Contributions:</h4>
<ul>
<li><strong>Adaptive Feature Selection</strong>: The network dynamically adjusts the importance of features, focusing on those most relevant to the task at hand.</li>
<li><strong>Improved Discriminative Power</strong>: By emphasizing discriminative features, the model is able to achieve higher classification accuracy, particularly for challenging classes in remote sensing datasets.</li>
</ul>
<h3 id="domain-specific-transfer-learning">Domain-Specific Transfer Learning</h3>
<p>One of the challenges in training deep learning models for remote sensing is the scarcity of annotated data, particularly for high-resolution images. To address this, I introduced <strong>Domain-Specific Transfer Learning</strong>. This technique involves leveraging pre-trained models from different but related datasets to transfer knowledge across domains.</p>
<p>By utilizing pre-trained models from one dataset (e.g., ISPRS Vaihingen) and applying them to another (e.g., Landsat-8), I was able to mitigate the data scarcity issue and improve the performance of my models. This approach ensures that knowledge gained from one domain can benefit another, allowing the model to generalize better with limited annotated data.</p>
<h4 id="key-contributions-2">Key Contributions:</h4>
<ul>
<li><strong>Cross-Domain Knowledge Transfer</strong>: Knowledge learned from high-resolution datasets is transferred to medium-resolution tasks, significantly improving segmentation accuracy with minimal labeled data.</li>
<li><strong>Pre-Trained Weights Utilization</strong>: The use of pre-trained weights from different datasets enables the model to learn features that are generalizable across various remote sensing tasks.</li>
</ul>
<h3 id="feature-fusion-and-depthwise-atrous-convolution">Feature Fusion and Depthwise Atrous Convolution</h3>
<p>To further refine feature extraction and improve segmentation performance, I introduced <strong>Feature Fusion</strong> and <strong>Depthwise Atrous Convolution (DA)</strong>. These techniques work synergistically to enhance the model&rsquo;s ability to capture multi-scale information while maintaining high resolution.</p>
<ul>
<li><strong>Feature Fusion</strong>: This technique fuses low-level features, such as edges and textures, from the backbone network with high-level features from the segmentation model. This fusion ensures that fine-grained details are preserved while providing the model with a richer set of features for segmentation.</li>
</ul>
<p>$$
\mathbf{F}_{\text{fused}} = \mathbf{F}_L + \alpha \cdot \mathbf{F}_H
$$</p>
<ul>
<li><strong>Depthwise Atrous Convolution</strong>: The DA module applies dilated convolutions at multiple scales, enabling the network to capture contextual information over larger areas without losing spatial resolution. This is particularly important for remote sensing tasks where object boundaries (e.g., between forest and water) need to be sharply delineated.</li>
</ul>
<p>The Depthwise Atrous Convolution is mathematically expressed as:</p>
<p>$$
y_d = \sum_{k} w_k \cdot x_{i + r \cdot k}
$$</p>
<h4 id="key-contributions-3">Key Contributions:</h4>
<ul>
<li><strong>Improved Feature Representation</strong>: By integrating low-level features with deep model representations, the model gains a more comprehensive understanding of the image.</li>
<li><strong>Enhanced Contextual Understanding</strong>: The DA module allows the network to consider broader context in each layer, improving segmentation accuracy, especially for large objects and distant features.</li>
</ul>
<h2 id="experiments-and-results">Experiments and Results</h2>
<h3 id="datasets">Datasets</h3>
<p>I conducted experiments on three benchmark datasets:</p>
<ol>
<li><strong>ISPRS Vaihingen Challenge Dataset</strong> (Very High Resolution)</li>
<li><strong>Landsat-8 Satellite Imagery</strong> (Medium Resolution)</li>
<li><strong>Private Datasets</strong> from GISTDA (Geo-Informatics and Space Technology Development Agency)</li>
</ol>
<p>These datasets represent a mix of very high-resolution and medium-resolution imagery, which provided a comprehensive testbed for evaluating the effectiveness of my proposed methods.</p>
<h3 id="performance-metrics">Performance Metrics</h3>
<p>The model was evaluated using standard segmentation metrics:</p>
<h4 id="1-f1-score">1. <strong>F1 Score</strong>:</h4>
<p>The F1 Score measures the balance between <strong>Precision</strong> and <strong>Recall</strong>, and is calculated as:</p>
<p>$$
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$</p>
<p>Where:</p>
<ul>
<li><strong>Precision</strong> is the fraction of relevant instances among the retrieved instances:</li>
</ul>
<p>$$
\text{Precision} = \frac{TP}{TP + FP}
$$</p>
<ul>
<li><strong>Recall</strong> is the fraction of relevant instances that have been retrieved over the total amount of relevant instances:</li>
</ul>
<p>$$
\text{Recall} = \frac{TP}{TP + FN}
$$</p>
<h5 id="example-pineapple-class">Example: <strong>Pineapple Class</strong></h5>
<p>For the <strong>pineapple</strong> class:</p>
<ul>
<li>( TP = 50 )</li>
<li>( FP = 10 )</li>
<li>( FN = 15 )</li>
</ul>
<p>We calculate <strong>Precision</strong>:</p>
<p>$$
\text{Precision} = \frac{50}{50 + 10} = 0.8333
$$</p>
<p>And <strong>Recall</strong>:</p>
<p>$$
\text{Recall} = \frac{50}{50 + 15} = 0.7692
$$</p>
<p>Now calculate the <strong>F1 Score</strong>:</p>
<p>$$
F1 = 2 \cdot \frac{0.8333 \cdot 0.7692}{0.8333 + 0.7692} = 0.799
$$</p>
<p>Thus, the <strong>F1 Score</strong> for the pineapple class is <strong>0.799</strong>.</p>
<hr>
<h4 id="2-mean-iou-intersection-over-union">2. <strong>Mean IoU (Intersection over Union)</strong>:</h4>
<p>The <strong>IoU</strong> quantifies the overlap between the predicted and true segmentation maps:</p>
<p>$$
IoU = \frac{TP}{TP + FP + FN}
$$</p>
<h5 id="example-corn-class">Example: <strong>Corn Class</strong></h5>
<p>For the <strong>corn</strong> class:</p>
<ul>
<li>( TP = 80 )</li>
<li>( FP = 5 )</li>
<li>( FN = 20 )</li>
</ul>
<p>We calculate the <strong>IoU</strong>:</p>
<p>$$
IoU = \frac{80}{80 + 5 + 20} = 0.7619
$$</p>
<p>Thus, the <strong>IoU</strong> for the corn class is <strong>0.7619</strong>.</p>
<hr>
<h4 id="3-mean-iou-for-multiple-classes">3. <strong>Mean IoU for Multiple Classes</strong>:</h4>
<p>For evaluating the <strong>Mean IoU</strong> over multiple classes (e.g., pineapple, corn, pararubber), we compute the average IoU:</p>
<p>$$
\text{Mean IoU} = \frac{IoU_{\text{pineapple}} + IoU_{\text{corn}} + IoU_{\text{pararubber}}}{3}
$$</p>
<p>Using the IoUs for each class:</p>
<ul>
<li>IoU for pineapple = 0.799</li>
<li>IoU for corn = 0.7619</li>
<li>IoU for pararubber = 0.85</li>
</ul>
<p>We get the <strong>Mean IoU</strong>:</p>
<p>$$
\text{Mean IoU} = \frac{0.799 + 0.7619 + 0.85}{3} = 0.8036
$$</p>
<p>Thus, the <strong>Mean IoU</strong> across all classes is <strong>0.8036</strong>.</p>
<hr>
<h3 id="results">Results</h3>
<p>The proposed model significantly outperformed baseline models, including traditional Deep Convolutional Encoder-Decoder (DCED) networks, across all datasets:</p>
<ul>
<li><strong>ISPRS Vaihingen Dataset</strong>: F1 Score of <strong>0.9362</strong></li>
<li><strong>Landsat-8 Dataset</strong>: F1 Score of <strong>0.9114</strong></li>
</ul>
<p>The proposed model consistently exceeded the <strong>90% F1 score</strong> threshold across all classes, demonstrating its robustness and adaptability to different image resolutions and domains.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This research introduces several key advancements in deep learning for remote sensing semantic segmentation. By incorporating multi-resolution feature extraction, channel attention, domain-specific transfer learning, feature fusion, and depthwise atrous convolutions, my approach addresses the unique challenges posed by remote sensing data. The experimental results validate the effectiveness of these techniques, providing a solid foundation for further improvements in remote sensing applications.</p>
<p>With the successful application of these methods, I am confident that these innovations will contribute significantly to the field of remote sensing and provide new avenues for improving the accuracy and generalization of deep learning models in this domain.</p>
<blockquote>
<p>Explore more about my PhD story <a href="https://kaopanboonyuen.wordpress.com/2022/05/23/the-phd-journey/" target="_blank" rel="noopener">here</a>.</p>
</blockquote>
<p><strong>Kao Panboonyuen</strong></p>

    </div>

    

















  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://kaopanboonyuen.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/teerapong-panboonyuen/avatar_hu3c429e132ccde7f98e52ca20c1f589ef_2676345_270x270_fill_q75_lanczos_center.jpg" alt="Teerapong Panboonyuen"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://kaopanboonyuen.github.io/">Teerapong Panboonyuen</a></h5>
      
      <p class="card-text">My research focuses on leveraging advanced machine intelligence techniques, specifically computer vision, to enhance semantic understanding, learning representations, visual recognition, and geospatial data interpretation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:teerapong.panboonyuen@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://x.com/kaopanboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.th/citations?user=myy0qDgAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="fas fa-graduation-cap"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.youtube.com/@kaopanboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-youtube"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/kaopanboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/teerapong-panboonyuen" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://kaopanboonyuen.github.io/files/panboonyuen_cv.pdf" target="_blank" rel="noopener">
        <i class="fas fa-download"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  




  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    ©2025 Kao Panboonyuen
  </p>
  

  
  






  <p class="powered-by">
    
    Built using <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a> and the <a href="https://github.com/wowchemy/starter-hugo-academic" target="_blank" rel="noopener">Wowchemy academic template</a>. View <a href="https://github.com/kaopanboonyuen/kaopanboonyuen.github.io" target="_blank" rel="noopener">source</a>.
        
  </p>
</footer>
    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/golang.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b36873e4e886c7b03b21e4eb97d9b6d7.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
