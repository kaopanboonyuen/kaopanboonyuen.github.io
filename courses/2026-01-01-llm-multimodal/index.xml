<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM in Multimodal: Text, Vision, Audio, Video | Teerapong Panboonyuen</title>
    <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/</link>
      <atom:link href="https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/index.xml" rel="self" type="application/rss+xml" />
    <description>LLM in Multimodal: Text, Vision, Audio, Video</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â©2026 Kao Panboonyuen</copyright><lastBuildDate>Thu, 01 Jan 2026 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png</url>
      <title>LLM in Multimodal: Text, Vision, Audio, Video</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/</link>
    </image>
    
    <item>
      <title>Lecture 01 â€” What Is a Multimodal LLM, Really?</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-01-what-is-multimodal-llm/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-01-what-is-multimodal-llm/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~3 hours (deep foundational lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-matters&#34;&gt;ğŸŒ Why This Lecture Matters&lt;/h2&gt;
&lt;p&gt;Before code.&lt;br&gt;
Before models.&lt;br&gt;
Before GPUs.&lt;/p&gt;
&lt;p&gt;We must answer &lt;strong&gt;one fundamental question&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;What does it mean for a machine to understand the world through many senses?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Multimodal LLMs are not just:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bigger models&lt;/li&gt;
&lt;li&gt;more parameters&lt;/li&gt;
&lt;li&gt;more data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They represent a &lt;strong&gt;shift in how intelligence is built&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-big-picture&#34;&gt;ğŸ§  The Big Picture&lt;/h2&gt;
&lt;p&gt;Humans are multimodal by nature:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Human Sense&lt;/th&gt;
&lt;th&gt;AI Modality&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Vision&lt;/td&gt;
&lt;td&gt;Images / Video&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hearing&lt;/td&gt;
&lt;td&gt;Audio&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Language&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Memory&lt;/td&gt;
&lt;td&gt;Documents&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;td&gt;LLM&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A &lt;strong&gt;multimodal LLM&lt;/strong&gt; attempts to &lt;strong&gt;unify perception and reasoning&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-formal-definition-intuitive&#34;&gt;ğŸ§© Formal Definition (Intuitive)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;Multimodal Large Language Model (MLLM)&lt;/strong&gt; is a system that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;processes &lt;strong&gt;multiple input modalities&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;aligns them into a &lt;strong&gt;shared representation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;performs &lt;strong&gt;reasoning primarily through language&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Key idea:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Language is the reasoning interface.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-modalities-vs-models-important-distinction&#34;&gt;ğŸ”¬ Modalities vs Models (Important Distinction)&lt;/h2&gt;
&lt;p&gt;âŒ Multimodal â‰  multiple models glued together&lt;br&gt;
âœ… Multimodal = &lt;strong&gt;coherent representation space&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Image â†’ Vision Encoder â”
Audio â†’ Audio Encoder  â”œâ”€&amp;gt; Shared Latent Space â†’ LLM â†’ Output
Text  â†’ Text Encoder   â”˜

&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-llms-became-the-brain&#34;&gt;ğŸ§  Why LLMs Became the â€œBrainâ€&lt;/h2&gt;
&lt;p&gt;Historically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vision models â†’ pattern recognition&lt;/li&gt;
&lt;li&gt;Audio models â†’ signal processing&lt;/li&gt;
&lt;li&gt;NLP models â†’ reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LLMs won because they:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;handle &lt;strong&gt;symbolic abstraction&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;perform &lt;strong&gt;long-chain reasoning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;generalize across tasks&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;LLMs are not just text models â€” they are reasoning engines.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-components-of-a-multimodal-llm&#34;&gt;ğŸ§© Core Components of a Multimodal LLM&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Purpose&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Modality Encoder&lt;/td&gt;
&lt;td&gt;Convert raw input â†’ embeddings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Projection Layer&lt;/td&gt;
&lt;td&gt;Align modality to language space&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LLM Backbone&lt;/td&gt;
&lt;td&gt;Reasoning &amp;amp; generation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Output Head&lt;/td&gt;
&lt;td&gt;Decode answers&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-component-deep-dive&#34;&gt;ğŸ” Component Deep Dive&lt;/h2&gt;
&lt;h3 id=&#34;1-modality-encoders&#34;&gt;1ï¸âƒ£ Modality Encoders&lt;/h3&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Image â†’ ViT, CNN&lt;/li&gt;
&lt;li&gt;Audio â†’ Whisper, Wav2Vec&lt;/li&gt;
&lt;li&gt;Video â†’ Frame encoder + temporal model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Role:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Convert &lt;strong&gt;raw signals&lt;/strong&gt; into &lt;strong&gt;semantic vectors&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-projection--alignment-layer-critical&#34;&gt;2ï¸âƒ£ Projection / Alignment Layer (CRITICAL)&lt;/h3&gt;
&lt;p&gt;This is the &lt;strong&gt;most underrated component&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Purpose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;map non-text embeddings â†’ LLM token space&lt;/li&gt;
&lt;li&gt;enable cross-modal attention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Without good alignment:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The LLM sees noise, not meaning.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;3-llm-backbone&#34;&gt;3ï¸âƒ£ LLM Backbone&lt;/h3&gt;
&lt;p&gt;Usually:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decoder-only Transformer&lt;/li&gt;
&lt;li&gt;Pretrained on massive text corpora&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why reuse?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;language encodes &lt;strong&gt;world knowledge&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;reasoning already learned&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-mental-model-very-important&#34;&gt;ğŸ§  Mental Model (Very Important)&lt;/h2&gt;
&lt;p&gt;Think of a multimodal LLM as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Perception â†’ Translation â†’ Thought â†’ Expression&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;perception = encoders&lt;/li&gt;
&lt;li&gt;translation = projection&lt;/li&gt;
&lt;li&gt;thought = LLM&lt;/li&gt;
&lt;li&gt;expression = output&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-example-systems-conceptual&#34;&gt;ğŸ”„ Example Systems (Conceptual)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Input&lt;/th&gt;
&lt;th&gt;Output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Image Captioning&lt;/td&gt;
&lt;td&gt;Image&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VQA&lt;/td&gt;
&lt;td&gt;Image + Question&lt;/td&gt;
&lt;td&gt;Answer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ASR&lt;/td&gt;
&lt;td&gt;Audio&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video QA&lt;/td&gt;
&lt;td&gt;Video + Text&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Doc QA&lt;/td&gt;
&lt;td&gt;PDF&lt;/td&gt;
&lt;td&gt;Answer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-common-misconceptions&#34;&gt;âš ï¸ Common Misconceptions&lt;/h2&gt;
&lt;h3 id=&#34;-myth-1-bigger--better&#34;&gt;âŒ Myth 1: Bigger = Better&lt;/h3&gt;
&lt;p&gt;Truth:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Alignment quality &amp;gt; parameter count&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-myth-2-multimodal-means-end-to-end-training&#34;&gt;âŒ Myth 2: Multimodal means end-to-end training&lt;/h3&gt;
&lt;p&gt;Truth:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most systems are &lt;strong&gt;composed + aligned&lt;/strong&gt;, not trained from scratch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-myth-3-vision-models-can-reason&#34;&gt;âŒ Myth 3: Vision models can reason&lt;/h3&gt;
&lt;p&gt;Truth:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reasoning happens in &lt;strong&gt;language space&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--conceptual&#34;&gt;ğŸ§ª Knowledge Check â€” Conceptual&lt;/h2&gt;
&lt;h3 id=&#34;q1-objective&#34;&gt;Q1 (Objective)&lt;/h3&gt;
&lt;p&gt;What is the primary role of an LLM in a multimodal system?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Reasoning and generation across aligned modalities.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2-true--false&#34;&gt;Q2 (True / False)&lt;/h3&gt;
&lt;p&gt;Multimodal LLMs require a separate reasoning engine for each modality.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-mathematical-intuition-lightweight&#34;&gt;ğŸ§  Mathematical Intuition (Lightweight)&lt;/h2&gt;
&lt;p&gt;Each modality produces vectors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Image â†’ â„â¿
Audio â†’ â„áµ
Text  â†’ â„áµ

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Projection learns:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
â„â¿, â„áµ â†’ â„áµ

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the LLM can attend uniformly.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Alignment = learning a shared geometry of meaning&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--alignment&#34;&gt;ğŸ§ª Knowledge Check â€” Alignment&lt;/h2&gt;
&lt;h3 id=&#34;q3-mcq&#34;&gt;Q3 (MCQ)&lt;/h3&gt;
&lt;p&gt;What happens if embeddings are poorly aligned?&lt;/p&gt;
&lt;p&gt;A) Slower inference&lt;br&gt;
B) Higher memory usage&lt;br&gt;
C) Hallucinations&lt;br&gt;
D) Overfitting&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) Hallucinations&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-multimodal-llms-emerged-now&#34;&gt;ğŸ§  Why Multimodal LLMs Emerged &lt;em&gt;Now&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Three forces converged:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Foundation models&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cheap large-scale pretraining&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformers with attention&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Multimodality was &lt;em&gt;impossible&lt;/em&gt; without scalable language reasoning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-beginner--advanced-progression&#34;&gt;ğŸŒ± Beginner â†’ Advanced Progression&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Level&lt;/th&gt;
&lt;th&gt;Focus&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Beginner&lt;/td&gt;
&lt;td&gt;What is multimodal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Intermediate&lt;/td&gt;
&lt;td&gt;Architecture &amp;amp; alignment&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Advanced&lt;/td&gt;
&lt;td&gt;Training strategies, evaluation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Expert&lt;/td&gt;
&lt;td&gt;Agents, reasoning, ethics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This course follows &lt;strong&gt;that arc intentionally&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--systems-thinking&#34;&gt;ğŸ§ª Knowledge Check â€” Systems Thinking&lt;/h2&gt;
&lt;h3 id=&#34;q4-objective&#34;&gt;Q4 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is language used as the shared interface instead of vision?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because language is symbolic, compositional, and supports reasoning.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-human-centered-perspective&#34;&gt;ğŸ§  Human-Centered Perspective&lt;/h2&gt;
&lt;p&gt;Humans:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;perceive multimodally&lt;/li&gt;
&lt;li&gt;reason symbolically&lt;/li&gt;
&lt;li&gt;communicate linguistically&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multimodal LLMs mirror this &lt;strong&gt;cognitive pipeline&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;But remember:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Understanding â‰  Consciousness&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-limitations-be-honest&#34;&gt;âš ï¸ Limitations (Be Honest)&lt;/h2&gt;
&lt;p&gt;Multimodal LLMs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hallucinate&lt;/li&gt;
&lt;li&gt;inherit bias&lt;/li&gt;
&lt;li&gt;lack grounding&lt;/li&gt;
&lt;li&gt;do not &lt;em&gt;understand&lt;/em&gt; like humans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Awareness is responsibility.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--ethics-awareness&#34;&gt;ğŸ§ª Knowledge Check â€” Ethics Awareness&lt;/h2&gt;
&lt;h3 id=&#34;q5-true--false&#34;&gt;Q5 (True / False)&lt;/h3&gt;
&lt;p&gt;Multimodal LLMs truly understand the world.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False â€” they model correlations, not lived experience.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;âœ… Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Multimodal LLMs unify perception + reasoning&lt;/li&gt;
&lt;li&gt;Language is the cognitive backbone&lt;/li&gt;
&lt;li&gt;Alignment is more important than scale&lt;/li&gt;
&lt;li&gt;Understanding systems &amp;gt; using tools&lt;/li&gt;
&lt;li&gt;Responsibility is part of intelligence&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection-very-important&#34;&gt;ğŸŒ Final Reflection (Very Important)&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If machines can see and hear, what remains uniquely human?&lt;/summary&gt;
  &lt;p&gt;Values, wisdom, empathy, responsibility.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 02 â€” How to Think Like a Multimodal System Designer</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-02-thinking-like-multimodal-architect/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-02-thinking-like-multimodal-architect/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~3â€“4 hours (core system-design lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-matters&#34;&gt;ğŸŒ Why This Lecture Matters&lt;/h2&gt;
&lt;p&gt;Most people learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“¦ APIs&lt;/li&gt;
&lt;li&gt;ğŸ§© libraries&lt;/li&gt;
&lt;li&gt;âš™ï¸ frameworks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Very few learn:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;How to design an intelligent system from first principles.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This lecture transforms you from:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;model user&lt;/em&gt; â†’ &lt;strong&gt;multimodal system architect&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-architects-mindset&#34;&gt;ğŸ§  The Architectâ€™s Mindset&lt;/h2&gt;
&lt;p&gt;A multimodal architect does &lt;strong&gt;not&lt;/strong&gt; ask first:&lt;/p&gt;
&lt;p&gt;âŒ â€œWhich model should I use?â€&lt;/p&gt;
&lt;p&gt;They ask:&lt;/p&gt;
&lt;p&gt;âœ… What problem am I solving?&lt;br&gt;
âœ… What information is available?&lt;br&gt;
âœ… What modality carries the signal?&lt;br&gt;
âœ… What errors are acceptable?&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-1-start-from-the-task-not-the-model&#34;&gt;ğŸ—ï¸ First Principle #1: Start From the Task, Not the Model&lt;/h2&gt;
&lt;p&gt;Every intelligent system begins with a &lt;strong&gt;task definition&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;ask-these-questions-always&#34;&gt;Ask These Questions (Always)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;What is the &lt;strong&gt;input&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;What is the &lt;strong&gt;output&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;What transformation is required?&lt;/li&gt;
&lt;li&gt;What failure is unacceptable?&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Task:&lt;/strong&gt; Medical image diagnosis&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aspect&lt;/th&gt;
&lt;th&gt;Decision&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Input&lt;/td&gt;
&lt;td&gt;Image + text report&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Output&lt;/td&gt;
&lt;td&gt;Text explanation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Risk&lt;/td&gt;
&lt;td&gt;False negative&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Requirement&lt;/td&gt;
&lt;td&gt;Human-in-the-loop&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--task-thinking&#34;&gt;ğŸ§ª Knowledge Check â€” Task Thinking&lt;/h2&gt;
&lt;h3 id=&#34;q1-objective&#34;&gt;Q1 (Objective)&lt;/h3&gt;
&lt;p&gt;Why should task definition come before model selection?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because architecture depends on constraints, risk, and signal â€” not tools.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-2-modalities-are-information-channels&#34;&gt;ğŸ§  First Principle #2: Modalities Are Information Channels&lt;/h2&gt;
&lt;p&gt;Each modality has &lt;strong&gt;strengths and weaknesses&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Modality&lt;/th&gt;
&lt;th&gt;Strength&lt;/th&gt;
&lt;th&gt;Weakness&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;td&gt;No raw perception&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image&lt;/td&gt;
&lt;td&gt;Spatial&lt;/td&gt;
&lt;td&gt;No abstraction&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Audio&lt;/td&gt;
&lt;td&gt;Emotion, tone&lt;/td&gt;
&lt;td&gt;Noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video&lt;/td&gt;
&lt;td&gt;Time&lt;/td&gt;
&lt;td&gt;Cost &amp;amp; complexity&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Good design uses the minimum modality required.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-over-engineering-trap-very-common&#34;&gt;âŒ Over-Engineering Trap (Very Common)&lt;/h2&gt;
&lt;p&gt;Many beginners think:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œMore modalities = smarter AIâ€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reality:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;More modalities = more noise, cost, and failure modes&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--modalities&#34;&gt;ğŸ§ª Knowledge Check â€” Modalities&lt;/h2&gt;
&lt;h3 id=&#34;q2-mcq&#34;&gt;Q2 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which modality is the most expensive to annotate?&lt;/p&gt;
&lt;p&gt;A) Text&lt;br&gt;
B) Image&lt;br&gt;
C) Audio&lt;br&gt;
D) Video&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;D) Video&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-3-separate-perception-from-reasoning&#34;&gt;ğŸ§  First Principle #3: Separate Perception from Reasoning&lt;/h2&gt;
&lt;p&gt;One of the &lt;strong&gt;most important design rules&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;correct-separation&#34;&gt;Correct Separation&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
Perception â†’ Representation â†’ Reasoning â†’ Action

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Perception = encoders&lt;/li&gt;
&lt;li&gt;Reasoning = LLM&lt;/li&gt;
&lt;li&gt;Action = output or tool use&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h3&gt;
&lt;p&gt;If you mix everything:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;debugging becomes impossible&lt;/li&gt;
&lt;li&gt;errors propagate&lt;/li&gt;
&lt;li&gt;evaluation is unclear&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Clean boundaries create reliable systems.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--architecture&#34;&gt;ğŸ§ª Knowledge Check â€” Architecture&lt;/h2&gt;
&lt;h3 id=&#34;q3-true--false&#34;&gt;Q3 (True / False)&lt;/h3&gt;
&lt;p&gt;Vision models should handle logical reasoning.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-4-alignment-is-the-bottleneck&#34;&gt;ğŸ§  First Principle #4: Alignment Is the Bottleneck&lt;/h2&gt;
&lt;p&gt;Alignment answers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;How does non-language data become â€œthinkableâ€?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Bad alignment â†’&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hallucinations&lt;/li&gt;
&lt;li&gt;irrelevant answers&lt;/li&gt;
&lt;li&gt;false confidence&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Good alignment â†’&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reasoning&lt;/li&gt;
&lt;li&gt;grounding&lt;/li&gt;
&lt;li&gt;generalization&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-alignment-design-choices&#34;&gt;ğŸ§© Alignment Design Choices&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;When to Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear projection&lt;/td&gt;
&lt;td&gt;Simple tasks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MLP&lt;/td&gt;
&lt;td&gt;Moderate complexity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cross-attention&lt;/td&gt;
&lt;td&gt;High alignment need&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Q-Former&lt;/td&gt;
&lt;td&gt;Vision-language fusion&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--alignment&#34;&gt;ğŸ§ª Knowledge Check â€” Alignment&lt;/h2&gt;
&lt;h3 id=&#34;q4-mcq&#34;&gt;Q4 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which component most directly affects hallucination?&lt;/p&gt;
&lt;p&gt;A) Tokenizer&lt;br&gt;
B) Alignment layer&lt;br&gt;
C) GPU size&lt;br&gt;
D) Dataset size&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;B) Alignment layer&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-5-think-in-pipelines-not-models&#34;&gt;ğŸ§  First Principle #5: Think in Pipelines, Not Models&lt;/h2&gt;
&lt;p&gt;Architects think in &lt;strong&gt;pipelines&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;example-image-question-answering&#34;&gt;Example: Image Question Answering&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
Image â†’ Vision Encoder
Question â†’ Text Encoder
â†“
Alignment
â†“
LLM
â†“
Answer

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each box is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;replaceable&lt;/li&gt;
&lt;li&gt;testable&lt;/li&gt;
&lt;li&gt;improvable&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--pipeline-thinking&#34;&gt;ğŸ§ª Knowledge Check â€” Pipeline Thinking&lt;/h2&gt;
&lt;h3 id=&#34;q5-objective&#34;&gt;Q5 (Objective)&lt;/h3&gt;
&lt;p&gt;Why should components be modular?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To allow debugging, replacement, and independent improvement.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-beginner--advanced-design-levels&#34;&gt;ğŸ§  Beginner â†’ Advanced Design Levels&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Level&lt;/th&gt;
&lt;th&gt;Focus&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Beginner&lt;/td&gt;
&lt;td&gt;Single modality&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Intermediate&lt;/td&gt;
&lt;td&gt;Multimodal fusion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Advanced&lt;/td&gt;
&lt;td&gt;RAG + tools&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Expert&lt;/td&gt;
&lt;td&gt;Agents + feedback loops&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You &lt;strong&gt;do not&lt;/strong&gt; jump levels.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-case-study-1--image-captioning&#34;&gt;ğŸ§  Case Study 1 â€” Image Captioning&lt;/h2&gt;
&lt;h3 id=&#34;design-decision&#34;&gt;Design Decision&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Choice&lt;/th&gt;
&lt;th&gt;Reason&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Frozen vision encoder&lt;/td&gt;
&lt;td&gt;Stability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Small projection&lt;/td&gt;
&lt;td&gt;Efficiency&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pretrained LLM&lt;/td&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;This works because &lt;strong&gt;task complexity is low&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-case-study-2--medical-vqa-high-risk&#34;&gt;ğŸ§  Case Study 2 â€” Medical VQA (High Risk)&lt;/h2&gt;
&lt;p&gt;Changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HITL required&lt;/li&gt;
&lt;li&gt;Conservative decoding&lt;/li&gt;
&lt;li&gt;Explanation mandatory&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Risk changes architecture.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--risk-awareness&#34;&gt;ğŸ§ª Knowledge Check â€” Risk Awareness&lt;/h2&gt;
&lt;h3 id=&#34;q6-true--false&#34;&gt;Q6 (True / False)&lt;/h3&gt;
&lt;p&gt;The same architecture fits both chatbots and medical diagnosis.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-first-principle-6-evaluation-shapes-design&#34;&gt;ğŸ§  First Principle #6: Evaluation Shapes Design&lt;/h2&gt;
&lt;p&gt;If you canâ€™t measure it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;You canâ€™t trust it.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Evaluation informs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;architecture choice&lt;/li&gt;
&lt;li&gt;data needs&lt;/li&gt;
&lt;li&gt;alignment method&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(We go deep in Lecture 09.)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-thinking-beyond-accuracy&#34;&gt;ğŸ§  Thinking Beyond Accuracy&lt;/h2&gt;
&lt;p&gt;Architects evaluate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robustness&lt;/li&gt;
&lt;li&gt;calibration&lt;/li&gt;
&lt;li&gt;failure modes&lt;/li&gt;
&lt;li&gt;ethical impact&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--evaluation-thinking&#34;&gt;ğŸ§ª Knowledge Check â€” Evaluation Thinking&lt;/h2&gt;
&lt;h3 id=&#34;q7-objective&#34;&gt;Q7 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is accuracy alone insufficient?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because it hides bias, uncertainty, and rare failures.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-architects-checklist-very-practical&#34;&gt;ğŸ§  Architectâ€™s Checklist (Very Practical)&lt;/h2&gt;
&lt;p&gt;Before coding, ask:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Is this modality necessary?&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Is language the reasoning layer?&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Is alignment explicit?&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Are risks identified?&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Can humans intervene?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-human-centered-design-core-philosophy&#34;&gt;ğŸŒ± Human-Centered Design (Core Philosophy)&lt;/h2&gt;
&lt;p&gt;Multimodal AI should:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;assist humans&lt;/li&gt;
&lt;li&gt;explain decisions&lt;/li&gt;
&lt;li&gt;accept correction&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Architects design for humility, not dominance.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-knowledge-check--reflection&#34;&gt;ğŸ§ª Final Knowledge Check â€” Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;What separates an AI architect from a model user?&lt;/summary&gt;
  &lt;p&gt;System-level thinking, responsibility, and first-principle design.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;âœ… Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Architects start from tasks&lt;/li&gt;
&lt;li&gt;Modalities are information channels&lt;/li&gt;
&lt;li&gt;Alignment is critical&lt;/li&gt;
&lt;li&gt;Pipelines beat monoliths&lt;/li&gt;
&lt;li&gt;Ethics influence architecture&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;If AI systems fail, who is responsible?&lt;/summary&gt;
  &lt;p&gt;The humans who designed them.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 03 â€” Training Paradigms: Pretraining, Fine-tuning, and Training from Scratch</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-03-training-paradigms/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-03-training-paradigms/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~3â€“4 hours (core learning lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-matters&#34;&gt;ğŸŒ Why This Lecture Matters&lt;/h2&gt;
&lt;p&gt;Every modern AI system answers &lt;strong&gt;one critical question&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;How was this intelligence created?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Understanding &lt;em&gt;training paradigms&lt;/em&gt; means understanding:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;capability&lt;/li&gt;
&lt;li&gt;limitation&lt;/li&gt;
&lt;li&gt;cost&lt;/li&gt;
&lt;li&gt;risk&lt;/li&gt;
&lt;li&gt;ethics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This lecture teaches you &lt;strong&gt;how intelligence is shaped&lt;/strong&gt;, not just deployed.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-three-ways-machines-learn&#34;&gt;ğŸ§  The Three Ways Machines Learn&lt;/h2&gt;
&lt;p&gt;All modern multimodal systems are trained using &lt;strong&gt;one (or more)&lt;/strong&gt; of these paradigms:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ğŸ§± Training from Scratch&lt;/li&gt;
&lt;li&gt;ğŸ”§ Fine-tuning&lt;/li&gt;
&lt;li&gt;ğŸ§  Pretraining (Foundation Models)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-big-picture-comparison&#34;&gt;ğŸ§© Big Picture Comparison&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Paradigm&lt;/th&gt;
&lt;th&gt;Data Size&lt;/th&gt;
&lt;th&gt;Cost&lt;/th&gt;
&lt;th&gt;Flexibility&lt;/th&gt;
&lt;th&gt;Risk&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Scratch&lt;/td&gt;
&lt;td&gt;Massive&lt;/td&gt;
&lt;td&gt;ğŸ’°ğŸ’°ğŸ’°ğŸ’°&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Very High&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pretraining&lt;/td&gt;
&lt;td&gt;Huge&lt;/td&gt;
&lt;td&gt;ğŸ’°ğŸ’°ğŸ’°&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fine-tuning&lt;/td&gt;
&lt;td&gt;Smallâ€“Medium&lt;/td&gt;
&lt;td&gt;ğŸ’°&lt;/td&gt;
&lt;td&gt;Lowâ€“Medium&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Most real systems use pretrained + fine-tuned models.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-paradigm-1--training-from-scratch&#34;&gt;ğŸ§± Paradigm 1 â€” Training From Scratch&lt;/h2&gt;
&lt;h3 id=&#34;what-it-means&#34;&gt;What It Means&lt;/h3&gt;
&lt;p&gt;Training &lt;strong&gt;all weights from random initialization&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;No prior knowledge.
No shortcuts.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;when-it-makes-sense-rare&#34;&gt;When It Makes Sense (Rare)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;New modality (e.g., brain signals)&lt;/li&gt;
&lt;li&gt;Fundamental research&lt;/li&gt;
&lt;li&gt;Extreme domain shift&lt;/li&gt;
&lt;li&gt;National-scale infrastructure&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-its-dangerous&#34;&gt;Why Itâ€™s Dangerous&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Requires massive data&lt;/li&gt;
&lt;li&gt;Requires massive compute&lt;/li&gt;
&lt;li&gt;High chance of bias&lt;/li&gt;
&lt;li&gt;Easy to fail silently&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Training from scratch is not bravery â€” itâ€™s responsibility.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--scratch-training&#34;&gt;ğŸ§ª Knowledge Check â€” Scratch Training&lt;/h2&gt;
&lt;h3 id=&#34;q1-true--false&#34;&gt;Q1 (True / False)&lt;/h3&gt;
&lt;p&gt;Training from scratch is the best choice for most applications.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2-objective&#34;&gt;Q2 (Objective)&lt;/h3&gt;
&lt;p&gt;Name one valid reason to train from scratch.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;When no pretrained model exists for the modality or domain.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-paradigm-2--pretraining-foundation-models&#34;&gt;ğŸ§  Paradigm 2 â€” Pretraining (Foundation Models)&lt;/h2&gt;
&lt;h3 id=&#34;what-is-pretraining&#34;&gt;What Is Pretraining?&lt;/h3&gt;
&lt;p&gt;Learning &lt;strong&gt;general-purpose representations&lt;/strong&gt; from massive unlabeled or weakly labeled data.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT (text)&lt;/li&gt;
&lt;li&gt;CLIP (imageâ€“text)&lt;/li&gt;
&lt;li&gt;Whisper (audio)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-pretraining-works&#34;&gt;Why Pretraining Works&lt;/h3&gt;
&lt;p&gt;Because the world is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;repetitive&lt;/li&gt;
&lt;li&gt;structured&lt;/li&gt;
&lt;li&gt;statistically learnable&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Pretraining captures &lt;strong&gt;world regularities&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;multimodal-pretraining&#34;&gt;Multimodal Pretraining&lt;/h3&gt;
&lt;p&gt;Typical objective:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
(Image, Text) â†’ Predict missing modality

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates &lt;strong&gt;cross-modal alignment&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--pretraining&#34;&gt;ğŸ§ª Knowledge Check â€” Pretraining&lt;/h2&gt;
&lt;h3 id=&#34;q3-mcq&#34;&gt;Q3 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is the main goal of pretraining?&lt;/p&gt;
&lt;p&gt;A) Task accuracy&lt;br&gt;
B) Memorization&lt;br&gt;
C) General representation learning&lt;br&gt;
D) Deployment speed&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) General representation learning&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-paradigm-3--fine-tuning&#34;&gt;ğŸ”§ Paradigm 3 â€” Fine-tuning&lt;/h2&gt;
&lt;h3 id=&#34;what-is-fine-tuning&#34;&gt;What Is Fine-tuning?&lt;/h3&gt;
&lt;p&gt;Adapting a pretrained model to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a specific task&lt;/li&gt;
&lt;li&gt;a specific domain&lt;/li&gt;
&lt;li&gt;a specific behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;types-of-fine-tuning&#34;&gt;Types of Fine-tuning&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Full fine-tuning&lt;/td&gt;
&lt;td&gt;Update all weights&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Partial&lt;/td&gt;
&lt;td&gt;Update some layers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PEFT&lt;/td&gt;
&lt;td&gt;LoRA, adapters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Instruction tuning&lt;/td&gt;
&lt;td&gt;Align behavior&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-fine-tuning-is-powerful&#34;&gt;Why Fine-tuning Is Powerful&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Low data requirement&lt;/li&gt;
&lt;li&gt;Low compute&lt;/li&gt;
&lt;li&gt;Fast iteration&lt;/li&gt;
&lt;li&gt;Safer behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Fine-tuning is &lt;strong&gt;how most intelligence is specialized&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--fine-tuning&#34;&gt;ğŸ§ª Knowledge Check â€” Fine-tuning&lt;/h2&gt;
&lt;h3 id=&#34;q4-true--false&#34;&gt;Q4 (True / False)&lt;/h3&gt;
&lt;p&gt;Fine-tuning always requires large datasets.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5-objective&#34;&gt;Q5 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is PEFT (e.g., LoRA) popular?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It reduces memory and compute while preserving performance.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-pretraining-vs-fine-tuning-mental-model&#34;&gt;ğŸ§  Pretraining vs Fine-tuning (Mental Model)&lt;/h2&gt;
&lt;p&gt;Think of a human:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretraining = education&lt;/li&gt;
&lt;li&gt;Fine-tuning = job training&lt;/li&gt;
&lt;li&gt;Scratch = growing up alone on an island&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-multimodal-specific-considerations&#34;&gt;ğŸ§  Multimodal-Specific Considerations&lt;/h2&gt;
&lt;h3 id=&#34;what-can-be-fine-tuned&#34;&gt;What Can Be Fine-tuned?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Encoders&lt;/li&gt;
&lt;li&gt;Projection layers&lt;/li&gt;
&lt;li&gt;LLM&lt;/li&gt;
&lt;li&gt;Output heads&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;common-strategy-best-practice&#34;&gt;Common Strategy (Best Practice)&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Strategy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Encoder&lt;/td&gt;
&lt;td&gt;Freeze&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Projection&lt;/td&gt;
&lt;td&gt;Train&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LLM&lt;/td&gt;
&lt;td&gt;PEFT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Head&lt;/td&gt;
&lt;td&gt;Train&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Alignment layers are usually the sweet spot.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--multimodal-strategy&#34;&gt;ğŸ§ª Knowledge Check â€” Multimodal Strategy&lt;/h2&gt;
&lt;h3 id=&#34;q6-mcq&#34;&gt;Q6 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which component is most commonly fine-tuned first?&lt;/p&gt;
&lt;p&gt;A) Tokenizer&lt;br&gt;
B) Vision encoder&lt;br&gt;
C) Projection layer&lt;br&gt;
D) Dataset&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) Projection layer&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-overfitting--catastrophic-forgetting&#34;&gt;âš ï¸ Overfitting &amp;amp; Catastrophic Forgetting&lt;/h2&gt;
&lt;p&gt;Fine-tuning risks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;forgetting general knowledge&lt;/li&gt;
&lt;li&gt;over-specialization&lt;/li&gt;
&lt;li&gt;bias amplification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mitigations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;low learning rate&lt;/li&gt;
&lt;li&gt;freezing layers&lt;/li&gt;
&lt;li&gt;mixed data&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-paradigm-comparison-by-task&#34;&gt;ğŸ§  Paradigm Comparison by Task&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Best Paradigm&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Image captioning&lt;/td&gt;
&lt;td&gt;Pretrained + light FT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Medical QA&lt;/td&gt;
&lt;td&gt;FT + HITL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;New sensor modality&lt;/td&gt;
&lt;td&gt;Scratch&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Internal company data&lt;/td&gt;
&lt;td&gt;RAG or FT&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--decision-making&#34;&gt;ğŸ§ª Knowledge Check â€” Decision Making&lt;/h2&gt;
&lt;h3 id=&#34;q7-objective&#34;&gt;Q7 (Objective)&lt;/h3&gt;
&lt;p&gt;Why might RAG be preferred over fine-tuning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;When knowledge changes frequently or data cannot be embedded in weights.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-training-is-not-just-optimization&#34;&gt;ğŸ§  Training Is Not Just Optimization&lt;/h2&gt;
&lt;p&gt;Training choices encode:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;values&lt;/li&gt;
&lt;li&gt;assumptions&lt;/li&gt;
&lt;li&gt;power&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Who chooses the data chooses the behavior.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ethical-considerations&#34;&gt;ğŸŒ± Ethical Considerations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Pretraining data bias&lt;/li&gt;
&lt;li&gt;Fine-tuning reinforcement of norms&lt;/li&gt;
&lt;li&gt;Scratch training without safeguards&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ethics begins &lt;strong&gt;before training starts&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--ethics&#34;&gt;ğŸ§ª Knowledge Check â€” Ethics&lt;/h2&gt;
&lt;h3 id=&#34;q8-true--false&#34;&gt;Q8 (True / False)&lt;/h3&gt;
&lt;p&gt;Bias can only be fixed during deployment.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False â€” bias enters during data and training.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-architects-decision-tree-practical&#34;&gt;ğŸ§  Architectâ€™s Decision Tree (Practical)&lt;/h2&gt;
&lt;p&gt;Ask:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Is there a pretrained model?&lt;/li&gt;
&lt;li&gt;Is the domain stable?&lt;/li&gt;
&lt;li&gt;Is data private?&lt;/li&gt;
&lt;li&gt;Is behavior critical?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then choose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAG&lt;/li&gt;
&lt;li&gt;Fine-tuning&lt;/li&gt;
&lt;li&gt;Scratch (rare)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;âœ… Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Training defines intelligence&lt;/li&gt;
&lt;li&gt;Pretraining builds foundations&lt;/li&gt;
&lt;li&gt;Fine-tuning specializes behavior&lt;/li&gt;
&lt;li&gt;Scratch training is exceptional&lt;/li&gt;
&lt;li&gt;Ethics is embedded in data&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;If a model learns from biased data, who is accountable?&lt;/summary&gt;
  &lt;p&gt;The humans who selected, curated, and approved the data.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 04 â€” Audio â†” Text â†” Reasoning: Teaching Machines to Listen</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-04-audio-text/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-04-audio-text/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“5 hours (theory + code)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-audiotext-matters&#34;&gt;ğŸŒ Why Audioâ€“Text Matters&lt;/h2&gt;
&lt;p&gt;Sound is the &lt;strong&gt;first interface of intelligence&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Before writing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;humans listened&lt;/li&gt;
&lt;li&gt;learned tone&lt;/li&gt;
&lt;li&gt;sensed emotion&lt;/li&gt;
&lt;li&gt;reacted in real time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Audioâ€“Text systems allow machines to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transcribe speech&lt;/li&gt;
&lt;li&gt;understand intent&lt;/li&gt;
&lt;li&gt;reason about meaning&lt;/li&gt;
&lt;li&gt;respond naturally&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If vision gives machines eyes, audio gives them ears.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-an-audiotext-multimodal-system&#34;&gt;ğŸ§  What Is an Audioâ€“Text Multimodal System?&lt;/h2&gt;
&lt;p&gt;An &lt;strong&gt;Audioâ€“Text-to-Text&lt;/strong&gt; system takes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§ audio input (speech, sound)&lt;/li&gt;
&lt;li&gt;ğŸ§  converts it to representations&lt;/li&gt;
&lt;li&gt;âœï¸ produces text output&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Speech-to-text (ASR)&lt;/li&gt;
&lt;li&gt;Audio question answering&lt;/li&gt;
&lt;li&gt;Voice assistants&lt;/li&gt;
&lt;li&gt;Meeting summarization&lt;/li&gt;
&lt;li&gt;Emotion-aware chatbots&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-high-level-architecture&#34;&gt;ğŸ§© High-Level Architecture&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Raw Audio
â†“
Audio Encoder (Whisper / Wav2Vec)
â†“
Projection / Alignment
â†“
LLM (Reasoning)
â†“
Text Output

&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Audio models perceive. LLMs reason.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-understanding-audio-first-principles&#34;&gt;ğŸ§ Understanding Audio (First Principles)&lt;/h2&gt;
&lt;p&gt;Audio is a &lt;strong&gt;time-domain signal&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Amplitude vs Time

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Key challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;noise&lt;/li&gt;
&lt;li&gt;accents&lt;/li&gt;
&lt;li&gt;speed variation&lt;/li&gt;
&lt;li&gt;emotion&lt;/li&gt;
&lt;li&gt;silence&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-audio-is-harder-than-text&#34;&gt;ğŸ§  Why Audio Is Harder Than Text&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aspect&lt;/th&gt;
&lt;th&gt;Audio&lt;/th&gt;
&lt;th&gt;Text&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Noise&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ambiguity&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Temporal&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Emotion&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Rare&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Audio carries meaning beyond words.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--fundamentals&#34;&gt;ğŸ§ª Knowledge Check â€” Fundamentals&lt;/h2&gt;
&lt;h3 id=&#34;q1-objective&#34;&gt;Q1 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is audio considered a high-entropy modality?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because it varies continuously in time, tone, speed, and noise.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-audio-tasks&#34;&gt;ğŸ§  Core Audio Tasks&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ASR&lt;/td&gt;
&lt;td&gt;Speech â†’ Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Audio QA&lt;/td&gt;
&lt;td&gt;Audio + Question â†’ Answer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Emotion Recognition&lt;/td&gt;
&lt;td&gt;Audio â†’ Emotion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Speaker ID&lt;/td&gt;
&lt;td&gt;Audio â†’ Identity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;td&gt;Audio â†’ Meaning&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This lecture focuses on &lt;strong&gt;ASR + reasoning&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-audio-encoders-the-ears&#34;&gt;ğŸ§ Audio Encoders (The Ears)&lt;/h2&gt;
&lt;p&gt;Popular models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Whisper&lt;/strong&gt; (OpenAI)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wav2Vec 2.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;HuBERT&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They convert waveform â†’ embeddings.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-encoder-output&#34;&gt;ğŸ§  Encoder Output&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Audio waveform â†’ Frame-level embeddings â†’ Sequence

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pooled&lt;/li&gt;
&lt;li&gt;projected&lt;/li&gt;
&lt;li&gt;aligned to language space&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--encoders&#34;&gt;ğŸ§ª Knowledge Check â€” Encoders&lt;/h2&gt;
&lt;h3 id=&#34;q2-mcq&#34;&gt;Q2 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which model is widely used for multilingual ASR?&lt;/p&gt;
&lt;p&gt;A) ResNet&lt;br&gt;
B) Whisper&lt;br&gt;
C) CLIP&lt;br&gt;
D) BERT&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;B) Whisper&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-lab-1--speech-to-text-with-whisper&#34;&gt;ğŸ Python Lab 1 â€” Speech-to-Text with Whisper&lt;/h2&gt;
&lt;h3 id=&#34;-install-dependencies&#34;&gt;ğŸ“¦ Install Dependencies&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install transformers accelerate torch torchaudio
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-load-model&#34;&gt;ğŸ§  Load Model&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import WhisperProcessor, WhisperForConditionalGeneration
import torchaudio

model_name = &amp;quot;openai/whisper-small&amp;quot;

processor = WhisperProcessor.from_pretrained(model_name)
model = WhisperForConditionalGeneration.from_pretrained(model_name)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-load-audio&#34;&gt;ğŸ§ Load Audio&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;waveform, sample_rate = torchaudio.load(&amp;quot;sample.wav&amp;quot;)

inputs = processor(
    waveform.squeeze(),
    sampling_rate=sample_rate,
    return_tensors=&amp;quot;pt&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-generate-text&#34;&gt;âœï¸ Generate Text&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;with torch.no_grad():
    predicted_ids = model.generate(inputs[&amp;quot;input_features&amp;quot;])

text = processor.batch_decode(
    predicted_ids,
    skip_special_tokens=True
)

print(text)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;ğŸ‰ You just built a speech-to-text system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--code-understanding&#34;&gt;ğŸ§ª Knowledge Check â€” Code Understanding&lt;/h2&gt;
&lt;h3 id=&#34;q3-objective&#34;&gt;Q3 (Objective)&lt;/h3&gt;
&lt;p&gt;What is the role of the processor in Whisper?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It converts raw audio into model-ready features and decodes outputs.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-adding-reasoning-with-an-llm&#34;&gt;ğŸ§  Adding Reasoning with an LLM&lt;/h2&gt;
&lt;p&gt;ASR alone is &lt;strong&gt;not intelligence&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We add an LLM to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;summarize&lt;/li&gt;
&lt;li&gt;answer questions&lt;/li&gt;
&lt;li&gt;extract intent&lt;/li&gt;
&lt;li&gt;reason&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-full-audiotext-reasoning-pipeline&#34;&gt;ğŸ— Full Audioâ€“Text Reasoning Pipeline&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Audio â†’ ASR â†’ Transcript â†’ Prompt â†’ LLM â†’ Answer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This separation is &lt;strong&gt;architecturally clean&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-lab-2--audio-qa-with-llm&#34;&gt;ğŸ Python Lab 2 â€” Audio QA with LLM&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoTokenizer, AutoModelForCausalLM

llm_name = &amp;quot;meta-llama/Llama-3-8B-Instruct&amp;quot;

tokenizer = AutoTokenizer.from_pretrained(llm_name)
llm = AutoModelForCausalLM.from_pretrained(llm_name)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-prompting-with-transcript&#34;&gt;ğŸ§  Prompting with Transcript&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;transcript = text[0]

prompt = f&amp;quot;&amp;quot;&amp;quot;
You are an assistant.
Audio transcript:
{transcript}

Question:
What is the main topic of this audio?
&amp;quot;&amp;quot;&amp;quot;

inputs = tokenizer(prompt, return_tensors=&amp;quot;pt&amp;quot;)

outputs = llm.generate(**inputs, max_new_tokens=100)

answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(answer)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--system-design&#34;&gt;ğŸ§ª Knowledge Check â€” System Design&lt;/h2&gt;
&lt;h3 id=&#34;q4-true--false&#34;&gt;Q4 (True / False)&lt;/h3&gt;
&lt;p&gt;ASR models alone can reason about audio content.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-audiotext-alignment-strategies&#34;&gt;ğŸ§  Audioâ€“Text Alignment Strategies&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Strategy&lt;/th&gt;
&lt;th&gt;Use Case&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Transcript-only&lt;/td&gt;
&lt;td&gt;Simple QA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Timestamp alignment&lt;/td&gt;
&lt;td&gt;Video/audio sync&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embedding fusion&lt;/td&gt;
&lt;td&gt;Emotion + content&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Multitask training&lt;/td&gt;
&lt;td&gt;Robust systems&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-common-failure-modes&#34;&gt;âš ï¸ Common Failure Modes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Background noise&lt;/li&gt;
&lt;li&gt;Code-switching&lt;/li&gt;
&lt;li&gt;Accents&lt;/li&gt;
&lt;li&gt;Domain-specific terms&lt;/li&gt;
&lt;li&gt;Emotional nuance loss&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Architects design for failure, not perfection.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--failures&#34;&gt;ğŸ§ª Knowledge Check â€” Failures&lt;/h2&gt;
&lt;h3 id=&#34;q5-mcq&#34;&gt;Q5 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which issue is hardest for ASR?&lt;/p&gt;
&lt;p&gt;A) Silence
B) Clear speech
C) Accents
D) Typed text&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) Accents&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-metrics&#34;&gt;ğŸ§  Evaluation Metrics&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;WER&lt;/td&gt;
&lt;td&gt;Word Error Rate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CER&lt;/td&gt;
&lt;td&gt;Character Error Rate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;QA Accuracy&lt;/td&gt;
&lt;td&gt;Reasoning quality&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Latency&lt;/td&gt;
&lt;td&gt;Real-time ability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--evaluation&#34;&gt;ğŸ§ª Knowledge Check â€” Evaluation&lt;/h2&gt;
&lt;h3 id=&#34;q6-objective&#34;&gt;Q6 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is low WER not sufficient for good QA?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because reasoning depends on semantic correctness, not just word accuracy.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ethics--audio-ai&#34;&gt;ğŸŒ± Ethics &amp;amp; Audio AI&lt;/h2&gt;
&lt;p&gt;Risks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;surveillance&lt;/li&gt;
&lt;li&gt;consent violation&lt;/li&gt;
&lt;li&gt;accent discrimination&lt;/li&gt;
&lt;li&gt;voice cloning&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Listening without permission is not intelligence.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--ethics&#34;&gt;ğŸ§ª Knowledge Check â€” Ethics&lt;/h2&gt;
&lt;h3 id=&#34;q7-true--false&#34;&gt;Q7 (True / False)&lt;/h3&gt;
&lt;p&gt;Audio AI systems should always inform users they are listening.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;True.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-human-in-the-loop-hitl&#34;&gt;ğŸ§  Human-in-the-Loop (HITL)&lt;/h2&gt;
&lt;p&gt;Best practice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;humans review transcripts&lt;/li&gt;
&lt;li&gt;corrections feed back&lt;/li&gt;
&lt;li&gt;confidence thresholds trigger review&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;âœ… Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Audio is rich but noisy&lt;/li&gt;
&lt;li&gt;Encoders perceive, LLMs reason&lt;/li&gt;
&lt;li&gt;Separation of ASR and reasoning is powerful&lt;/li&gt;
&lt;li&gt;Python pipelines are modular&lt;/li&gt;
&lt;li&gt;Ethics matter deeply for audio&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;If a machine understands your voice, what responsibility does it have?&lt;/summary&gt;
  &lt;p&gt;To respect consent, privacy, and human dignity.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 05 â€” Image â†” Text: Teaching Machines to See and Reason</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-05-image-text/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-05-image-text/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~5 hours (core multimodal lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-imagetext-is-so-important&#34;&gt;ğŸŒ Why Imageâ€“Text Is So Important&lt;/h2&gt;
&lt;p&gt;Vision is the &lt;strong&gt;dominant human sense&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Images contain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;spatial structure&lt;/li&gt;
&lt;li&gt;objects&lt;/li&gt;
&lt;li&gt;relationships&lt;/li&gt;
&lt;li&gt;context&lt;/li&gt;
&lt;li&gt;ambiguity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Teaching machines to &lt;strong&gt;see and explain&lt;/strong&gt; is one of the hardest problems in AI.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Seeing is easy. Understanding is hard.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-an-imagetext-multimodal-system&#34;&gt;ğŸ§  What Is an Imageâ€“Text Multimodal System?&lt;/h2&gt;
&lt;p&gt;An &lt;strong&gt;Imageâ€“Text-to-Text&lt;/strong&gt; system takes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ–¼ an image&lt;/li&gt;
&lt;li&gt;âœï¸ optional text (question, instruction)&lt;/li&gt;
&lt;li&gt;ğŸ§  performs reasoning&lt;/li&gt;
&lt;li&gt;ğŸ—£ produces text&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Image captioning&lt;/li&gt;
&lt;li&gt;Visual Question Answering (VQA)&lt;/li&gt;
&lt;li&gt;Image-based reasoning&lt;/li&gt;
&lt;li&gt;Medical imaging reports&lt;/li&gt;
&lt;li&gt;Autonomous perception explanations&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-high-level-architecture&#34;&gt;ğŸ§© High-Level Architecture&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Image
â†“
Vision Encoder (ViT / CNN)
â†“
Projection / Alignment
â†“
LLM (Reasoning)
â†“
Text Output

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Key idea:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Vision models perceive. LLMs reason.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-vision-alone-is-not-enough&#34;&gt;ğŸ§  Why Vision Alone Is Not Enough&lt;/h2&gt;
&lt;p&gt;Vision models are great at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;detecting patterns&lt;/li&gt;
&lt;li&gt;recognizing objects&lt;/li&gt;
&lt;li&gt;learning spatial features&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But they struggle with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;logic&lt;/li&gt;
&lt;li&gt;explanation&lt;/li&gt;
&lt;li&gt;abstraction&lt;/li&gt;
&lt;li&gt;causality&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Images do not reason. Language does.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--fundamentals&#34;&gt;ğŸ§ª Knowledge Check â€” Fundamentals&lt;/h2&gt;
&lt;h3 id=&#34;q1-true--false&#34;&gt;Q1 (True / False)&lt;/h3&gt;
&lt;p&gt;A vision model alone can perform logical reasoning.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-imagetext-tasks&#34;&gt;ğŸ§  Core Imageâ€“Text Tasks&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Input&lt;/th&gt;
&lt;th&gt;Output&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Image Captioning&lt;/td&gt;
&lt;td&gt;Image&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VQA&lt;/td&gt;
&lt;td&gt;Image + Question&lt;/td&gt;
&lt;td&gt;Answer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Grounding&lt;/td&gt;
&lt;td&gt;Image + Text&lt;/td&gt;
&lt;td&gt;Region&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image QA&lt;/td&gt;
&lt;td&gt;Image&lt;/td&gt;
&lt;td&gt;Explanation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCR + Reasoning&lt;/td&gt;
&lt;td&gt;Image&lt;/td&gt;
&lt;td&gt;Text + Answer&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This lecture focuses on &lt;strong&gt;captioning + VQA&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-vision-encoders-the-eyes&#34;&gt;ğŸ‘ Vision Encoders (The Eyes)&lt;/h2&gt;
&lt;p&gt;Popular encoders:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ResNet (CNN-based)&lt;/li&gt;
&lt;li&gt;Vision Transformer (ViT)&lt;/li&gt;
&lt;li&gt;Swin Transformer&lt;/li&gt;
&lt;li&gt;ConvNeXt&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They convert pixels â†’ embeddings.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-vision-encoder-output&#34;&gt;ğŸ§  Vision Encoder Output&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Image â†’ Patch embeddings â†’ Sequence of vectors

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each patch represents &lt;strong&gt;local visual semantics&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--vision&#34;&gt;ğŸ§ª Knowledge Check â€” Vision&lt;/h2&gt;
&lt;h3 id=&#34;q2-mcq&#34;&gt;Q2 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which model introduced patch-based vision processing?&lt;/p&gt;
&lt;p&gt;A) ResNet&lt;br&gt;
B) YOLO&lt;br&gt;
C) ViT&lt;br&gt;
D) AlexNet&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) ViT&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-alignment-problem-critical&#34;&gt;ğŸ§  The Alignment Problem (CRITICAL)&lt;/h2&gt;
&lt;p&gt;Vision embeddings â‰  language embeddings.&lt;/p&gt;
&lt;p&gt;Alignment answers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;How does a pixel become a word?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-alignment-strategies&#34;&gt;ğŸ§© Alignment Strategies&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Strategy&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Linear projection&lt;/td&gt;
&lt;td&gt;Simple, efficient&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MLP&lt;/td&gt;
&lt;td&gt;Nonlinear mapping&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cross-attention&lt;/td&gt;
&lt;td&gt;Deep fusion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Q-Former&lt;/td&gt;
&lt;td&gt;Learned query alignment&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Most failures come from poor alignment.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--alignment&#34;&gt;ğŸ§ª Knowledge Check â€” Alignment&lt;/h2&gt;
&lt;h3 id=&#34;q3-objective&#34;&gt;Q3 (Objective)&lt;/h3&gt;
&lt;p&gt;What is the purpose of the projection layer?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To map vision embeddings into the language embedding space.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-clip--a-foundational-breakthrough&#34;&gt;ğŸ§  CLIP â€” A Foundational Breakthrough&lt;/h2&gt;
&lt;p&gt;CLIP learned:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Image â†” Text similarity

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By contrastive learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;match image with correct caption&lt;/li&gt;
&lt;li&gt;separate mismatched pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Result:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Shared semantic space&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--clip&#34;&gt;ğŸ§ª Knowledge Check â€” CLIP&lt;/h2&gt;
&lt;h3 id=&#34;q4-mcq&#34;&gt;Q4 (MCQ)&lt;/h3&gt;
&lt;p&gt;What learning paradigm does CLIP use?&lt;/p&gt;
&lt;p&gt;A) Supervised classification&lt;br&gt;
B) Reinforcement learning&lt;br&gt;
C) Contrastive learning&lt;br&gt;
D) Autoencoding&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;C) Contrastive learning&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-lab-1--image-captioning-with-blip&#34;&gt;ğŸ Python Lab 1 â€” Image Captioning with BLIP&lt;/h2&gt;
&lt;h3 id=&#34;-install-dependencies&#34;&gt;ğŸ“¦ Install Dependencies&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install transformers pillow torch torchvision
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-load-model&#34;&gt;ğŸ§  Load Model&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image

model_name = &amp;quot;Salesforce/blip-image-captioning-base&amp;quot;

processor = BlipProcessor.from_pretrained(model_name)
model = BlipForConditionalGeneration.from_pretrained(model_name)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-load-image&#34;&gt;ğŸ–¼ Load Image&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;image = Image.open(&amp;quot;example.jpg&amp;quot;).convert(&amp;quot;RGB&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-generate-caption&#34;&gt;âœï¸ Generate Caption&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inputs = processor(image, return_tensors=&amp;quot;pt&amp;quot;)

out = model.generate(**inputs, max_new_tokens=50)

caption = processor.decode(out[0], skip_special_tokens=True)
print(caption)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;ğŸ‰ You just taught a machine to describe what it sees.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--code&#34;&gt;ğŸ§ª Knowledge Check â€” Code&lt;/h2&gt;
&lt;h3 id=&#34;q5-objective&#34;&gt;Q5 (Objective)&lt;/h3&gt;
&lt;p&gt;What role does the processor play in BLIP?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It preprocesses images and decodes generated tokens.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-adding-reasoning-with-an-llm&#34;&gt;ğŸ§  Adding Reasoning with an LLM&lt;/h2&gt;
&lt;p&gt;Captioning â‰  understanding.&lt;/p&gt;
&lt;p&gt;We add an LLM to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;answer questions&lt;/li&gt;
&lt;li&gt;infer relationships&lt;/li&gt;
&lt;li&gt;explain scenes&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-full-imagetext-reasoning-pipeline&#34;&gt;ğŸ— Full Imageâ€“Text Reasoning Pipeline&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Image â†’ Vision Encoder â†’ Alignment â†’ LLM â†’ Answer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Optional:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+ Question
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-lab-2--visual-question-answering&#34;&gt;ğŸ Python Lab 2 â€” Visual Question Answering&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;question = &amp;quot;What is the person doing in the image?&amp;quot;

prompt = f&amp;quot;&amp;quot;&amp;quot;
You are a vision-language assistant.
Image description:
{caption}

Question:
{question}
&amp;quot;&amp;quot;&amp;quot;

from transformers import AutoTokenizer, AutoModelForCausalLM

llm_name = &amp;quot;meta-llama/Llama-3-8B-Instruct&amp;quot;

tokenizer = AutoTokenizer.from_pretrained(llm_name)
llm = AutoModelForCausalLM.from_pretrained(llm_name)

inputs = tokenizer(prompt, return_tensors=&amp;quot;pt&amp;quot;)
outputs = llm.generate(**inputs, max_new_tokens=100)

answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(answer)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--reasoning&#34;&gt;ğŸ§ª Knowledge Check â€” Reasoning&lt;/h2&gt;
&lt;h3 id=&#34;q6-true--false&#34;&gt;Q6 (True / False)&lt;/h3&gt;
&lt;p&gt;Image captioning alone is sufficient for VQA.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-common-failure-modes&#34;&gt;ğŸ§  Common Failure Modes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Hallucinated objects&lt;/li&gt;
&lt;li&gt;Missed small details&lt;/li&gt;
&lt;li&gt;Incorrect spatial relations&lt;/li&gt;
&lt;li&gt;Cultural bias&lt;/li&gt;
&lt;li&gt;Overconfidence&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Seeing â‰  understanding â‰  truth&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--failures&#34;&gt;ğŸ§ª Knowledge Check â€” Failures&lt;/h2&gt;
&lt;h3 id=&#34;q7-mcq&#34;&gt;Q7 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which failure is most dangerous?&lt;/p&gt;
&lt;p&gt;A) Slow inference
B) Hallucinated objects
C) Low resolution
D) Long captions&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Correct Answer&lt;/summary&gt;
  &lt;p&gt;B) Hallucinated objects&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-metrics&#34;&gt;ğŸ§  Evaluation Metrics&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BLEU / CIDEr&lt;/td&gt;
&lt;td&gt;Caption quality&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VQA Accuracy&lt;/td&gt;
&lt;td&gt;QA correctness&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Human Eval&lt;/td&gt;
&lt;td&gt;Trust &amp;amp; clarity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Calibration&lt;/td&gt;
&lt;td&gt;Confidence reliability&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--evaluation&#34;&gt;ğŸ§ª Knowledge Check â€” Evaluation&lt;/h2&gt;
&lt;h3 id=&#34;q8-objective&#34;&gt;Q8 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is human evaluation important for vision-language tasks?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because correctness depends on semantics and human perception.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ethics-in-visionlanguage-ai&#34;&gt;ğŸŒ± Ethics in Visionâ€“Language AI&lt;/h2&gt;
&lt;p&gt;Risks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;surveillance&lt;/li&gt;
&lt;li&gt;facial recognition abuse&lt;/li&gt;
&lt;li&gt;bias in datasets&lt;/li&gt;
&lt;li&gt;privacy violation&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If a machine sees people, it must respect humanity.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-knowledge-check--ethics&#34;&gt;ğŸ§ª Knowledge Check â€” Ethics&lt;/h2&gt;
&lt;h3 id=&#34;q9-true--false&#34;&gt;Q9 (True / False)&lt;/h3&gt;
&lt;p&gt;Imageâ€“text systems can be ethically neutral.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;False.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-human-in-the-loop-best-practice&#34;&gt;ğŸ§  Human-in-the-Loop (Best Practice)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Human review for sensitive outputs&lt;/li&gt;
&lt;li&gt;Confidence thresholds&lt;/li&gt;
&lt;li&gt;Explainable responses&lt;/li&gt;
&lt;li&gt;Feedback-based refinement&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;âœ… Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Vision provides perception&lt;/li&gt;
&lt;li&gt;Language provides reasoning&lt;/li&gt;
&lt;li&gt;Alignment is the hardest part&lt;/li&gt;
&lt;li&gt;Python pipelines are modular&lt;/li&gt;
&lt;li&gt;Ethics is not optional&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-10&#34;&gt;
  &lt;summary&gt;If a machine describes a human incorrectly, who is harmed?&lt;/summary&gt;
  &lt;p&gt;The human â€” therefore responsibility lies with designers.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 06 â€” Videoâ€“Text Multimodal Intelligence</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-06-video-text/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-06-video-text/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“5 hours (advanced + practical lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-video-is-the-hardest-modality&#34;&gt;ğŸ¥ Why Video Is the Hardest Modality&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Video = Images + Time + Motion + Audio + Semantics&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Compared to text or images, video introduces:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;â± Temporal dependency&lt;/li&gt;
&lt;li&gt;ğŸ Motion understanding&lt;/li&gt;
&lt;li&gt;ğŸ”Š Optional audio synchronization&lt;/li&gt;
&lt;li&gt;ğŸ§  Long-range reasoning&lt;/li&gt;
&lt;li&gt;ğŸ’¾ Massive compute &amp;amp; memory cost&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;If you master &lt;strong&gt;Videoâ€“Text&lt;/strong&gt;, you understand &lt;em&gt;true multimodal intelligence&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-videotext-totext&#34;&gt;ğŸ§  What Is Videoâ€“Text-toâ€“Text?&lt;/h2&gt;
&lt;p&gt;Videoâ€“Text models map:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“¹ Video â†’ ğŸ“ Text&lt;/li&gt;
&lt;li&gt;ğŸ“¹ + â“ Question â†’ âœï¸ Answer&lt;/li&gt;
&lt;li&gt;ğŸ“¹ + ğŸ—£ Prompt â†’ ğŸ“– Explanation / Summary / Reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;common-tasks&#34;&gt;Common Tasks&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Video Captioning&lt;/td&gt;
&lt;td&gt;â€œA man is cooking pasta in a kitchen.â€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video QA&lt;/td&gt;
&lt;td&gt;â€œWhat did the dog do after jumping?â€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video Summarization&lt;/td&gt;
&lt;td&gt;â€œThis video shows a traffic accidentâ€¦â€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Temporal Reasoning&lt;/td&gt;
&lt;td&gt;â€œWhat happened before the explosion?â€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Instruction Following&lt;/td&gt;
&lt;td&gt;â€œExplain this experiment step-by-step.â€&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-video-is-fundamentally-different&#34;&gt;ğŸ§© Why Video Is Fundamentally Different&lt;/h2&gt;
&lt;h3 id=&#34;image-vs-video&#34;&gt;Image vs Video&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Image&lt;/th&gt;
&lt;th&gt;Video&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Static&lt;/td&gt;
&lt;td&gt;Temporal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Single embedding&lt;/td&gt;
&lt;td&gt;Sequence of embeddings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Local reasoning&lt;/td&gt;
&lt;td&gt;Long-range reasoning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Easy batching&lt;/td&gt;
&lt;td&gt;Memory explosion&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Key idea:&lt;/strong&gt;&lt;br&gt;
Video understanding = &lt;strong&gt;sequence modeling + vision + alignment&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-thinking-like-a-videotext-architect&#34;&gt;ğŸ§  Thinking Like a Videoâ€“Text Architect&lt;/h2&gt;
&lt;h3 id=&#34;the-core-questions&#34;&gt;The Core Questions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;What is the &lt;strong&gt;unit of time&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;How many frames matter?&lt;/li&gt;
&lt;li&gt;Do we need &lt;strong&gt;motion&lt;/strong&gt;, or just &lt;strong&gt;key frames&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;Can we compress time?&lt;/li&gt;
&lt;li&gt;Where does language interact?&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-canonical-videotext-architecture&#34;&gt;ğŸ§± Canonical Videoâ€“Text Architecture&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Video Frames â†’ Vision Encoder â†’ Temporal Encoder â†’ LLM â†’ Text Output

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;components&#34;&gt;Components&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Examples&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Vision Encoder&lt;/td&gt;
&lt;td&gt;ViT, ConvNet, Swin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Temporal Encoder&lt;/td&gt;
&lt;td&gt;Transformer, LSTM, Mamba&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fusion&lt;/td&gt;
&lt;td&gt;Cross-attention&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Language Model&lt;/td&gt;
&lt;td&gt;LLaMA, GPT, T5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-temporal-modeling-strategies&#34;&gt;â± Temporal Modeling Strategies&lt;/h2&gt;
&lt;h3 id=&#34;1-uniform-sampling&#34;&gt;1ï¸âƒ£ Uniform Sampling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Sample every &lt;em&gt;n&lt;/em&gt; frames&lt;/li&gt;
&lt;li&gt;Cheap but may miss key events&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-keyframe-extraction&#34;&gt;2ï¸âƒ£ Keyframe Extraction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Shot detection&lt;/li&gt;
&lt;li&gt;Scene change detection&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-learned-temporal-attention&#34;&gt;3ï¸âƒ£ Learned Temporal Attention&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Model decides which frames matter&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Rule:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;Not all frames are equally intelligent.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-temporal-reasoning--frame-understanding&#34;&gt;ğŸ§  Temporal Reasoning â‰  Frame Understanding&lt;/h2&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;â€œWhat happened &lt;strong&gt;before&lt;/strong&gt; the fall?â€&lt;/li&gt;
&lt;li&gt;â€œWhy did the crowd start running?â€&lt;/li&gt;
&lt;li&gt;â€œWhat caused the explosion?â€&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Event ordering&lt;/li&gt;
&lt;li&gt;Causal reasoning&lt;/li&gt;
&lt;li&gt;Memory across time&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-videotext-alignment&#34;&gt;ğŸ”— Videoâ€“Text Alignment&lt;/h2&gt;
&lt;h3 id=&#34;alignment-objectives&#34;&gt;Alignment Objectives&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Frame â†” Word&lt;/li&gt;
&lt;li&gt;Segment â†” Sentence&lt;/li&gt;
&lt;li&gt;Event â†” Explanation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Losses commonly used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Contrastive loss (CLIP-style)&lt;/li&gt;
&lt;li&gt;Cross-entropy on generated text&lt;/li&gt;
&lt;li&gt;Temporal grounding loss&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-popular-videotext-models&#34;&gt;ğŸ§ª Popular Videoâ€“Text Models&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Key Idea&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VideoBERT&lt;/td&gt;
&lt;td&gt;Treat frames as tokens&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Flamingo&lt;/td&gt;
&lt;td&gt;Perceiver-style attention&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;InternVideo&lt;/td&gt;
&lt;td&gt;Unified video representation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video-LLaMA&lt;/td&gt;
&lt;td&gt;Video + LLM alignment&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPT-4V&lt;/td&gt;
&lt;td&gt;Proprietary multimodal reasoning&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-videotext-pipeline-conceptual&#34;&gt;ğŸ Python: Videoâ€“Text Pipeline (Conceptual)&lt;/h2&gt;
&lt;h3 id=&#34;step-1-load-video-frames&#34;&gt;Step 1: Load Video Frames&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2

def load_frames(video_path, max_frames=32):
    cap = cv2.VideoCapture(video_path)
    frames = []
    while len(frames) &amp;lt; max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
    cap.release()
    return frames
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-2-encode-frames&#34;&gt;Step 2: Encode Frames&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch

with torch.no_grad():
    frame_embeddings = vision_encoder(frames)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-3-temporal-encoding&#34;&gt;Step 3: Temporal Encoding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;video_embedding = temporal_transformer(frame_embeddings)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-4-language-generation&#34;&gt;Step 4: Language Generation&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;output = llm.generate(
    video_embedding=video_embedding,
    prompt=&amp;quot;Describe what is happening in this video&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-memory--efficiency-tricks-very-important&#34;&gt;ğŸ§  Memory &amp;amp; Efficiency Tricks (VERY IMPORTANT)&lt;/h2&gt;
&lt;h3 id=&#34;problem&#34;&gt;Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Video = huge memory cost&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solutions&#34;&gt;Solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Frame pooling&lt;/li&gt;
&lt;li&gt;Token pruning&lt;/li&gt;
&lt;li&gt;Sliding windows&lt;/li&gt;
&lt;li&gt;Temporal compression&lt;/li&gt;
&lt;li&gt;Hierarchical attention&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Engineering intelligence matters as much as model size&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-of-videotext-models&#34;&gt;ğŸ§ª Evaluation of Videoâ€“Text Models&lt;/h2&gt;
&lt;h3 id=&#34;automatic-metrics&#34;&gt;Automatic Metrics&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BLEU&lt;/li&gt;
&lt;li&gt;METEOR&lt;/li&gt;
&lt;li&gt;CIDEr&lt;/li&gt;
&lt;li&gt;ROUGE&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;human-evaluation-best&#34;&gt;Human Evaluation (BEST)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Temporal correctness&lt;/li&gt;
&lt;li&gt;Causal reasoning&lt;/li&gt;
&lt;li&gt;Hallucination rate&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-failure-modes&#34;&gt;âš ï¸ Failure Modes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;âŒ Hallucinating events&lt;/li&gt;
&lt;li&gt;âŒ Mixing timelines&lt;/li&gt;
&lt;li&gt;âŒ Ignoring small but critical actions&lt;/li&gt;
&lt;li&gt;âŒ Overconfidence&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Video hallucination is &lt;strong&gt;more dangerous&lt;/strong&gt; than image hallucination.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight-important&#34;&gt;ğŸ§  Research Insight (Important)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Most â€œvideo understandingâ€ models are actually &lt;strong&gt;image models with memory&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;True video intelligence requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Event abstraction&lt;/li&gt;
&lt;li&gt;Temporal causality&lt;/li&gt;
&lt;li&gt;Long-horizon planning&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-self-test-hidden-answers&#34;&gt;ğŸ§ª Student Self-Test (Hidden Answers)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;What makes video harder than images?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Temporal dependency, motion, memory, and causal reasoning.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which component models time?&lt;/p&gt;
&lt;p&gt;A. Vision Encoder
B. Tokenizer
C. Temporal Encoder
D. Loss Function&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Temporal Encoder&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is NOT a videoâ€“text task?&lt;/p&gt;
&lt;p&gt;A. Video captioning
B. Video QA
C. Video super-resolution
D. Video summarization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Video super-resolution&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is uniform frame sampling risky?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It may miss critical events or actions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is temporal hallucination?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Inventing events that never occurred in the video timeline.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If AI understands video perfectly, what responsibility do humans still hold?&lt;/summary&gt;
  &lt;p&gt;Interpretation, ethics, judgment, and accountability.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-takeaways&#34;&gt;âœ… Key Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Video is &lt;strong&gt;the hardest modality&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Time is the real challenge&lt;/li&gt;
&lt;li&gt;Compression = intelligence&lt;/li&gt;
&lt;li&gt;Reasoning &amp;gt; perception&lt;/li&gt;
&lt;li&gt;Human evaluation is critical&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 07 â€” Visual Question Answering (VQA) &amp; Document Question Answering (DocQA)</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-07-vqa-docqa/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-07-vqa-docqa/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“5 hours (applied multimodal reasoning)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-vqa--docqa-matter-to-humanity&#34;&gt;ğŸ‘ï¸ğŸ“„ Why VQA &amp;amp; DocQA Matter to Humanity&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;VQA &amp;amp; DocQA turn perception into understanding.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;They allow machines to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ‘ï¸ See&lt;/li&gt;
&lt;li&gt;ğŸ“„ Read&lt;/li&gt;
&lt;li&gt;â“ Understand questions&lt;/li&gt;
&lt;li&gt;ğŸ§  Reason&lt;/li&gt;
&lt;li&gt;âœï¸ Answer &lt;em&gt;grounded in evidence&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the foundation of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assistive AI&lt;/li&gt;
&lt;li&gt;Education AI&lt;/li&gt;
&lt;li&gt;Legal &amp;amp; medical AI&lt;/li&gt;
&lt;li&gt;Scientific discovery&lt;/li&gt;
&lt;li&gt;Accessibility technology&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-visual-question-answering-vqa&#34;&gt;ğŸ§  What Is Visual Question Answering (VQA)?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ–¼ Image&lt;/li&gt;
&lt;li&gt;â“ Natural language question&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;âœï¸ Text answer grounded in the image&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; â€œHow many people are wearing helmets?â€&lt;br&gt;
&lt;strong&gt;A:&lt;/strong&gt; â€œTwo.â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-document-question-answering-docqa&#34;&gt;ğŸ§  What Is Document Question Answering (DocQA)?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„ Document image / PDF&lt;/li&gt;
&lt;li&gt;â“ Question&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;âœï¸ Answer extracted or reasoned from the document&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; â€œWhat is the invoice total?â€&lt;br&gt;
&lt;strong&gt;A:&lt;/strong&gt; â€œ$1,245.50â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-vqa-vs-docqa-key-differences&#34;&gt;ğŸ” VQA vs DocQA (Key Differences)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aspect&lt;/th&gt;
&lt;th&gt;VQA&lt;/th&gt;
&lt;th&gt;DocQA&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Main Challenge&lt;/td&gt;
&lt;td&gt;Visual reasoning&lt;/td&gt;
&lt;td&gt;Text + layout understanding&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Precision&lt;/td&gt;
&lt;td&gt;Often coarse&lt;/td&gt;
&lt;td&gt;Extremely precise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCR Required&lt;/td&gt;
&lt;td&gt;Optional&lt;/td&gt;
&lt;td&gt;Mandatory&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hallucination Risk&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Very high&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Evaluation&lt;/td&gt;
&lt;td&gt;Semantic&lt;/td&gt;
&lt;td&gt;Exact match critical&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;DocQA punishes mistakes much harder than VQA.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-cognitive-skills-required&#34;&gt;ğŸ§  Cognitive Skills Required&lt;/h2&gt;
&lt;p&gt;Both tasks require:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visual grounding&lt;/li&gt;
&lt;li&gt;Cross-modal alignment&lt;/li&gt;
&lt;li&gt;Reasoning&lt;/li&gt;
&lt;li&gt;Attention control&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But DocQA adds:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Layout reasoning&lt;/li&gt;
&lt;li&gt;Reading order&lt;/li&gt;
&lt;li&gt;Table understanding&lt;/li&gt;
&lt;li&gt;Key-value extraction&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-canonical-architecture-unified-view&#34;&gt;ğŸ§± Canonical Architecture (Unified View)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Image / Document
â†“
Vision Encoder (ViT / CNN)
â†“
OCR (DocQA only)
â†“
Layout / Spatial Encoder
â†“
Cross-Attention Fusion
â†“
LLM Reasoning
â†“
Text Answer

&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-vision-encoding&#34;&gt;ğŸ‘ï¸ Vision Encoding&lt;/h2&gt;
&lt;p&gt;Common backbones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ViT&lt;/li&gt;
&lt;li&gt;Swin Transformer&lt;/li&gt;
&lt;li&gt;CNN + FPN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Key requirement:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Preserve &lt;strong&gt;spatial information&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ocr-is-not-optional-for-docqa&#34;&gt;ğŸ”¤ OCR Is NOT Optional for DocQA&lt;/h2&gt;
&lt;p&gt;OCR extracts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text&lt;/li&gt;
&lt;li&gt;Bounding boxes&lt;/li&gt;
&lt;li&gt;Confidence scores&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Popular OCR tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tesseract&lt;/li&gt;
&lt;li&gt;PaddleOCR&lt;/li&gt;
&lt;li&gt;EasyOCR&lt;/li&gt;
&lt;li&gt;TrOCR (Transformer-based)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Bad OCR = Impossible DocQA&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-layout-understanding-critical&#34;&gt;ğŸ§­ Layout Understanding (CRITICAL)&lt;/h2&gt;
&lt;p&gt;Documents are not sentences â€” they are &lt;strong&gt;spatial graphs&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;layout-features&#34;&gt;Layout Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;X, Y coordinates&lt;/li&gt;
&lt;li&gt;Width / height&lt;/li&gt;
&lt;li&gt;Reading order&lt;/li&gt;
&lt;li&gt;Font size / style&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LayoutLM&lt;/li&gt;
&lt;li&gt;LayoutLMv3&lt;/li&gt;
&lt;li&gt;DocFormer&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-reasoning-types-in-vqa--docqa&#34;&gt;ğŸ§  Reasoning Types in VQA &amp;amp; DocQA&lt;/h2&gt;
&lt;h3 id=&#34;vqa-reasoning&#34;&gt;VQA Reasoning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Counting&lt;/li&gt;
&lt;li&gt;Spatial (â€œleft ofâ€, â€œbehindâ€)&lt;/li&gt;
&lt;li&gt;Attribute recognition&lt;/li&gt;
&lt;li&gt;Commonsense&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;docqa-reasoning&#34;&gt;DocQA Reasoning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Lookup&lt;/li&gt;
&lt;li&gt;Aggregation&lt;/li&gt;
&lt;li&gt;Comparison&lt;/li&gt;
&lt;li&gt;Multi-hop reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-simple-vqa-pipeline&#34;&gt;ğŸ Python: Simple VQA Pipeline&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;image = load_image(&amp;quot;scene.jpg&amp;quot;)
question = &amp;quot;How many cars are parked?&amp;quot;

vision_features = vision_encoder(image)
answer = llm.generate(
    visual_features=vision_features,
    prompt=question
)

print(answer)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-docqa-pipeline-conceptual&#34;&gt;ğŸ Python: DocQA Pipeline (Conceptual)&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;doc_image = load_image(&amp;quot;invoice.png&amp;quot;)
ocr_tokens, boxes = ocr_engine(doc_image)

doc_embedding = layout_encoder(ocr_tokens, boxes)

answer = llm.generate(
    document_embedding=doc_embedding,
    prompt=&amp;quot;What is the total amount?&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-prompt-engineering-for-vqa--docqa&#34;&gt;ğŸ§  Prompt Engineering for VQA &amp;amp; DocQA&lt;/h2&gt;
&lt;p&gt;Bad prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œAnswer the question.â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Good prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œAnswer using only visible evidence. If uncertain, say â€˜Not foundâ€™.â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Prompt discipline reduces hallucination.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-datasets-must-know&#34;&gt;ğŸ§ª Datasets (Must-Know)&lt;/h2&gt;
&lt;h3 id=&#34;vqa&#34;&gt;VQA&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;VQA v2&lt;/li&gt;
&lt;li&gt;GQA&lt;/li&gt;
&lt;li&gt;CLEVR (synthetic reasoning)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;docqa&#34;&gt;DocQA&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DocVQA&lt;/li&gt;
&lt;li&gt;FUNSD&lt;/li&gt;
&lt;li&gt;RVL-CDIP&lt;/li&gt;
&lt;li&gt;CORD&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-metrics&#34;&gt;ğŸ“ Evaluation Metrics&lt;/h2&gt;
&lt;h3 id=&#34;vqa-1&#34;&gt;VQA&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accuracy&lt;/li&gt;
&lt;li&gt;Consensus-based scoring&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;docqa-1&#34;&gt;DocQA&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Exact Match (EM)&lt;/li&gt;
&lt;li&gt;F1 score&lt;/li&gt;
&lt;li&gt;String normalization critical&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;One wrong digit = wrong answer&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-hallucination-the-silent-killer&#34;&gt;âš ï¸ Hallucination: The Silent Killer&lt;/h2&gt;
&lt;p&gt;Common failure cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Answering from prior knowledge&lt;/li&gt;
&lt;li&gt;Guessing missing fields&lt;/li&gt;
&lt;li&gt;Confusing similar layouts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mitigation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evidence-aware prompting&lt;/li&gt;
&lt;li&gt;Answer verification&lt;/li&gt;
&lt;li&gt;Human-in-the-loop (later lecture)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight&#34;&gt;ğŸ§  Research Insight&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;DocQA is closer to &lt;strong&gt;symbolic reasoning&lt;/strong&gt; than vision.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Strong DocQA models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Behave more like databases&lt;/li&gt;
&lt;li&gt;Require constraint enforcement&lt;/li&gt;
&lt;li&gt;Prefer abstention over guessing&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden-answers&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden Answers)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;What extra component does DocQA require compared to VQA?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;OCR and layout understanding.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which model explicitly encodes layout?&lt;/p&gt;
&lt;p&gt;A. CLIP
B. ViT
C. LayoutLM
D. ResNet&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. LayoutLM&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which metric is most important for DocQA?&lt;/p&gt;
&lt;p&gt;A. BLEU
B. ROUGE
C. Exact Match
D. Perplexity&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Exact Match&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is hallucination more dangerous in DocQA?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because answers must be exact and legally or financially correct.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is layout reasoning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Understanding text based on spatial structure, not just content.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If AI can read documents perfectly, what must humans still verify?&lt;/summary&gt;
  &lt;p&gt;Truth, intent, context, and ethical consequences.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-takeaways&#34;&gt;âœ… Key Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VQA = visual reasoning&lt;/li&gt;
&lt;li&gt;DocQA = precision reasoning&lt;/li&gt;
&lt;li&gt;OCR quality defines upper bound&lt;/li&gt;
&lt;li&gt;Layout is intelligence&lt;/li&gt;
&lt;li&gt;Abstaining is better than hallucinating&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 08 â€” RAG, AI Agents &amp; Agentic Multimodal Systems</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-08-rag-agents/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-08-rag-agents/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“6 hours (modern AI systems design)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-changes-everything&#34;&gt;ğŸ§  Why This Lecture Changes Everything&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Models are not intelligent alone.&lt;br&gt;
Systems are.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;RAG and AI Agents represent a shift:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;âŒ From static models&lt;/li&gt;
&lt;li&gt;âœ… To &lt;em&gt;interactive, grounded, tool-using intelligence&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This lecture connects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLMs&lt;/li&gt;
&lt;li&gt;Multimodality&lt;/li&gt;
&lt;li&gt;Memory&lt;/li&gt;
&lt;li&gt;Tools&lt;/li&gt;
&lt;li&gt;Reasoning&lt;/li&gt;
&lt;li&gt;Real-world deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-retrieval-augmented-generation-rag&#34;&gt;ğŸ§© What Is Retrieval-Augmented Generation (RAG)?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;RAG = Knowledge + Reasoning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instead of forcing the model to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;memorize everything&lt;/li&gt;
&lt;li&gt;hallucinate confidently&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We let it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Retrieve relevant information&lt;/li&gt;
&lt;li&gt;Reason over it&lt;/li&gt;
&lt;li&gt;Generate grounded answers&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-classical-llm-vs-rag&#34;&gt;ğŸ” Classical LLM vs RAG&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aspect&lt;/th&gt;
&lt;th&gt;Classical LLM&lt;/th&gt;
&lt;th&gt;RAG&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Knowledge&lt;/td&gt;
&lt;td&gt;Frozen&lt;/td&gt;
&lt;td&gt;Dynamic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hallucination&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Lower&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Updates&lt;/td&gt;
&lt;td&gt;Retrain&lt;/td&gt;
&lt;td&gt;Re-index&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Traceability&lt;/td&gt;
&lt;td&gt;Poor&lt;/td&gt;
&lt;td&gt;Strong&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Enterprise-ready&lt;/td&gt;
&lt;td&gt;âŒ&lt;/td&gt;
&lt;td&gt;âœ…&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;RAG turns LLMs into â€œopen-book thinkers.â€&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-rag-pipeline&#34;&gt;ğŸ§  Core RAG Pipeline&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
User Query
â†“
Embedding
â†“
Retriever (Vector DB)
â†“
Relevant Context
â†“
LLM Reasoning
â†“
Answer + Citations

&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-can-be-retrieved&#34;&gt;ğŸ“¦ What Can Be Retrieved?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„ Documents&lt;/li&gt;
&lt;li&gt;ğŸ–¼ Images&lt;/li&gt;
&lt;li&gt;ğŸ¥ Videos&lt;/li&gt;
&lt;li&gt;ğŸ§¾ Tables&lt;/li&gt;
&lt;li&gt;ğŸ“Š Logs&lt;/li&gt;
&lt;li&gt;ğŸ§  Memories (Agent state)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Multimodal RAG = &lt;strong&gt;cross-modal retrieval + reasoning&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-embeddings-the-heart-of-rag&#34;&gt;ğŸ§  Embeddings: The Heart of RAG&lt;/h2&gt;
&lt;p&gt;Embedding models map meaning â†’ vectors.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text: sentence-transformers&lt;/li&gt;
&lt;li&gt;Image: CLIP&lt;/li&gt;
&lt;li&gt;Video: InternVideo&lt;/li&gt;
&lt;li&gt;Document: Layout-aware embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Good retrieval beats bigger models.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-minimal-rag-example&#34;&gt;ğŸ Python: Minimal RAG Example&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;query = &amp;quot;What is transformer attention?&amp;quot;

q_emb = embedder.encode(query)
docs = vector_db.search(q_emb, top_k=5)

context = &amp;quot;\n&amp;quot;.join(docs)

answer = llm.generate(
    prompt=f&amp;quot;Answer using the context below:\n{context}\n\nQuestion:{query}&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-common-rag-failure-modes&#34;&gt;âš ï¸ Common RAG Failure Modes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Retrieving irrelevant chunks&lt;/li&gt;
&lt;li&gt;Context too long&lt;/li&gt;
&lt;li&gt;Context ignored&lt;/li&gt;
&lt;li&gt;Conflicting documents&lt;/li&gt;
&lt;li&gt;Over-trusting retrieved text&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mitigation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chunking strategy&lt;/li&gt;
&lt;li&gt;Reranking&lt;/li&gt;
&lt;li&gt;Instruction tuning&lt;/li&gt;
&lt;li&gt;Answer verification&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-an-ai-agent&#34;&gt;ğŸ¤– What Is an AI Agent?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;An agent is an LLM that can act.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Agent abilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decide next action&lt;/li&gt;
&lt;li&gt;Use tools&lt;/li&gt;
&lt;li&gt;Store memory&lt;/li&gt;
&lt;li&gt;Observe outcomes&lt;/li&gt;
&lt;li&gt;Iterate&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-agent-loop-canonical&#34;&gt;ğŸ§  Agent Loop (Canonical)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Observe â†’ Think â†’ Act â†’ Reflect â†’ Repeat
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is &lt;strong&gt;not prompting&lt;/strong&gt; â€” it is &lt;strong&gt;control flow&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-agent-components&#34;&gt;ğŸ§© Agent Components&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Role&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;LLM&lt;/td&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Memory&lt;/td&gt;
&lt;td&gt;State&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tools&lt;/td&gt;
&lt;td&gt;Actions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Planner&lt;/td&gt;
&lt;td&gt;Decomposition&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Executor&lt;/td&gt;
&lt;td&gt;Tool calling&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Critic&lt;/td&gt;
&lt;td&gt;Self-evaluation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-tools-an-agent-can-use&#34;&gt;ğŸ›  Tools an Agent Can Use&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Search engines&lt;/li&gt;
&lt;li&gt;Databases&lt;/li&gt;
&lt;li&gt;Code execution&lt;/li&gt;
&lt;li&gt;APIs&lt;/li&gt;
&lt;li&gt;OCR&lt;/li&gt;
&lt;li&gt;Vision models&lt;/li&gt;
&lt;li&gt;File systems&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tools extend intelligence beyond tokens.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-simple-agent-skeleton&#34;&gt;ğŸ Python: Simple Agent Skeleton&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;while not task_done:
    thought = llm.think(state)
    action = planner.select(thought)
    result = tools.run(action)
    state.update(result)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-agentic-ai&#34;&gt;ğŸ§  What Is Agentic AI?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Agentic AI&lt;/strong&gt; means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Long-horizon goals&lt;/li&gt;
&lt;li&gt;Autonomous planning&lt;/li&gt;
&lt;li&gt;Self-correction&lt;/li&gt;
&lt;li&gt;Tool orchestration&lt;/li&gt;
&lt;li&gt;Memory persistence&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Research agents&lt;/li&gt;
&lt;li&gt;Coding agents&lt;/li&gt;
&lt;li&gt;Multimodal assistants&lt;/li&gt;
&lt;li&gt;Auto-analysts&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-rag--agents--power&#34;&gt;ğŸ”— RAG + Agents = Power&lt;/h2&gt;
&lt;p&gt;RAG answers questions.
Agents &lt;strong&gt;decide what to retrieve and why&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Agent
  â”œâ”€â”€ Query RAG
  â”œâ”€â”€ Verify answer
  â”œâ”€â”€ Ask follow-up
  â”œâ”€â”€ Use tools
  â””â”€â”€ Deliver result
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;This is how &lt;strong&gt;real AI systems are built today&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-multimodal-agent-example&#34;&gt;ğŸ§  Multimodal Agent Example&lt;/h2&gt;
&lt;p&gt;Task:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œAnalyze this traffic video and explain why the accident occurred.â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Agent flow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Extract video frames&lt;/li&gt;
&lt;li&gt;Retrieve traffic rules (RAG)&lt;/li&gt;
&lt;li&gt;Detect events&lt;/li&gt;
&lt;li&gt;Reason causality&lt;/li&gt;
&lt;li&gt;Generate explanation&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-risks-of-agentic-systems&#34;&gt;âš ï¸ Risks of Agentic Systems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tool misuse&lt;/li&gt;
&lt;li&gt;Infinite loops&lt;/li&gt;
&lt;li&gt;Overconfidence&lt;/li&gt;
&lt;li&gt;Hidden failures&lt;/li&gt;
&lt;li&gt;Alignment drift&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mitigation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Guardrails&lt;/li&gt;
&lt;li&gt;Cost limits&lt;/li&gt;
&lt;li&gt;Human approval&lt;/li&gt;
&lt;li&gt;Logging&lt;/li&gt;
&lt;li&gt;Evaluation&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluating-rag--agents&#34;&gt;ğŸ“ Evaluating RAG &amp;amp; Agents&lt;/h2&gt;
&lt;h3 id=&#34;rag-evaluation&#34;&gt;RAG Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Retrieval recall&lt;/li&gt;
&lt;li&gt;Faithfulness&lt;/li&gt;
&lt;li&gt;Answer correctness&lt;/li&gt;
&lt;li&gt;Citation accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;agent-evaluation&#34;&gt;Agent Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Task success rate&lt;/li&gt;
&lt;li&gt;Steps efficiency&lt;/li&gt;
&lt;li&gt;Error recovery&lt;/li&gt;
&lt;li&gt;Human satisfaction&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight&#34;&gt;ğŸ§  Research Insight&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Intelligence is no longer &lt;strong&gt;inside the model&lt;/strong&gt;
It is &lt;strong&gt;distributed across systems&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The future:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smaller models&lt;/li&gt;
&lt;li&gt;Better retrieval&lt;/li&gt;
&lt;li&gt;Smarter agents&lt;/li&gt;
&lt;li&gt;Human oversight&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;What problem does RAG primarily solve?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Hallucination and static knowledge.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is NOT a core agent component?&lt;/p&gt;
&lt;p&gt;A. Memory
B. Planner
C. Tool interface
D. Dataset labeler&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;D. Dataset labeler&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Why combine RAG with agents?&lt;/p&gt;
&lt;p&gt;A. Reduce cost
B. Improve UI
C. Enable decision-driven retrieval
D. Increase model size&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Enable decision-driven retrieval&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is agentic AI?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;AI systems that plan, act, use tools, and self-correct toward goals.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is human oversight important for agents?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To prevent unsafe, incorrect, or misaligned actions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If AI agents can act autonomously, what must humans always control?&lt;/summary&gt;
  &lt;p&gt;Goals, values, boundaries, and accountability.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-takeaways&#34;&gt;âœ… Key Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;RAG grounds intelligence&lt;/li&gt;
&lt;li&gt;Agents enable action&lt;/li&gt;
&lt;li&gt;Agentic AI is system-level intelligence&lt;/li&gt;
&lt;li&gt;Multimodal agents are the future&lt;/li&gt;
&lt;li&gt;Humans must remain in the loop&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 09 â€” Evaluation of Multimodal &amp; Agentic AI Systems</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-09-evaluation/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-09-evaluation/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“6 hours (advanced, critical thinking lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-evaluation-is-the-hardest-problem-in-ai&#34;&gt;ğŸ§  Why Evaluation Is the Hardest Problem in AI&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If you cannot evaluate it, you do not understand it.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Modern AI systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate free-form text&lt;/li&gt;
&lt;li&gt;Reason over images, videos, documents&lt;/li&gt;
&lt;li&gt;Use tools&lt;/li&gt;
&lt;li&gt;Act autonomously&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;â“ So how do we measure &lt;em&gt;correctness&lt;/em&gt;, &lt;em&gt;reasoning&lt;/em&gt;, &lt;em&gt;safety&lt;/em&gt;, and &lt;em&gt;usefulness&lt;/em&gt;?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Evaluation is harder than training.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-evaluation-crisis&#34;&gt;âš ï¸ The Evaluation Crisis&lt;/h2&gt;
&lt;p&gt;Common mistakes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using only BLEU / ROUGE&lt;/li&gt;
&lt;li&gt;Evaluating language but not reasoning&lt;/li&gt;
&lt;li&gt;Ignoring hallucination&lt;/li&gt;
&lt;li&gt;No human evaluation&lt;/li&gt;
&lt;li&gt;No failure analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;High benchmark scores â‰  trustworthy intelligence&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-are-we-actually-evaluating&#34;&gt;ğŸ§© What Are We Actually Evaluating?&lt;/h2&gt;
&lt;p&gt;Evaluation must answer &lt;strong&gt;what kind of intelligence&lt;/strong&gt; we care about.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dimension&lt;/th&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;Is the answer correct?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Grounding&lt;/td&gt;
&lt;td&gt;Is it supported by evidence?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reasoning&lt;/td&gt;
&lt;td&gt;Are the steps valid?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Robustness&lt;/td&gt;
&lt;td&gt;Does it fail gracefully?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Safety&lt;/td&gt;
&lt;td&gt;Is it harmful or biased?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Usefulness&lt;/td&gt;
&lt;td&gt;Does it help a human?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-by-task-type&#34;&gt;ğŸ§  Evaluation by Task Type&lt;/h2&gt;
&lt;h3 id=&#34;-text-only-llms&#34;&gt;ğŸ“ Text-only LLMs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fluency&lt;/li&gt;
&lt;li&gt;Factuality&lt;/li&gt;
&lt;li&gt;Reasoning&lt;/li&gt;
&lt;li&gt;Consistency&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-imagetext&#34;&gt;ğŸ–¼ Imageâ€“Text&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Visual grounding&lt;/li&gt;
&lt;li&gt;Hallucination&lt;/li&gt;
&lt;li&gt;Spatial correctness&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-videotext&#34;&gt;ğŸ¥ Videoâ€“Text&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Temporal reasoning&lt;/li&gt;
&lt;li&gt;Event ordering&lt;/li&gt;
&lt;li&gt;Causal understanding&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-docqa&#34;&gt;ğŸ“„ DocQA&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Exact match&lt;/li&gt;
&lt;li&gt;Numerical accuracy&lt;/li&gt;
&lt;li&gt;Layout grounding&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-agents&#34;&gt;ğŸ¤– Agents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Task success&lt;/li&gt;
&lt;li&gt;Tool correctness&lt;/li&gt;
&lt;li&gt;Efficiency&lt;/li&gt;
&lt;li&gt;Safety&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-automatic-metrics-know-their-limits&#34;&gt;ğŸ“ Automatic Metrics (Know Their Limits)&lt;/h2&gt;
&lt;h3 id=&#34;text-metrics&#34;&gt;Text Metrics&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th&gt;Measures&lt;/th&gt;
&lt;th&gt;Limitation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BLEU&lt;/td&gt;
&lt;td&gt;N-gram overlap&lt;/td&gt;
&lt;td&gt;Bad for reasoning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ROUGE&lt;/td&gt;
&lt;td&gt;Recall&lt;/td&gt;
&lt;td&gt;Shallow&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;METEOR&lt;/td&gt;
&lt;td&gt;Semantic match&lt;/td&gt;
&lt;td&gt;Still surface-level&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Perplexity&lt;/td&gt;
&lt;td&gt;Fluency&lt;/td&gt;
&lt;td&gt;Not correctness&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Text similarity â‰  truth&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-vision-language-metrics&#34;&gt;ğŸ“ Vision-Language Metrics&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;VQA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CIDEr&lt;/td&gt;
&lt;td&gt;Captioning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IoU&lt;/td&gt;
&lt;td&gt;Grounding&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recall@K&lt;/td&gt;
&lt;td&gt;Retrieval&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitive to wording&lt;/li&gt;
&lt;li&gt;Miss reasoning errors&lt;/li&gt;
&lt;li&gt;Encourage shortcut learning&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-faithfulness--grounding-evaluation&#34;&gt;ğŸ§  Faithfulness &amp;amp; Grounding Evaluation&lt;/h2&gt;
&lt;p&gt;Key question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Did the model use the provided evidence?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Attribution checks&lt;/li&gt;
&lt;li&gt;Citation verification&lt;/li&gt;
&lt;li&gt;Evidence overlap&lt;/li&gt;
&lt;li&gt;Counterfactual prompts&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-hallucination-evaluation-critical&#34;&gt;ğŸ§ª Hallucination Evaluation (CRITICAL)&lt;/h2&gt;
&lt;p&gt;Hallucination types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Factual hallucination&lt;/li&gt;
&lt;li&gt;Visual hallucination&lt;/li&gt;
&lt;li&gt;Temporal hallucination&lt;/li&gt;
&lt;li&gt;Tool hallucination&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Detection:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Human labeling&lt;/li&gt;
&lt;li&gt;Rule-based checks&lt;/li&gt;
&lt;li&gt;Retrieval consistency&lt;/li&gt;
&lt;li&gt;Self-verification prompts&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-human-evaluation-gold-standard&#34;&gt;ğŸ‘¥ Human Evaluation (Gold Standard)&lt;/h2&gt;
&lt;p&gt;Humans evaluate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Correctness&lt;/li&gt;
&lt;li&gt;Clarity&lt;/li&gt;
&lt;li&gt;Trustworthiness&lt;/li&gt;
&lt;li&gt;Helpfulness&lt;/li&gt;
&lt;li&gt;Harm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Best practices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiple annotators&lt;/li&gt;
&lt;li&gt;Clear rubrics&lt;/li&gt;
&lt;li&gt;Inter-annotator agreement&lt;/li&gt;
&lt;li&gt;Blind comparison&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Humans evaluate meaning, not tokens.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluation-of-reasoning&#34;&gt;ğŸ§  Evaluation of Reasoning&lt;/h2&gt;
&lt;p&gt;Bad evaluation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œIs the final answer correct?â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Good evaluation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are intermediate steps valid?&lt;/li&gt;
&lt;li&gt;Are assumptions reasonable?&lt;/li&gt;
&lt;li&gt;Is reasoning grounded?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Techniques:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chain-of-thought review&lt;/li&gt;
&lt;li&gt;Step-by-step scoring&lt;/li&gt;
&lt;li&gt;Error categorization&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-evaluating-agents-is-different&#34;&gt;ğŸ¤– Evaluating Agents Is Different&lt;/h2&gt;
&lt;p&gt;Agents are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-deterministic&lt;/li&gt;
&lt;li&gt;Multi-step&lt;/li&gt;
&lt;li&gt;Tool-dependent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Task completion rate&lt;/li&gt;
&lt;li&gt;Number of steps&lt;/li&gt;
&lt;li&gt;Cost&lt;/li&gt;
&lt;li&gt;Error recovery&lt;/li&gt;
&lt;li&gt;Safety violations&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-simple-evaluation-loop&#34;&gt;ğŸ Python: Simple Evaluation Loop&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;results = []

for example in dataset:
    prediction = model(example.input)
    score = evaluate(prediction, example.answer)
    results.append(score)

print(sum(results) / len(results))
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Simple code, deep thinking required.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-benchmark-vs-reality&#34;&gt;ğŸ§  Benchmark vs Reality&lt;/h2&gt;
&lt;p&gt;Benchmarks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Controlled&lt;/li&gt;
&lt;li&gt;Clean&lt;/li&gt;
&lt;li&gt;Known distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Messy&lt;/li&gt;
&lt;li&gt;Ambiguous&lt;/li&gt;
&lt;li&gt;Adversarial&lt;/li&gt;
&lt;li&gt;High stakes&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Always test on your own data.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-overfitting-to-benchmarks&#34;&gt;âš ï¸ Overfitting to Benchmarks&lt;/h2&gt;
&lt;p&gt;Symptoms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOTA on paper&lt;/li&gt;
&lt;li&gt;Poor real-world behavior&lt;/li&gt;
&lt;li&gt;Fragile prompts&lt;/li&gt;
&lt;li&gt;Dataset leakage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diverse evaluation&lt;/li&gt;
&lt;li&gt;Stress testing&lt;/li&gt;
&lt;li&gt;Out-of-distribution tests&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight&#34;&gt;ğŸ§  Research Insight&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The future of evaluation is &lt;strong&gt;interactive, human-centered, and continuous&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Trends:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM-as-judge (with caution)&lt;/li&gt;
&lt;li&gt;Hybrid humanâ€“AI evaluation&lt;/li&gt;
&lt;li&gt;Online evaluation in deployment&lt;/li&gt;
&lt;li&gt;Value-aligned metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why are BLEU/ROUGE insufficient for modern AI?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;They measure surface similarity, not reasoning or truth.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is the gold standard for evaluation?&lt;/p&gt;
&lt;p&gt;A. Automatic metrics
B. Benchmarks
C. Human evaluation
D. Leaderboards&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Human evaluation&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is most important for DocQA?&lt;/p&gt;
&lt;p&gt;A. Fluency
B. Creativity
C. Exact Match
D. Perplexity&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Exact Match&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is hallucination?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Producing confident but unsupported or false information.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is agent evaluation harder?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because agents are multi-step, non-deterministic, and tool-dependent.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If an AI scores high but harms people, is it a good model?&lt;/summary&gt;
  &lt;p&gt;No â€” evaluation must include human values and impact.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-takeaways&#34;&gt;âœ… Key Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Evaluation defines intelligence&lt;/li&gt;
&lt;li&gt;Automatic metrics are tools, not truth&lt;/li&gt;
&lt;li&gt;Grounding matters more than fluency&lt;/li&gt;
&lt;li&gt;Human judgment is essential&lt;/li&gt;
&lt;li&gt;Ethics begins at evaluation&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 10 â€” Bias, Ethics &amp; Human-in-the-Loop (HITL) in Multimodal AI</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-10-bias-ethics-hitl/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-10-bias-ethics-hitl/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~3â€“4 hours (human-centered AI lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-matters-more-than-any-other&#34;&gt;ğŸŒ Why This Lecture Matters More Than Any Other&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Power without ethics is danger.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Modern AI systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;see humans&lt;/li&gt;
&lt;li&gt;read private documents&lt;/li&gt;
&lt;li&gt;make recommendations&lt;/li&gt;
&lt;li&gt;influence decisions&lt;/li&gt;
&lt;li&gt;act autonomously&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Without ethics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bias scales&lt;/li&gt;
&lt;li&gt;harm multiplies&lt;/li&gt;
&lt;li&gt;trust collapses&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Ethics is not optional. It is engineering.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-bias-in-ai&#34;&gt;âš–ï¸ What Is Bias in AI?&lt;/h2&gt;
&lt;p&gt;Bias is &lt;strong&gt;systematic unfairness&lt;/strong&gt; that disadvantages individuals or groups.&lt;/p&gt;
&lt;p&gt;Bias can appear in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data&lt;/li&gt;
&lt;li&gt;models&lt;/li&gt;
&lt;li&gt;evaluation&lt;/li&gt;
&lt;li&gt;deployment&lt;/li&gt;
&lt;li&gt;human usage&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AI does not create bias â€” it amplifies it.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-types-of-bias-must-know&#34;&gt;ğŸ§  Types of Bias (Must-Know)&lt;/h2&gt;
&lt;h3 id=&#34;1-data-bias&#34;&gt;1ï¸âƒ£ Data Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Skewed demographics&lt;/li&gt;
&lt;li&gt;Missing populations&lt;/li&gt;
&lt;li&gt;Historical inequality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Face recognition trained mostly on light-skinned faces.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-annotation-bias&#34;&gt;2ï¸âƒ£ Annotation Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Subjective labels&lt;/li&gt;
&lt;li&gt;Cultural assumptions&lt;/li&gt;
&lt;li&gt;Inconsistent annotators&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;3-model-bias&#34;&gt;3ï¸âƒ£ Model Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Shortcut learning&lt;/li&gt;
&lt;li&gt;Spurious correlations&lt;/li&gt;
&lt;li&gt;Overgeneralization&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;4-deployment-bias&#34;&gt;4ï¸âƒ£ Deployment Bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Model used outside training context&lt;/li&gt;
&lt;li&gt;Different population&lt;/li&gt;
&lt;li&gt;High-stakes environment&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-bias-in-multimodal-systems&#34;&gt;ğŸ–¼ Bias in Multimodal Systems&lt;/h2&gt;
&lt;p&gt;Multimodal AI adds &lt;strong&gt;new bias risks&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vision stereotypes&lt;/li&gt;
&lt;li&gt;Language prejudice&lt;/li&gt;
&lt;li&gt;Accent discrimination&lt;/li&gt;
&lt;li&gt;Cultural misinterpretation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Describing professions differently based on gender in images.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-temporal--contextual-bias-video&#34;&gt;ğŸ¥ Temporal &amp;amp; Contextual Bias (Video)&lt;/h2&gt;
&lt;p&gt;Video models may:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Misinterpret behavior&lt;/li&gt;
&lt;li&gt;Infer intent incorrectly&lt;/li&gt;
&lt;li&gt;Over-police certain actions&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Seeing is not understanding.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ethical-risks-of-multimodal-ai&#34;&gt;âš ï¸ Ethical Risks of Multimodal AI&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Risk&lt;/th&gt;
&lt;th&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Surveillance&lt;/td&gt;
&lt;td&gt;Facial recognition misuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Privacy&lt;/td&gt;
&lt;td&gt;Reading personal documents&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Manipulation&lt;/td&gt;
&lt;td&gt;Deepfakes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Automation bias&lt;/td&gt;
&lt;td&gt;Blind trust in AI&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exclusion&lt;/td&gt;
&lt;td&gt;Accessibility gaps&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ethics--rules&#34;&gt;ğŸ§  Ethics â‰  Rules&lt;/h2&gt;
&lt;p&gt;Ethics involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Values&lt;/li&gt;
&lt;li&gt;Context&lt;/li&gt;
&lt;li&gt;Trade-offs&lt;/li&gt;
&lt;li&gt;Human judgment&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Ethical AI is not â€œalways rightâ€ â€” it is accountable.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-human-in-the-loop-hitl&#34;&gt;ğŸ‘¥ What Is Human-in-the-Loop (HITL)?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;HITL = Humans actively guide, verify, and override AI systems.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HITL is used when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stakes are high&lt;/li&gt;
&lt;li&gt;Errors are costly&lt;/li&gt;
&lt;li&gt;Context matters&lt;/li&gt;
&lt;li&gt;Accountability is required&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-hitl-interaction-modes&#34;&gt;ğŸ” HITL Interaction Modes&lt;/h2&gt;
&lt;h3 id=&#34;1-human-in-the-loop&#34;&gt;1ï¸âƒ£ Human-in-the-Loop&lt;/h3&gt;
&lt;p&gt;Human approves or corrects outputs.&lt;/p&gt;
&lt;h3 id=&#34;2-human-on-the-loop&#34;&gt;2ï¸âƒ£ Human-on-the-Loop&lt;/h3&gt;
&lt;p&gt;Human monitors and intervenes if needed.&lt;/p&gt;
&lt;h3 id=&#34;3-human-out-of-the-loop&#34;&gt;3ï¸âƒ£ Human-out-of-the-Loop&lt;/h3&gt;
&lt;p&gt;Fully autonomous (âš ï¸ risky).&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-where-hitl-fits-in-ai-pipelines&#34;&gt;ğŸ§© Where HITL Fits in AI Pipelines&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;
Data â†’ Model â†’ Prediction â†’ Human Review â†’ Decision

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Medical diagnosis&lt;/li&gt;
&lt;li&gt;Legal document review&lt;/li&gt;
&lt;li&gt;Loan approval&lt;/li&gt;
&lt;li&gt;Content moderation&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-python-hitl-pattern-conceptual&#34;&gt;ğŸ Python: HITL Pattern (Conceptual)&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;prediction = model(input)

if confidence &amp;lt; threshold:
    send_to_human(prediction)
else:
    accept(prediction)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Uncertainty is a signal, not a failure.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-designing-hitl-systems-well&#34;&gt;ğŸ§  Designing HITL Systems Well&lt;/h2&gt;
&lt;p&gt;Good HITL systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are transparent&lt;/li&gt;
&lt;li&gt;Minimize human fatigue&lt;/li&gt;
&lt;li&gt;Respect human expertise&lt;/li&gt;
&lt;li&gt;Log decisions&lt;/li&gt;
&lt;li&gt;Learn from corrections&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bad HITL systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Treat humans as rubber stamps&lt;/li&gt;
&lt;li&gt;Overload reviewers&lt;/li&gt;
&lt;li&gt;Hide model uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-fairness-metrics-high-level&#34;&gt;âš–ï¸ Fairness Metrics (High-Level)&lt;/h2&gt;
&lt;p&gt;Common notions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Demographic parity&lt;/li&gt;
&lt;li&gt;Equal opportunity&lt;/li&gt;
&lt;li&gt;Equalized odds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;âš ï¸ Important:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You &lt;strong&gt;cannot satisfy all fairness definitions simultaneously&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ethics requires &lt;em&gt;choices&lt;/em&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-accountability--responsibility&#34;&gt;ğŸ§  Accountability &amp;amp; Responsibility&lt;/h2&gt;
&lt;p&gt;Key questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is responsible for errors?&lt;/li&gt;
&lt;li&gt;Who audits the system?&lt;/li&gt;
&lt;li&gt;Who can appeal decisions?&lt;/li&gt;
&lt;li&gt;Who benefits?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AI shifts power â€” ethics decides where it goes.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-regulation--governance-brief&#34;&gt;ğŸ“œ Regulation &amp;amp; Governance (Brief)&lt;/h2&gt;
&lt;p&gt;Trends:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI Act (EU)&lt;/li&gt;
&lt;li&gt;Model cards&lt;/li&gt;
&lt;li&gt;Data sheets&lt;/li&gt;
&lt;li&gt;Audit trails&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Purpose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transparency&lt;/li&gt;
&lt;li&gt;Safety&lt;/li&gt;
&lt;li&gt;Human rights protection&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight&#34;&gt;ğŸ§  Research Insight&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The most dangerous AI is not malicious â€”
it is &lt;strong&gt;confident, biased, and unchecked&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Future AI research must integrate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ethics-by-design&lt;/li&gt;
&lt;li&gt;Value alignment&lt;/li&gt;
&lt;li&gt;Continuous monitoring&lt;/li&gt;
&lt;li&gt;Human agency&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;Does AI create bias?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;No. It amplifies existing bias in data and systems.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is NOT a type of bias?&lt;/p&gt;
&lt;p&gt;A. Data bias
B. Annotation bias
C. Hardware bias
D. Deployment bias&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Hardware bias&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;When is HITL most important?&lt;/p&gt;
&lt;p&gt;A. Low-risk chatbots
B. Image filters
C. High-stakes decisions
D. Games&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. High-stakes decisions&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is automation bias?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Humans over-trusting AI outputs without critical thinking.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is uncertainty important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It signals when human review is needed.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If AI becomes very powerful, what must always remain human?&lt;/summary&gt;
  &lt;p&gt;Values, responsibility, empathy, and moral judgment.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-takeaways&#34;&gt;âœ… Key Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bias is systemic, not accidental&lt;/li&gt;
&lt;li&gt;Multimodal AI increases ethical risk&lt;/li&gt;
&lt;li&gt;HITL is a design principle, not a patch&lt;/li&gt;
&lt;li&gt;Fairness requires trade-offs&lt;/li&gt;
&lt;li&gt;Humans must remain accountable&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 11 â€” Sharing Your Multimodal Model with the World (Hugging Face)</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-11-share-on-huggingface/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-11-share-on-huggingface/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~3â€“4 hours (practical + community impact lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-sharing-models-matters&#34;&gt;ğŸŒ Why Sharing Models Matters&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Knowledge hidden is knowledge wasted.&lt;br&gt;
Knowledge shared becomes civilization.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By sharing your model, you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸŒ± Give others a starting point&lt;/li&gt;
&lt;li&gt;ğŸ”¬ Enable reproducibility&lt;/li&gt;
&lt;li&gt;ğŸ§  Accelerate research&lt;/li&gt;
&lt;li&gt;â¤ï¸ Give back to the open-source community&lt;/li&gt;
&lt;li&gt;ğŸ› Build scientific trust&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Hugging Face is the &lt;strong&gt;GitHub of AI&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-hugging-face&#34;&gt;ğŸ¤— What Is Hugging Face?&lt;/h2&gt;
&lt;p&gt;Hugging Face is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;model hub&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;dataset hub&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;community&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;deployment platform&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Used by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Researchers&lt;/li&gt;
&lt;li&gt;Startups&lt;/li&gt;
&lt;li&gt;Universities&lt;/li&gt;
&lt;li&gt;Enterprises&lt;/li&gt;
&lt;li&gt;Open science communities&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-can-you-share&#34;&gt;ğŸ§© What Can You Share?&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Artifact&lt;/th&gt;
&lt;th&gt;Examples&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Models&lt;/td&gt;
&lt;td&gt;LLMs, vision models, multimodal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adapters&lt;/td&gt;
&lt;td&gt;LoRA, QLoRA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tokenizers&lt;/td&gt;
&lt;td&gt;Custom vocab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datasets&lt;/td&gt;
&lt;td&gt;Imageâ€“text, DocQA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spaces&lt;/td&gt;
&lt;td&gt;Demos (Gradio, Streamlit)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;You donâ€™t need a giant model to contribute.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-1--create-a-hugging-face-account&#34;&gt;ğŸªª Step 1 â€” Create a Hugging Face Account&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Go to ğŸ¤— Hugging Face&lt;/li&gt;
&lt;li&gt;Sign up&lt;/li&gt;
&lt;li&gt;Verify email&lt;/li&gt;
&lt;li&gt;Choose a &lt;strong&gt;clear username&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This username becomes your &lt;strong&gt;AI identity&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-2--generate-an-access-token&#34;&gt;ğŸ”‘ Step 2 â€” Generate an Access Token&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Settings â†’ Access Tokens&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Create a token:
&lt;ul&gt;
&lt;li&gt;Type: &lt;em&gt;Write&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Save it securely&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Treat this like a GitHub SSH key.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-3--install-required-tools&#34;&gt;ğŸ–¥ Step 3 â€” Install Required Tools&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install huggingface_hub transformers datasets accelerate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Login from terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;huggingface-cli login
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Paste your token when prompted.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-4--prepare-your-model-folder&#34;&gt;ğŸ“¦ Step 4 â€” Prepare Your Model Folder&lt;/h2&gt;
&lt;p&gt;Minimum structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my-multimodal-model/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin (or model.safetensors)
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ README.md
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For LoRA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Base model is referenced&lt;/li&gt;
&lt;li&gt;Only adapter weights uploaded&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-5--write-a-good-readme-very-important&#34;&gt;ğŸ§  Step 5 â€” Write a GOOD README (VERY IMPORTANT)&lt;/h2&gt;
&lt;p&gt;Your README is your &lt;strong&gt;scientific voice&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Must include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What the model does&lt;/li&gt;
&lt;li&gt;Training data&lt;/li&gt;
&lt;li&gt;Intended use&lt;/li&gt;
&lt;li&gt;Limitations&lt;/li&gt;
&lt;li&gt;Ethical considerations&lt;/li&gt;
&lt;li&gt;How to run inference&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-readme-skeleton&#34;&gt;âœï¸ README Skeleton&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-md&#34;&gt;# Model Name

## Overview
This model is a multimodal Videoâ€“Text model trained for ...

## Architecture
- Vision encoder: ViT
- Temporal encoder: Transformer
- LLM: LLaMA-based

## Training
- Dataset: ...
- Strategy: Fine-tuning with LoRA

## Usage
```python
# example code
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;May hallucinate&lt;/li&gt;
&lt;li&gt;Not for medical use&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ethics&#34;&gt;Ethics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Human review recommended&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;
&amp;gt; **A bad README harms trust.**

---

## ğŸš€ Step 6 â€” Push Model to Hugging Face

### Option A: Push via Python

```python
from huggingface_hub import HfApi

api = HfApi()
api.create_repo(
    repo_id=&amp;quot;username/my-multimodal-model&amp;quot;,
    private=False
)

api.upload_folder(
    folder_path=&amp;quot;my-multimodal-model&amp;quot;,
    repo_id=&amp;quot;username/my-multimodal-model&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;option-b-push-via-transformers&#34;&gt;Option B: Push via &lt;code&gt;transformers&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model.push_to_hub(&amp;quot;username/my-multimodal-model&amp;quot;)
tokenizer.push_to_hub(&amp;quot;username/my-multimodal-model&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-7--verify-on-the-hub&#34;&gt;ğŸ§ª Step 7 â€” Verify on the Hub&lt;/h2&gt;
&lt;p&gt;Check:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Files are visible&lt;/li&gt;
&lt;li&gt;README renders correctly&lt;/li&gt;
&lt;li&gt;Inference example works&lt;/li&gt;
&lt;li&gt;License is correct&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If users cannot run it, it doesnâ€™t exist.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-8--choose-the-right-license&#34;&gt;âš–ï¸ Step 8 â€” Choose the Right License&lt;/h2&gt;
&lt;p&gt;Common licenses:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;License&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Apache 2.0&lt;/td&gt;
&lt;td&gt;Very permissive&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MIT&lt;/td&gt;
&lt;td&gt;Simple &amp;amp; permissive&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CC-BY&lt;/td&gt;
&lt;td&gt;Attribution required&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CC-BY-NC&lt;/td&gt;
&lt;td&gt;Non-commercial only&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Licensing is &lt;strong&gt;ethical engineering&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-9--create-a-demo-hugging-face-spaces&#34;&gt;ğŸ® Step 9 â€” Create a Demo (Hugging Face Spaces)&lt;/h2&gt;
&lt;p&gt;Using &lt;strong&gt;Gradio&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import gradio as gr

def predict(image, question):
    return model_answer

gr.Interface(
    fn=predict,
    inputs=[&amp;quot;image&amp;quot;, &amp;quot;text&amp;quot;],
    outputs=&amp;quot;text&amp;quot;
).launch()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Push to a Space:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Public demo&lt;/li&gt;
&lt;li&gt;No installation needed&lt;/li&gt;
&lt;li&gt;Massive visibility&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-step-10--share-responsibly&#34;&gt;ğŸ§  Step 10 â€” Share Responsibly&lt;/h2&gt;
&lt;p&gt;Before sharing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;â“ Does it hallucinate?&lt;/li&gt;
&lt;li&gt;âš ï¸ Is it biased?&lt;/li&gt;
&lt;li&gt;ğŸ§ª Is evaluation documented?&lt;/li&gt;
&lt;li&gt;ğŸ‘¤ Is HITL required?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Responsible release &amp;gt; Fast release&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-becoming-a-good-open-source-citizen&#34;&gt;ğŸŒ± Becoming a Good Open-Source Citizen&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Respond to issues&lt;/li&gt;
&lt;li&gt;Accept pull requests&lt;/li&gt;
&lt;li&gt;Document failures&lt;/li&gt;
&lt;li&gt;Credit datasets&lt;/li&gt;
&lt;li&gt;Cite inspirations&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Open-source is &lt;strong&gt;a conversation, not a drop&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-research-insight&#34;&gt;ğŸ§  Research Insight&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The future of AI belongs to those who &lt;strong&gt;share early, share honestly, and share responsibly&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Impact â‰  model size
Impact = &lt;strong&gt;clarity + usefulness + ethics&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is README important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It explains usage, limitations, and builds trust.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which token permission is needed to upload models?&lt;/p&gt;
&lt;p&gt;A. Read
B. Execute
C. Write
D. Admin&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Write&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which tool creates public demos?&lt;/p&gt;
&lt;p&gt;A. WandB
B. Gradio
C. Docker
D. Kaggle&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Gradio&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is licensing important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It defines how others may legally use your work.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is responsible release?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Sharing models with transparency, limitations, and ethical care.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection-course-ending&#34;&gt;ğŸŒ± Final Reflection (Course Ending)&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If your model helps even one person learn, was it worth sharing?&lt;/summary&gt;
  &lt;p&gt;Yes. Knowledge shared multiplies impact.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways&#34;&gt;ğŸ Final Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sharing completes the research cycle&lt;/li&gt;
&lt;li&gt;Hugging Face is the global AI commons&lt;/li&gt;
&lt;li&gt;Documentation is ethics&lt;/li&gt;
&lt;li&gt;Community is intelligence&lt;/li&gt;
&lt;li&gt;You are now a contributor, not just a user&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 12 â€” Encoder, Decoder, and the Truth About How LLMs Are Trained</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-12-encoder-decoder-in-llms/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-12-encoder-decoder-in-llms/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~4â€“5 hours (core understanding lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-exists&#34;&gt;ğŸ§  Why This Lecture Exists&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Almost everyone uses LLMs.&lt;br&gt;
Very few understand how they are actually built.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Common confusion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;â€œIs ChatGPT encoderâ€“decoder?â€&lt;/li&gt;
&lt;li&gt;â€œWhy only decoder?â€&lt;/li&gt;
&lt;li&gt;â€œWhat does freezing weights really mean?â€&lt;/li&gt;
&lt;li&gt;â€œHow does multimodal fit into this?â€&lt;/li&gt;
&lt;li&gt;â€œWhat exactly am I training when I fine-tune?â€&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This lecture answers &lt;strong&gt;all of that â€” clearly, from first principles&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-the-original-transformer-2017&#34;&gt;ğŸ§© The Original Transformer (2017)&lt;/h2&gt;
&lt;p&gt;The original Transformer had &lt;strong&gt;two parts&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Encoder  â†’  Decoder

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;encoder&#34;&gt;Encoder&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Reads the input&lt;/li&gt;
&lt;li&gt;Understands meaning&lt;/li&gt;
&lt;li&gt;Produces representations&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;decoder&#34;&gt;Decoder&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Generates output tokens&lt;/li&gt;
&lt;li&gt;Uses attention + autoregression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was designed for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine Translation&lt;/li&gt;
&lt;li&gt;Summarization&lt;/li&gt;
&lt;li&gt;Seq2Seq tasks&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-encoder-what-is-it-really-doing&#34;&gt;ğŸ§  Encoder: What Is It Really Doing?&lt;/h2&gt;
&lt;p&gt;Encoder properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sees the &lt;strong&gt;entire input at once&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Bidirectional attention&lt;/li&gt;
&lt;li&gt;Builds rich representations&lt;/li&gt;
&lt;li&gt;Does &lt;strong&gt;not generate text&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BERT&lt;/li&gt;
&lt;li&gt;RoBERTa&lt;/li&gt;
&lt;li&gt;ViT (vision encoder)&lt;/li&gt;
&lt;li&gt;Audio encoders&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Encoders understand. They donâ€™t speak.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-decoder-what-is-it-really-doing&#34;&gt;ğŸ§  Decoder: What Is It Really Doing?&lt;/h2&gt;
&lt;p&gt;Decoder properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generates tokens &lt;strong&gt;one by one&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Causal (masked) attention&lt;/li&gt;
&lt;li&gt;Autoregressive&lt;/li&gt;
&lt;li&gt;Can reason, plan, and explain&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPT&lt;/li&gt;
&lt;li&gt;LLaMA&lt;/li&gt;
&lt;li&gt;Mistral&lt;/li&gt;
&lt;li&gt;Qwen&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Decoders speak, reason, and act.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-chatgpt-is-decoder-only&#34;&gt;â“ Why ChatGPT Is Decoder-Only&lt;/h2&gt;
&lt;p&gt;Key insight:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If you want open-ended generation, you only need a decoder.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decoder can read context (prompt)&lt;/li&gt;
&lt;li&gt;Decoder can generate indefinitely&lt;/li&gt;
&lt;li&gt;Encoder is not required for generation&lt;/li&gt;
&lt;li&gt;Simpler architecture&lt;/li&gt;
&lt;li&gt;Scales better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So ChatGPT is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Text â†’ Decoder â†’ Next Token â†’ Next Token â†’ ...

&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-decoder-only-training-gpt-style&#34;&gt;ğŸ§  Decoder-Only Training (GPT Style)&lt;/h2&gt;
&lt;p&gt;Training objective:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Predict the next token&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;&amp;quot;I love deep&amp;quot; â†’ predict &amp;quot;learning&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This single objective leads to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Language understanding&lt;/li&gt;
&lt;li&gt;Reasoning&lt;/li&gt;
&lt;li&gt;Code generation&lt;/li&gt;
&lt;li&gt;Planning&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Understanding emerges from generation.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-encoderdecoder-models-still-important&#34;&gt;ğŸ§© Encoderâ€“Decoder Models (Still Important!)&lt;/h2&gt;
&lt;p&gt;Encoderâ€“decoder models are still used when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input â‰  output&lt;/li&gt;
&lt;li&gt;Strong alignment is required&lt;/li&gt;
&lt;li&gt;Input is very long or structured&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T5&lt;/li&gt;
&lt;li&gt;FLAN-T5&lt;/li&gt;
&lt;li&gt;Whisper (audio â†’ text)&lt;/li&gt;
&lt;li&gt;Translation systems&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-multimodal-llms-the-hybrid-truth&#34;&gt;ğŸ§  Multimodal LLMs: The Hybrid Truth&lt;/h2&gt;
&lt;p&gt;Most multimodal LLMs are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Encoder (image/audio/video)
        â†“
Projection / Adapter
        â†“
Decoder-only LLM
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CLIP â†’ LLaMA&lt;/li&gt;
&lt;li&gt;ViT â†’ GPT&lt;/li&gt;
&lt;li&gt;Audio encoder â†’ LLM&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Multimodal models are encoderâ€“decoder systems,
but the decoder is still the brain.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-encoders-are-usually-frozen&#34;&gt;ğŸ”— Why Encoders Are Usually Frozen&lt;/h2&gt;
&lt;p&gt;Encoders:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretrained on massive data&lt;/li&gt;
&lt;li&gt;Expensive to retrain&lt;/li&gt;
&lt;li&gt;General-purpose&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we often:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;â„ï¸ Freeze encoder&lt;/li&gt;
&lt;li&gt;ğŸ”§ Train adapter / projector&lt;/li&gt;
&lt;li&gt;ğŸ§  Fine-tune decoder lightly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This saves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute&lt;/li&gt;
&lt;li&gt;Data&lt;/li&gt;
&lt;li&gt;Stability&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-what-is-actually-trained-very-important&#34;&gt;ğŸ§  What Is Actually Trained? (Very Important)&lt;/h2&gt;
&lt;h3 id=&#34;pretraining&#34;&gt;Pretraining&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Train &lt;strong&gt;all weights&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Massive data&lt;/li&gt;
&lt;li&gt;Extremely expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fine-tuning&#34;&gt;Fine-tuning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Train &lt;strong&gt;some weights&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Task-specific data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;instruction-tuning&#34;&gt;Instruction tuning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Train decoder to follow instructions&lt;/li&gt;
&lt;li&gt;Often freezes most layers&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-freezing-strategies&#34;&gt;ğŸ§© Freezing Strategies&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Strategy&lt;/th&gt;
&lt;th&gt;What Moves&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Full fine-tune&lt;/td&gt;
&lt;td&gt;Everything&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Freeze encoder&lt;/td&gt;
&lt;td&gt;Decoder only&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LoRA&lt;/td&gt;
&lt;td&gt;Small rank matrices&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adapters&lt;/td&gt;
&lt;td&gt;Tiny modules&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prompt tuning&lt;/td&gt;
&lt;td&gt;No weights&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Most real-world systems do NOT full fine-tune.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-example-freezing-encoder&#34;&gt;ğŸ Example: Freezing Encoder&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for param in vision_encoder.parameters():
    param.requires_grad = False
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then train:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Projection layer&lt;/li&gt;
&lt;li&gt;LLM LoRA weights&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-lora-explained-simply&#34;&gt;ğŸ§  LoRA Explained Simply&lt;/h2&gt;
&lt;p&gt;LoRA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Injects low-rank matrices&lt;/li&gt;
&lt;li&gt;Keeps original weights frozen&lt;/li&gt;
&lt;li&gt;Learns task-specific behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cheap&lt;/li&gt;
&lt;li&gt;Stable&lt;/li&gt;
&lt;li&gt;Shareable&lt;/li&gt;
&lt;li&gt;Reversible&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;LoRA is how the world fine-tunes LLMs today.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-not-encoder-only-llms&#34;&gt;â“ Why Not Encoder-Only LLMs?&lt;/h2&gt;
&lt;p&gt;Encoder-only models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cannot generate freely&lt;/li&gt;
&lt;li&gt;Need a decoder for output&lt;/li&gt;
&lt;li&gt;Not conversational&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thatâ€™s why:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BERT â‰  ChatGPT&lt;/li&gt;
&lt;li&gt;ViT â‰  multimodal assistant&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-mental-model-remember-this-forever&#34;&gt;ğŸ§  Mental Model (Remember This Forever)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Role&lt;/th&gt;
&lt;th&gt;Model Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Understand&lt;/td&gt;
&lt;td&gt;Encoder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reason&lt;/td&gt;
&lt;td&gt;Decoder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Speak&lt;/td&gt;
&lt;td&gt;Decoder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Act&lt;/td&gt;
&lt;td&gt;Decoder + Tools&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;See&lt;/td&gt;
&lt;td&gt;Vision Encoder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hear&lt;/td&gt;
&lt;td&gt;Audio Encoder&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-student-knowledge-check-hidden&#34;&gt;ğŸ§ª Student Knowledge Check (Hidden)&lt;/h2&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why can ChatGPT work without an encoder?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Because a decoder can read context and generate text autoregressively.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which model is encoder-only?&lt;/p&gt;
&lt;p&gt;A. GPT
B. LLaMA
C. BERT
D. ChatGPT&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. BERT&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--mcq&#34;&gt;Q3 â€” MCQ&lt;/h3&gt;
&lt;p&gt;What is usually frozen in multimodal LLMs?&lt;/p&gt;
&lt;p&gt;A. Decoder
B. Encoder
C. Tokenizer
D. Loss function&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Encoder&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--objective&#34;&gt;Q4 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why use LoRA instead of full fine-tuning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To reduce cost, preserve knowledge, and improve stability.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;Who is the â€œbrainâ€ of a multimodal LLM?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;The decoder-only LLM.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-reflection&#34;&gt;ğŸŒ± Final Reflection&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;If intelligence emerges from predicting the next token, what does that say about human thinking?&lt;/summary&gt;
  &lt;p&gt;That reasoning may emerge from sequence prediction guided by experience.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-takeaways-burn-this-in&#34;&gt;âœ… Final Takeaways (Burn This In)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ChatGPT is &lt;strong&gt;decoder-only&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Encoders understand, decoders generate&lt;/li&gt;
&lt;li&gt;Multimodal = encoders + decoder brain&lt;/li&gt;
&lt;li&gt;Freezing is strategy, not weakness&lt;/li&gt;
&lt;li&gt;Fine-tuning is about &lt;em&gt;what to move&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Lecture 13 â€” Real-World LLM Engineer &amp; Research Scientist Interview (Top Tech Level)</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-13-llm-interview/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-13-llm-interview/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~6â€“8 hours (elite interview preparation)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-lecture-exists&#34;&gt;ğŸ¯ Why This Lecture Exists&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Top tech companies do not test tools.&lt;br&gt;
They test thinking.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This lecture simulates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI&lt;/li&gt;
&lt;li&gt;Google DeepMind / Gemini&lt;/li&gt;
&lt;li&gt;Anthropic&lt;/li&gt;
&lt;li&gt;Meta FAIR&lt;/li&gt;
&lt;li&gt;Microsoft Research&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Focus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fundamentals&lt;/li&gt;
&lt;li&gt;Architecture&lt;/li&gt;
&lt;li&gt;Training&lt;/li&gt;
&lt;li&gt;Evaluation&lt;/li&gt;
&lt;li&gt;Safety&lt;/li&gt;
&lt;li&gt;Systems thinking&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;-part-i--core-llm-architecture-q1q10&#34;&gt;ğŸ§  Part I â€” Core LLM Architecture (Q1â€“Q10)&lt;/h1&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q1-mcq&#34;&gt;Q1 (MCQ)&lt;/h3&gt;
&lt;p&gt;Why are most modern LLMs &lt;em&gt;decoder-only&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;A. Encoders are too slow&lt;br&gt;
B. Decoders can model autoregressive generation&lt;br&gt;
C. Encoders cannot scale&lt;br&gt;
D. Decoders use less memory&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Decoder-only models naturally support autoregressive next-token prediction, which aligns perfectly with text generation.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2-objective&#34;&gt;Q2 (Objective)&lt;/h3&gt;
&lt;p&gt;What does â€œautoregressiveâ€ mean in LLMs?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Predicting the next token conditioned on all previous tokens; generation proceeds sequentially.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3-mcq&#34;&gt;Q3 (MCQ)&lt;/h3&gt;
&lt;p&gt;What mask is used in decoder self-attention?&lt;/p&gt;
&lt;p&gt;A. Padding mask&lt;br&gt;
B. Causal (look-ahead) mask&lt;br&gt;
C. Bidirectional mask&lt;br&gt;
D. Cross-attention mask&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Causal masks prevent the model from seeing future tokens during training.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4-objective&#34;&gt;Q4 (Objective)&lt;/h3&gt;
&lt;p&gt;Why are encoders still useful in multimodal systems?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Encoders excel at representation learning (images, audio, documents) which can be fused into LLMs.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5-mcq&#34;&gt;Q5 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which model is encoderâ€“decoder?&lt;/p&gt;
&lt;p&gt;A. GPT-4&lt;br&gt;
B. LLaMA&lt;br&gt;
C. T5&lt;br&gt;
D. PaLM&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. T5 uses an encoderâ€“decoder Transformer architecture.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q6-objective&#34;&gt;Q6 (Objective)&lt;/h3&gt;
&lt;p&gt;What is the role of positional encoding?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It injects token order information into attention-based models which are otherwise permutation-invariant.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q7-mcq&#34;&gt;Q7 (MCQ)&lt;/h3&gt;
&lt;p&gt;Why is self-attention preferred over RNNs?&lt;/p&gt;
&lt;p&gt;A. Faster training&lt;br&gt;
B. Parallelism&lt;br&gt;
C. Long-range dependency modeling&lt;br&gt;
D. All of the above&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;. Self-attention improves speed, scalability, and contextual understanding.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q8-objective&#34;&gt;Q8 (Objective)&lt;/h3&gt;
&lt;p&gt;What limits context length in Transformers?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Quadratic attention cost in sequence length (O(nÂ²)).&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q9-mcq&#34;&gt;Q9 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which improves long-context handling?&lt;/p&gt;
&lt;p&gt;A. FlashAttention&lt;br&gt;
B. Sparse attention&lt;br&gt;
C. RoPE&lt;br&gt;
D. All of the above&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;. Each addresses efficiency or extrapolation in long contexts.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q10-objective&#34;&gt;Q10 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is decoder-only dominant for chat models?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-10&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It unifies understanding and generation into a single autoregressive process.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h1 id=&#34;-part-ii--training--fine-tuning-q11q20&#34;&gt;ğŸ”¥ Part II â€” Training &amp;amp; Fine-Tuning (Q11â€“Q20)&lt;/h1&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q11-mcq&#34;&gt;Q11 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is the pretraining objective of GPT-like models?&lt;/p&gt;
&lt;p&gt;A. Masked language modeling&lt;br&gt;
B. Next token prediction&lt;br&gt;
C. Sentence classification&lt;br&gt;
D. Contrastive loss&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-11&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. GPT models are trained to predict the next token autoregressively.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q12-objective&#34;&gt;Q12 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is pretraining so expensive?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-12&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It requires massive datasets, compute, and long optimization cycles.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q13-mcq&#34;&gt;Q13 (MCQ)&lt;/h3&gt;
&lt;p&gt;What does fine-tuning change?&lt;/p&gt;
&lt;p&gt;A. Model architecture&lt;br&gt;
B. Tokenizer&lt;br&gt;
C. Weights&lt;br&gt;
D. Loss function only&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-13&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Fine-tuning updates weights to adapt behavior.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q14-objective&#34;&gt;Q14 (Objective)&lt;/h3&gt;
&lt;p&gt;What is catastrophic forgetting?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-14&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;When fine-tuning overwrites previously learned knowledge.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q15-mcq&#34;&gt;Q15 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which method reduces forgetting?&lt;/p&gt;
&lt;p&gt;A. Lower learning rate&lt;br&gt;
B. Freezing layers&lt;br&gt;
C. LoRA&lt;br&gt;
D. All of the above&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-15&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;. Each constrains weight updates.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q16-objective&#34;&gt;Q16 (Objective)&lt;/h3&gt;
&lt;p&gt;What is LoRA?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-16&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Low-Rank Adaptation: fine-tuning via small rank-decomposed matrices.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q17-mcq&#34;&gt;Q17 (MCQ)&lt;/h3&gt;
&lt;p&gt;Why freeze base model weights?&lt;/p&gt;
&lt;p&gt;A. Save memory&lt;br&gt;
B. Prevent overfitting&lt;br&gt;
C. Preserve general knowledge&lt;br&gt;
D. All of the above&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-17&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;. Freezing improves stability and efficiency.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q18-objective&#34;&gt;Q18 (Objective)&lt;/h3&gt;
&lt;p&gt;Difference between instruction tuning and pretraining?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-18&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Instruction tuning aligns model behavior to human instructions rather than raw text prediction.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q19-mcq&#34;&gt;Q19 (MCQ)&lt;/h3&gt;
&lt;p&gt;What does RLHF optimize?&lt;/p&gt;
&lt;p&gt;A. Accuracy&lt;br&gt;
B. Likelihood&lt;br&gt;
C. Human preference&lt;br&gt;
D. Latency&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-19&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. RLHF aligns outputs with human feedback.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q20-objective&#34;&gt;Q20 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is RLHF unstable?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-20&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Reward models are imperfect and can be exploited.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h1 id=&#34;-part-iii--systems-safety--evaluation-q21q35&#34;&gt;ğŸ§  Part III â€” Systems, Safety &amp;amp; Evaluation (Q21â€“Q35)&lt;/h1&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q21-mcq&#34;&gt;Q21 (MCQ)&lt;/h3&gt;
&lt;p&gt;What causes hallucination most?&lt;/p&gt;
&lt;p&gt;A. Small models&lt;br&gt;
B. Lack of grounding&lt;br&gt;
C. Bad tokenizer&lt;br&gt;
D. Low temperature&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-21&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Hallucination arises from missing or unverified knowledge.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q22-objective&#34;&gt;Q22 (Objective)&lt;/h3&gt;
&lt;p&gt;How does RAG reduce hallucination?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-22&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;By grounding generation in retrieved external knowledge.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q23-mcq&#34;&gt;Q23 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which metric is worst for reasoning?&lt;/p&gt;
&lt;p&gt;A. BLEU&lt;br&gt;
B. ROUGE&lt;br&gt;
C. Exact Match&lt;br&gt;
D. Accuracy&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-23&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;. BLEU focuses on surface n-gram overlap.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q24-objective&#34;&gt;Q24 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is human evaluation critical?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-24&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Humans judge meaning, usefulness, and harm beyond metrics.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q25-mcq&#34;&gt;Q25 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is alignment?&lt;/p&gt;
&lt;p&gt;A. Model speed&lt;br&gt;
B. Model size&lt;br&gt;
C. Matching human values&lt;br&gt;
D. Token efficiency&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-25&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Alignment ensures AI behaves consistently with human intent.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q26-objective&#34;&gt;Q26 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is safety not solved by data alone?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-26&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Values are contextual, evolving, and require judgment.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q27-mcq&#34;&gt;Q27 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which is an agent failure?&lt;/p&gt;
&lt;p&gt;A. Wrong answer&lt;br&gt;
B. Tool misuse&lt;br&gt;
C. Infinite loop&lt;br&gt;
D. All of the above&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-27&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;. Agents introduce new failure modes.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q28-objective&#34;&gt;Q28 (Objective)&lt;/h3&gt;
&lt;p&gt;Why must agents be logged?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-28&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;For debugging, auditing, and accountability.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q29-mcq&#34;&gt;Q29 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is temperature?&lt;/p&gt;
&lt;p&gt;A. Training speed&lt;br&gt;
B. Randomness control&lt;br&gt;
C. Model size&lt;br&gt;
D. Loss scaling&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-29&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Temperature controls output diversity.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q30-objective&#34;&gt;Q30 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is low temperature risky?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-30&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It can amplify confident but wrong answers.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q31-mcq&#34;&gt;Q31 (MCQ)&lt;/h3&gt;
&lt;p&gt;Which improves long-context reasoning?&lt;/p&gt;
&lt;p&gt;A. Bigger model&lt;br&gt;
B. Better data&lt;br&gt;
C. Memory mechanisms&lt;br&gt;
D. UI design&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-31&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Memory and retrieval matter more than size.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q32-objective&#34;&gt;Q32 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is evaluation harder than training?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-32&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Correctness is ambiguous, contextual, and human-dependent.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q33-mcq&#34;&gt;Q33 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is distribution shift?&lt;/p&gt;
&lt;p&gt;A. Token drift&lt;br&gt;
B. Deployment data differs from training&lt;br&gt;
C. Model collapse&lt;br&gt;
D. Optimizer bug&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-33&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Real-world data rarely matches training data.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q34-objective&#34;&gt;Q34 (Objective)&lt;/h3&gt;
&lt;p&gt;How do you detect silent failures?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-34&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Stress tests, adversarial inputs, and monitoring.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q35-objective&#34;&gt;Q35 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is abstention important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-35&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Saying â€œI donâ€™t knowâ€ prevents harm and hallucination.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h1 id=&#34;-part-iv--research-mindset-q36q50&#34;&gt;ğŸŒ Part IV â€” Research Mindset (Q36â€“Q50)&lt;/h1&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q36-mcq&#34;&gt;Q36 (MCQ)&lt;/h3&gt;
&lt;p&gt;What makes a strong LLM researcher?&lt;/p&gt;
&lt;p&gt;A. Model size obsession&lt;br&gt;
B. Tool mastery&lt;br&gt;
C. Question formulation&lt;br&gt;
D. Coding speed&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-36&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Research starts with the right questions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q37-objective&#34;&gt;Q37 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is ablation important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-37&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It isolates which components actually matter.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q38-mcq&#34;&gt;Q38 (MCQ)&lt;/h3&gt;
&lt;p&gt;What does â€œscaling lawâ€ describe?&lt;/p&gt;
&lt;p&gt;A. Inference speed&lt;br&gt;
B. Relationship between compute, data, performance&lt;br&gt;
C. Model compression&lt;br&gt;
D. Tokenization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-38&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;. Scaling laws guide resource allocation.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q39-objective&#34;&gt;Q39 (Objective)&lt;/h3&gt;
&lt;p&gt;Why are smaller models still relevant?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-39&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;They are cheaper, faster, safer, and deployable.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q40-mcq&#34;&gt;Q40 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is the biggest unsolved problem?&lt;/p&gt;
&lt;p&gt;A. Accuracy&lt;br&gt;
B. Speed&lt;br&gt;
C. Alignment&lt;br&gt;
D. UI&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-40&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Alignment is fundamentally human and societal.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q41-objective&#34;&gt;Q41 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is interpretability important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-41&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;To trust, debug, and regulate AI systems.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q42-mcq&#34;&gt;Q42 (MCQ)&lt;/h3&gt;
&lt;p&gt;What does â€œemergent behaviorâ€ mean?&lt;/p&gt;
&lt;p&gt;A. Bugs&lt;br&gt;
B. Overfitting&lt;br&gt;
C. Capabilities appearing at scale&lt;br&gt;
D. Prompt tricks&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-42&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. New abilities emerge non-linearly with scale.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q43-objective&#34;&gt;Q43 (Objective)&lt;/h3&gt;
&lt;p&gt;Why are benchmarks insufficient?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-43&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;They fail to represent real-world complexity.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q44-mcq&#34;&gt;Q44 (MCQ)&lt;/h3&gt;
&lt;p&gt;What defines a good LLM system?&lt;/p&gt;
&lt;p&gt;A. Model size&lt;br&gt;
B. Latency&lt;br&gt;
C. User trust&lt;br&gt;
D. Parameter count&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-44&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Trust defines real adoption.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q45-objective&#34;&gt;Q45 (Objective)&lt;/h3&gt;
&lt;p&gt;Why must humans stay in the loop?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-45&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;AI lacks values, responsibility, and moral judgment.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q46-mcq&#34;&gt;Q46 (MCQ)&lt;/h3&gt;
&lt;p&gt;What will differentiate future LLMs?&lt;/p&gt;
&lt;p&gt;A. Bigger GPUs&lt;br&gt;
B. Better prompts&lt;br&gt;
C. Better systems &amp;amp; alignment&lt;br&gt;
D. More tokens&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-46&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Systems and alignment matter more than scale.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q47-objective&#34;&gt;Q47 (Objective)&lt;/h3&gt;
&lt;p&gt;What mindset do interviewers seek?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-47&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Clarity, humility, rigor, and responsibility.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q48-mcq&#34;&gt;Q48 (MCQ)&lt;/h3&gt;
&lt;p&gt;What is a red flag in interviews?&lt;/p&gt;
&lt;p&gt;A. Admitting uncertainty&lt;br&gt;
B. Asking questions&lt;br&gt;
C. Overconfidence&lt;br&gt;
D. Thoughtful pauses&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-48&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;. Overconfidence signals lack of depth.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q49-objective&#34;&gt;Q49 (Objective)&lt;/h3&gt;
&lt;p&gt;Why is â€œI donâ€™t knowâ€ powerful?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-49&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;It shows intellectual honesty and growth mindset.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q50-final-reflection&#34;&gt;Q50 (Final Reflection)&lt;/h3&gt;
&lt;p&gt;What makes a great LLM engineer?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-50&#34;&gt;
  &lt;summary&gt;Answer + Explanation&lt;/summary&gt;
  &lt;p&gt;Someone who combines technical mastery, ethical responsibility, and human-centered thinking.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-words&#34;&gt;ğŸŒ± Final Words&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;You are not training models.&lt;br&gt;
You are shaping intelligence.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Build wisely.&lt;br&gt;
Question deeply.&lt;br&gt;
Stay human.&lt;/p&gt;
&lt;p&gt;â¤ï¸&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
---&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Lecture 14 â€” Deep Learning Foundations &amp; Modern AI (Final Mastery)</title>
      <link>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-14-deep-learning-modern-ai-final/</link>
      <pubDate>Thu, 01 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://kaopanboonyuen.github.io/courses/2026-01-01-llm-multimodal/lecture-14-deep-learning-modern-ai-final/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; ~5â€“6 hours (final synthesis lecture)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-this-final-lecture-exists&#34;&gt;ğŸŒ Why This Final Lecture Exists&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Strong AI engineers are built on fundamentals.&lt;br&gt;
Great AI leaders are built on understanding + responsibility.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This lecture revisits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Core deep learning&lt;/li&gt;
&lt;li&gt;Modern LLM-era AI&lt;/li&gt;
&lt;li&gt;Common misconceptions&lt;/li&gt;
&lt;li&gt;Interview-level clarity&lt;/li&gt;
&lt;li&gt;First-principles thinking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you master this lecture, you are no longer &lt;em&gt;confused by trends&lt;/em&gt; â€”&lt;br&gt;
you &lt;strong&gt;understand the machine&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-part-i--deep-learning-foundations-q1q25&#34;&gt;ğŸ§  PART I â€” Deep Learning Foundations (Q1â€“Q25)&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q1--objective&#34;&gt;Q1 â€” Objective&lt;/h3&gt;
&lt;p&gt;What problem does gradient descent solve?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It minimizes a loss function by iteratively updating model parameters.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q2--mcq&#34;&gt;Q2 â€” MCQ&lt;/h3&gt;
&lt;p&gt;What is backpropagation?&lt;/p&gt;
&lt;p&gt;A. Data normalization&lt;br&gt;
B. Gradient computation via chain rule&lt;br&gt;
C. Weight initialization&lt;br&gt;
D. Loss regularization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Gradient computation via chain rule&lt;br&gt;
Backprop efficiently computes gradients for all parameters.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q3--objective&#34;&gt;Q3 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why do we need activation functions?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To introduce non-linearity so neural networks can model complex functions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q4--mcq&#34;&gt;Q4 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which activation helps mitigate vanishing gradients?&lt;/p&gt;
&lt;p&gt;A. Sigmoid&lt;br&gt;
B. Tanh&lt;br&gt;
C. ReLU&lt;br&gt;
D. Softmax&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. ReLU&lt;br&gt;
It preserves gradients for positive inputs.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q5--objective&#34;&gt;Q5 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is overfitting?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;When a model performs well on training data but poorly on unseen data.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q6--mcq&#34;&gt;Q6 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which technique reduces overfitting?&lt;/p&gt;
&lt;p&gt;A. Increasing epochs&lt;br&gt;
B. Dropout&lt;br&gt;
C. Larger batch size&lt;br&gt;
D. Removing regularization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Dropout&lt;br&gt;
It prevents co-adaptation of neurons.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q7--objective&#34;&gt;Q7 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is batch normalization useful?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It stabilizes training by normalizing intermediate activations.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q8--mcq&#34;&gt;Q8 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which optimizer adapts learning rates per parameter?&lt;/p&gt;
&lt;p&gt;A. SGD&lt;br&gt;
B. Momentum&lt;br&gt;
C. Adam&lt;br&gt;
D. Newton&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Adam&lt;br&gt;
Adam combines momentum and adaptive scaling.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q9--objective&#34;&gt;Q9 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is the biasâ€“variance tradeoff?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-9&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;The balance between underfitting (high bias) and overfitting (high variance).&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q10--mcq&#34;&gt;Q10 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which loss is best for classification?&lt;/p&gt;
&lt;p&gt;A. MSE&lt;br&gt;
B. Cross-entropy&lt;br&gt;
C. Hinge (always)&lt;br&gt;
D. L1&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-10&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Cross-entropy&lt;br&gt;
It aligns with probabilistic outputs.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q11--objective&#34;&gt;Q11 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is data scaling important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-11&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It improves convergence speed and numerical stability.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q12--mcq&#34;&gt;Q12 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which network handles sequences best (classically)?&lt;/p&gt;
&lt;p&gt;A. CNN&lt;br&gt;
B. MLP&lt;br&gt;
C. RNN&lt;br&gt;
D. Autoencoder&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-12&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. RNN&lt;br&gt;
Designed to process sequential data.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q13--objective&#34;&gt;Q13 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is vanishing gradient?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-13&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;When gradients become too small to update earlier layers effectively.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q14--mcq&#34;&gt;Q14 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which architecture solved long-term dependency issues?&lt;/p&gt;
&lt;p&gt;A. Vanilla RNN&lt;br&gt;
B. CNN&lt;br&gt;
C. LSTM&lt;br&gt;
D. Perceptron&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-14&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. LSTM&lt;br&gt;
It uses gating mechanisms to preserve information.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q15--objective&#34;&gt;Q15 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is representation learning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-15&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Learning useful features automatically from data.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q16--mcq&#34;&gt;Q16 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which layer reduces spatial resolution?&lt;/p&gt;
&lt;p&gt;A. Convolution&lt;br&gt;
B. Pooling&lt;br&gt;
C. Attention&lt;br&gt;
D. Normalization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-16&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Pooling&lt;br&gt;
It aggregates spatial information.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q17--objective&#34;&gt;Q17 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why are deeper networks harder to train?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-17&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Due to gradient instability and optimization difficulty.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q18--mcq&#34;&gt;Q18 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which innovation enabled very deep networks?&lt;/p&gt;
&lt;p&gt;A. Sigmoid&lt;br&gt;
B. Residual connections&lt;br&gt;
C. Larger datasets&lt;br&gt;
D. Dropout&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-18&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Residual connections&lt;br&gt;
They allow gradients to flow directly.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q19--objective&#34;&gt;Q19 â€” Objective&lt;/h3&gt;
&lt;p&gt;What does regularization encourage?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-19&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Simpler models that generalize better.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q20--mcq&#34;&gt;Q20 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is NOT a regularization method?&lt;/p&gt;
&lt;p&gt;A. L2 penalty&lt;br&gt;
B. Dropout&lt;br&gt;
C. Data augmentation&lt;br&gt;
D. Increasing learning rate&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-20&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;D. Increasing learning rate&lt;br&gt;
It affects optimization, not regularization.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q21--objective&#34;&gt;Q21 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is transfer learning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-21&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Reusing knowledge from a pretrained model for a new task.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q22--mcq&#34;&gt;Q22 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Why freeze layers during fine-tuning?&lt;/p&gt;
&lt;p&gt;A. Reduce memory&lt;br&gt;
B. Prevent catastrophic forgetting&lt;br&gt;
C. Increase randomness&lt;br&gt;
D. Speed inference&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-22&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Prevent catastrophic forgetting&lt;br&gt;
Frozen layers preserve learned representations.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q23--objective&#34;&gt;Q23 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is catastrophic forgetting?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-23&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;When a model forgets old knowledge while learning new tasks.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q24--mcq&#34;&gt;Q24 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which setting usually needs the least data?&lt;/p&gt;
&lt;p&gt;A. Training from scratch&lt;br&gt;
B. Pretraining&lt;br&gt;
C. Fine-tuning&lt;br&gt;
D. Random initialization&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-24&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Fine-tuning&lt;br&gt;
It leverages pretrained knowledge.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q25--objective&#34;&gt;Q25 â€” Objective&lt;/h3&gt;
&lt;p&gt;What defines a good loss function?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-25&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It aligns optimization with the true task objective.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-part-ii--modern-ai--llm-era-q26q50&#34;&gt;ğŸš€ PART II â€” Modern AI &amp;amp; LLM Era (Q26â€“Q50)&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q26--mcq&#34;&gt;Q26 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which architecture dominates modern LLMs?&lt;/p&gt;
&lt;p&gt;A. CNN&lt;br&gt;
B. RNN&lt;br&gt;
C. Transformer&lt;br&gt;
D. Autoencoder&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-26&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Transformer&lt;br&gt;
It enables parallelism and long-range dependency modeling.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q27--objective&#34;&gt;Q27 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is self-attention powerful?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-27&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;It allows tokens to dynamically attend to relevant context.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q28--mcq&#34;&gt;Q28 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Decoder-only models are trained to:&lt;/p&gt;
&lt;p&gt;A. Encode inputs only&lt;br&gt;
B. Predict masked tokens&lt;br&gt;
C. Predict next token autoregressively&lt;br&gt;
D. Align image-text&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-28&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Predict next token autoregressively&lt;br&gt;
This is how GPT-style models are trained.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q29--objective&#34;&gt;Q29 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is pretraining in LLMs?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-29&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Training on massive unlabeled data to learn general language patterns.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q30--mcq&#34;&gt;Q30 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which dataset type is most common for LLM pretraining?&lt;/p&gt;
&lt;p&gt;A. Labeled QA&lt;br&gt;
B. Reinforcement signals&lt;br&gt;
C. Unlabeled text&lt;br&gt;
D. Synthetic only&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-30&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Unlabeled text&lt;br&gt;
Self-supervised learning scales best.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q31--objective&#34;&gt;Q31 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why does scale matter in LLMs?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-31&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Larger models show emergent abilities and better generalization.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q32--mcq&#34;&gt;Q32 â€” MCQ&lt;/h3&gt;
&lt;p&gt;What is fine-tuning?&lt;/p&gt;
&lt;p&gt;A. Changing architecture&lt;br&gt;
B. Training from scratch&lt;br&gt;
C. Adapting pretrained weights&lt;br&gt;
D. Prompt engineering&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-32&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Adapting pretrained weights&lt;br&gt;
Fine-tuning adjusts behavior for specific tasks.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q33--objective&#34;&gt;Q33 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is instruction tuning?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-33&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Fine-tuning models to follow human instructions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q34--mcq&#34;&gt;Q34 â€” MCQ&lt;/h3&gt;
&lt;p&gt;RLHF stands for:&lt;/p&gt;
&lt;p&gt;A. Reinforced Learning with Human Feedback&lt;br&gt;
B. Reinforcement Learning from Human Feedback&lt;br&gt;
C. Recurrent Learning from Human Feedback&lt;br&gt;
D. Regularized Learning from Human Feedback&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-34&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Reinforcement Learning from Human Feedback&lt;br&gt;
Used to align models with human preferences.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q35--objective&#34;&gt;Q35 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is alignment important?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-35&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To ensure AI behavior matches human values and intentions.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q36--mcq&#34;&gt;Q36 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which technique reduces hallucination?&lt;/p&gt;
&lt;p&gt;A. Bigger models&lt;br&gt;
B. RAG&lt;br&gt;
C. Longer prompts&lt;br&gt;
D. Temperature increase&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-36&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. RAG&lt;br&gt;
It grounds answers in retrieved evidence.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q37--objective&#34;&gt;Q37 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is an embedding?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-37&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;A vector representation capturing semantic meaning.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q38--mcq&#34;&gt;Q38 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which enables multimodal understanding?&lt;/p&gt;
&lt;p&gt;A. Tokenization only&lt;br&gt;
B. Cross-attention&lt;br&gt;
C. SGD&lt;br&gt;
D. Dropout&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-38&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;B. Cross-attention&lt;br&gt;
It aligns different modalities.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q39--objective&#34;&gt;Q39 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is an AI agent?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-39&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;A system that reasons, acts, uses tools, and iterates toward goals.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q40--mcq&#34;&gt;Q40 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is NOT a risk of agentic AI?&lt;/p&gt;
&lt;p&gt;A. Infinite loops&lt;br&gt;
B. Tool misuse&lt;br&gt;
C. Alignment drift&lt;br&gt;
D. Faster convergence&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-40&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;D. Faster convergence&lt;br&gt;
The others are real risks.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q41--objective&#34;&gt;Q41 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why is evaluation difficult for LLMs?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-41&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Outputs are open-ended and context-dependent.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q42--mcq&#34;&gt;Q42 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which is the gold standard of evaluation?&lt;/p&gt;
&lt;p&gt;A. BLEU&lt;br&gt;
B. ROUGE&lt;br&gt;
C. Human judgment&lt;br&gt;
D. Perplexity&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-42&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Human judgment&lt;br&gt;
Humans assess meaning and usefulness.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q43--objective&#34;&gt;Q43 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is hallucination?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-43&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Confidently generating incorrect or unsupported information.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q44--mcq&#34;&gt;Q44 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which helps reduce hallucination most?&lt;/p&gt;
&lt;p&gt;A. Temperature tuning&lt;br&gt;
B. Larger vocabulary&lt;br&gt;
C. Grounded retrieval&lt;br&gt;
D. More layers&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-44&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. Grounded retrieval&lt;br&gt;
Evidence constrains generation.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q45--objective&#34;&gt;Q45 â€” Objective&lt;/h3&gt;
&lt;p&gt;Why keep humans in the loop?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-45&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;To ensure safety, correctness, and ethical oversight.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q46--mcq&#34;&gt;Q46 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which best describes modern AI engineering?&lt;/p&gt;
&lt;p&gt;A. Model-centric&lt;br&gt;
B. Data-centric&lt;br&gt;
C. System-centric&lt;br&gt;
D. Prompt-only&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-46&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. System-centric&lt;br&gt;
Modern AI combines models, tools, data, and humans.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q47--objective&#34;&gt;Q47 â€” Objective&lt;/h3&gt;
&lt;p&gt;What is the biggest misconception about LLMs?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-47&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;That they â€œunderstandâ€ like humans.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q48--mcq&#34;&gt;Q48 â€” MCQ&lt;/h3&gt;
&lt;p&gt;Which skill matters most long-term?&lt;/p&gt;
&lt;p&gt;A. Framework mastery&lt;br&gt;
B. Prompt tricks&lt;br&gt;
C. First-principles understanding&lt;br&gt;
D. Leaderboard scores&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-48&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;C. First-principles understanding&lt;br&gt;
Tools change, principles remain.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q49--objective&#34;&gt;Q49 â€” Objective&lt;/h3&gt;
&lt;p&gt;What should AI ultimately optimize for?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-49&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Human well-being and societal benefit.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h3 id=&#34;q50--final-reflection&#34;&gt;Q50 â€” Final Reflection&lt;/h3&gt;
&lt;p&gt;What makes a &lt;em&gt;great&lt;/em&gt; AI engineer?&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-50&#34;&gt;
  &lt;summary&gt;Answer&lt;/summary&gt;
  &lt;p&gt;Technical excellence, humility, ethics, and responsibility to humanity.&lt;/p&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-final-words&#34;&gt;ğŸŒ± Final Words&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AI is not about replacing humans.&lt;br&gt;
It is about helping humans become better.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If this course helped you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Think deeper&lt;/li&gt;
&lt;li&gt;Act responsibly&lt;/li&gt;
&lt;li&gt;Teach others kindly&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description>
    </item>
    
  </channel>
</rss>
