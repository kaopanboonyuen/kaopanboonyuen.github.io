<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.2.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Teerapong Panboonyuen" />

  
  
  
    
  
  <meta name="description" content="" />

  
  <link rel="alternate" hreflang="en-us" href="https://kaopanboonyuen.github.io/courses/2026-01-08-daily-knowledge-notes/dk-010-agi-problem/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.08f2e04360a1c87f5ad39547c02bf219.css" />

  



  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://kaopanboonyuen.github.io/courses/2026-01-08-daily-knowledge-notes/dk-010-agi-problem/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Teerapong Panboonyuen" />
  <meta property="og:url" content="https://kaopanboonyuen.github.io/courses/2026-01-08-daily-knowledge-notes/dk-010-agi-problem/" />
  <meta property="og:title" content="DK-010 ‚Äî Why AGI Is a Systems Problem, Not a Model | Teerapong Panboonyuen" />
  <meta property="og:description" content="" /><meta property="og:image" content="https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://kaopanboonyuen.github.io/media/icon_hueaa9297dc78a770d45cebdfb81bbca28_1203332_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2026-02-07T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2026-02-07T00:00:00&#43;00:00">
  

  



  

  

  





  <title>DK-010 ‚Äî Why AGI Is a Systems Problem, Not a Model | Teerapong Panboonyuen</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="df75b6b72cbb24709c7d17fe116c2b5e" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Teerapong Panboonyuen</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#awards"><span>Awards</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#press"><span>Press</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Featured</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#tags"><span>Topics</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#communities"><span>Communities</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/blog/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
          
          <li class="nav-item d-none d-lg-inline-flex">
            <a class="nav-link" href="https://x.com/kaopanboonyuen" data-toggle="tooltip" data-placement="bottom" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
              <i class="fab fa-twitter" aria-hidden="true"></i>
            </a>
          </li>
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    





<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
          Knowledge Notes
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li><a href="/courses/"><i class="fas fa-arrow-left pr-1"></i>Courses</a></li>
      </ul>

      
      
        
          
        
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/courses/2026-01-08-daily-knowledge-notes/">Knowledge Notes</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-011-banking-as-a-system/">DK-011 ‚Äî Banking as a System</a></li>



  <li class="active"><a href="/courses/2026-01-08-daily-knowledge-notes/dk-010-agi-problem/">DK-010 ‚Äî Why AGI Is a Systems Problem, Not a Model</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-009-llm-recap/">DK-009 ‚Äî From Pretraining to MoE and Agentic Systems</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-008-geospatial-intelligence/">DK-008 ‚Äî Geospatial Intelligence</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-007-astronomy/">DK-007 ‚Äî Astronomy</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-006-iq-puzzle-practice/">DK-006 ‚Äî IQ Practice</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-005-playing-cards/">DK-005 ‚Äî Playing Cards &amp; Probability with Python</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-004-music-theory/">DK-004 ‚Äî Music Theory</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-003-probability/">DK-003 ‚Äî Probability</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-002-math-every-programmer-should-know-copy/">DK-002 ‚Äî Math Every Programmer Should Know</a></li>



  <li class=""><a href="/courses/2026-01-08-daily-knowledge-notes/dk-001-harry-potter-overview/">DK-001 ‚Äî The Harry Potter Universe (A Beginner-Friendly Guide)</a></li>

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#1-definitions-ani-agi-asi">1Ô∏è‚É£ Definitions: ANI, AGI, ASI</a>
      <ul>
        <li><a href="#11-artificial-narrow-intelligence-ani">1.1 Artificial Narrow Intelligence (ANI)</a></li>
        <li><a href="#12-artificial-general-intelligence-agi">1.2 Artificial General Intelligence (AGI)</a></li>
        <li><a href="#13-artificial-superintelligence-asi">1.3 Artificial Superintelligence (ASI)</a></li>
      </ul>
    </li>
    <li><a href="#2-why-llms-are-ani-not-agi">2Ô∏è‚É£ Why LLMs Are ANI, Not AGI</a></li>
    <li><a href="#3-intelligence-is-a-control-system">3Ô∏è‚É£ Intelligence Is a Control System</a></li>
    <li><a href="#4-the-core-components-of-agi-nerd-edition">4Ô∏è‚É£ The Core Components of AGI (Nerd Edition)</a>
      <ul>
        <li><a href="#41-world-model">4.1 World Model</a></li>
        <li><a href="#42-memory-beyond-context-windows">4.2 Memory (Beyond Context Windows)</a></li>
        <li><a href="#43-planning-and-search">4.3 Planning and Search</a></li>
        <li><a href="#44-learning-from-interaction">4.4 Learning From Interaction</a></li>
        <li><a href="#45-goal-management">4.5 Goal Management</a></li>
      </ul>
    </li>
    <li><a href="#5-why-scaling-models-alone-fails">5Ô∏è‚É£ Why Scaling Models Alone Fails</a></li>
    <li><a href="#6-agi-as-an-emergent-system">6Ô∏è‚É£ AGI as an Emergent System</a></li>
    <li><a href="#7-why-humans-are-a-useful-reference">7Ô∏è‚É£ Why Humans Are a Useful Reference</a></li>
    <li><a href="#8-implications-for-ai-research">8Ô∏è‚É£ Implications for AI Research</a></li>
    <li><a href="#9-final-takeaway">9Ô∏è‚É£ Final Takeaway</a></li>
    <li><a href="#-closing-thought">üß† Closing Thought</a></li>
  </ul>

  <ul>
    <li><a href="#1-first-what-would-agi-happening-even-mean">1Ô∏è‚É£ First: What Would ‚ÄúAGI Happening‚Äù Even Mean?</a></li>
    <li><a href="#2-the-pro-agi-argument-why-it-should-happen">2Ô∏è‚É£ The Pro-AGI Argument (Why It <em>Should</em> Happen)</a>
      <ul>
        <li><a href="#21-intelligence-is-substrate-independent">2.1 Intelligence Is Substrate-Independent</a></li>
        <li><a href="#22-scaling-laws-have-not-broken-yet">2.2 Scaling Laws Have Not Broken (Yet)</a></li>
        <li><a href="#23-cognitive-functions-are-decomposable">2.3 Cognitive Functions Are Decomposable</a></li>
        <li><a href="#24-systems-are-catching-up-to-models">2.4 Systems Are Catching Up to Models</a></li>
      </ul>
    </li>
    <li><a href="#3-the-anti-agi-argument-why-it-might-not-happen">3Ô∏è‚É£ The Anti-AGI Argument (Why It Might <em>Not</em> Happen)</a>
      <ul>
        <li><a href="#31-generalization-might-be-ill-defined">3.1 Generalization Might Be Ill-Defined</a></li>
        <li><a href="#32-world-models-might-be-the-hard-wall">3.2 World Models Might Be the Hard Wall</a></li>
        <li><a href="#33-self-directed-learning-is-still-weak">3.3 Self-Directed Learning Is Still Weak</a></li>
        <li><a href="#34-scaling-might-plateau">3.4 Scaling Might Plateau</a></li>
      </ul>
    </li>
    <li><a href="#4-the-real-answer-agi-is-not-binary">4Ô∏è‚É£ The Real Answer: AGI Is Not Binary</a></li>
    <li><a href="#5-agi-as-an-engineering-threshold-not-a-breakthrough">5Ô∏è‚É£ AGI as an Engineering Threshold, Not a Breakthrough</a></li>
    <li><a href="#6-the-most-likely-scenario">6Ô∏è‚É£ The Most Likely Scenario</a></li>
    <li><a href="#7-what-would-actually-block-agi">7Ô∏è‚É£ What Would <em>Actually</em> Block AGI?</a></li>
    <li><a href="#8-final-nerd-conclusion">8Ô∏è‚É£ Final Nerd Conclusion</a></li>
    <li><a href="#-final-thought">üß† Final Thought</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          
            
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
  
  

  <li class="breadcrumb-item">
    <a href="/">
      
        Home
      
    </a>
  </li>


  <li class="breadcrumb-item">
    <a href="/courses/">
      
        Courses
      
    </a>
  </li>


  <li class="breadcrumb-item">
    <a href="/courses/2026-01-08-daily-knowledge-notes/">
      
        Knowledge Notes
      
    </a>
  </li>


      <li class="breadcrumb-item active" aria-current="page">
        DK-010 ‚Äî Why AGI Is a Systems Problem, Not a Model
      </li>
    </ol>
  </nav>


          

          <h1>DK-010 ‚Äî Why AGI Is a Systems Problem, Not a Model</h1>

          <div class="article-style">
            <hr>
<h1 id="-why-agi-is-a-systems-problem-not-a-model">üß† Why AGI Is a Systems Problem, Not a Model</h1>
<p>Artificial General Intelligence (AGI) is often misunderstood as<br>
‚Äúa bigger, smarter language model.‚Äù</p>
<p>This is incorrect.</p>
<p>AGI is <strong>not a single model</strong>.<br>
AGI is a <strong>system of interacting components</strong>.</p>
<p>This chapter explains:</p>
<ul>
<li>what AGI actually means</li>
<li>how it differs from ANI and ASI</li>
<li>why scaling models alone will never be sufficient</li>
<li>what components are fundamentally required</li>
</ul>
<hr>
<h2 id="1-definitions-ani-agi-asi">1Ô∏è‚É£ Definitions: ANI, AGI, ASI</h2>
<p>Let us begin with precise terms.</p>
<hr>
<h3 id="11-artificial-narrow-intelligence-ani">1.1 Artificial Narrow Intelligence (ANI)</h3>
<p>ANI systems:</p>
<ul>
<li>perform <strong>specific tasks</strong></li>
<li>operate within <strong>fixed domains</strong></li>
<li>do not generalize autonomously</li>
</ul>
<p>Examples:</p>
<ul>
<li>image classifiers</li>
<li>speech recognition</li>
<li>recommender systems</li>
<li>current LLMs (yes, including GPT-scale models)</li>
</ul>
<p>Formally:</p>
<p>$$
f: X \rightarrow Y \quad \text{within a narrow task distribution}
$$</p>
<p>ANI excels at <em>competence</em>, not <em>adaptability</em>.</p>
<hr>
<h3 id="12-artificial-general-intelligence-agi">1.2 Artificial General Intelligence (AGI)</h3>
<p>AGI systems:</p>
<ul>
<li>learn <strong>across domains</strong></li>
<li>transfer knowledge</li>
<li>reason abstractly</li>
<li>adapt goals and strategies</li>
</ul>
<p>AGI approximates <strong>human-level general cognition</strong>.</p>
<p>A rough definition:</p>
<p>$$
\text{AGI} \approx \text{Ability to achieve goals across diverse environments}
$$</p>
<p>AGI is not about <strong>knowing everything</strong>.<br>
It is about <strong>learning anything</strong>.</p>
<hr>
<h3 id="13-artificial-superintelligence-asi">1.3 Artificial Superintelligence (ASI)</h3>
<p>ASI exceeds human intelligence in:</p>
<ul>
<li>speed</li>
<li>scale</li>
<li>creativity</li>
<li>strategic reasoning</li>
</ul>
<p>ASI is <strong>post-human intelligence</strong>.</p>
<p>$$
\text{ASI} \gg \text{Human Cognitive Capacity}
$$</p>
<p>ASI is not required to understand AGI.<br>
Conflating them leads to confusion and fear.</p>
<hr>
<h2 id="2-why-llms-are-ani-not-agi">2Ô∏è‚É£ Why LLMs Are ANI, Not AGI</h2>
<p>Large Language Models compute:</p>
<p>$$
P(x_t \mid x_{&lt;t})
$$</p>
<p>They:</p>
<ul>
<li>predict tokens</li>
<li>interpolate patterns</li>
<li>lack grounded objectives</li>
</ul>
<p>Even with reasoning:</p>
<ul>
<li>no persistent goals</li>
<li>no self-directed learning</li>
<li>no causal grounding</li>
</ul>
<p>They are <strong>general tools</strong>, not general intelligences.</p>
<hr>
<h2 id="3-intelligence-is-a-control-system">3Ô∏è‚É£ Intelligence Is a Control System</h2>
<p>True intelligence requires <strong>closed-loop interaction</strong>.</p>
<p>A minimal intelligence loop:</p>
<p>$$
\text{Perception} \rightarrow \text{Model} \rightarrow \text{Decision} \rightarrow \text{Action} \rightarrow \text{Environment}
$$</p>
<p>LLMs occupy only <strong>one block</strong>.</p>
<p>AGI requires <strong>all blocks</strong>.</p>
<hr>
<h2 id="4-the-core-components-of-agi-nerd-edition">4Ô∏è‚É£ The Core Components of AGI (Nerd Edition)</h2>
<p>AGI is a composition of subsystems.</p>
<hr>
<h3 id="41-world-model">4.1 World Model</h3>
<p>A world model estimates dynamics:</p>
<p>$$
P(s_{t+1} \mid s_t, a_t)
$$</p>
<p>Without this:</p>
<ul>
<li>no planning</li>
<li>no causality</li>
<li>no foresight</li>
</ul>
<p>LLMs approximate <em>textual worlds</em>, not physical or social reality.</p>
<hr>
<h3 id="42-memory-beyond-context-windows">4.2 Memory (Beyond Context Windows)</h3>
<p>Human intelligence relies on:</p>
<ul>
<li>episodic memory</li>
<li>semantic memory</li>
<li>procedural memory</li>
</ul>
<p>A system needs memory persistence:</p>
<p>$$
M_{t+1} = f(M_t, s_t, a_t)
$$</p>
<p>Context length ‚â† memory.</p>
<hr>
<h3 id="43-planning-and-search">4.3 Planning and Search</h3>
<p>Planning solves:</p>
<p>$$
\max_{a_{1:T}} \mathbb{E}\left[\sum_{t=1}^T r(s_t, a_t)\right]
$$</p>
<p>LLMs do not optimize reward.
They generate plausible text.</p>
<hr>
<h3 id="44-learning-from-interaction">4.4 Learning From Interaction</h3>
<p>AGI must learn online:</p>
<p>$$
\theta_{t+1} = \theta_t + \alpha \nabla_\theta \mathcal{L}(s_t, a_t)
$$</p>
<p>Pretraining alone cannot achieve this.</p>
<hr>
<h3 id="45-goal-management">4.5 Goal Management</h3>
<p>Humans:</p>
<ul>
<li>form goals</li>
<li>revise goals</li>
<li>abandon goals</li>
</ul>
<p>This requires:</p>
<ul>
<li>internal objectives</li>
<li>meta-cognition</li>
<li>self-evaluation</li>
</ul>
<p>LLMs have none of these natively.</p>
<hr>
<h2 id="5-why-scaling-models-alone-fails">5Ô∏è‚É£ Why Scaling Models Alone Fails</h2>
<p>Scaling laws improve:</p>
<ul>
<li>fluency</li>
<li>recall</li>
<li>pattern completion</li>
</ul>
<p>They do not automatically yield:</p>
<ul>
<li>agency</li>
<li>grounded understanding</li>
<li>intentional behavior</li>
</ul>
<p>More parameters ‚â† more autonomy.</p>
<hr>
<h2 id="6-agi-as-an-emergent-system">6Ô∏è‚É£ AGI as an Emergent System</h2>
<p>AGI emerges when components interact:</p>
<p>$$
\text{AGI} \neq \sum \text{Models}
$$</p>
<p>Instead:</p>
<p>$$
\text{AGI} = \text{Model} + \text{Memory} + \text{World} + \text{Learning} + \text{Control}
$$</p>
<p>This is systems engineering, not model training.</p>
<hr>
<h2 id="7-why-humans-are-a-useful-reference">7Ô∏è‚É£ Why Humans Are a Useful Reference</h2>
<p>Human cognition includes:</p>
<ul>
<li>imperfect reasoning</li>
<li>bounded memory</li>
<li>slow learning</li>
</ul>
<p>Yet humans are general.</p>
<p>Why?</p>
<p>Because intelligence is <strong>architectural</strong>, not parametric.</p>
<hr>
<h2 id="8-implications-for-ai-research">8Ô∏è‚É£ Implications for AI Research</h2>
<p>To move toward AGI:</p>
<ul>
<li>stop chasing single-model breakthroughs</li>
<li>focus on integration</li>
<li>treat LLMs as cognitive modules</li>
</ul>
<p>The future is:</p>
<ul>
<li>agent architectures</li>
<li>simulators</li>
<li>tool-augmented reasoning</li>
<li>long-horizon learning</li>
</ul>
<hr>
<h2 id="9-final-takeaway">9Ô∏è‚É£ Final Takeaway</h2>
<p>AGI is not:</p>
<ul>
<li>a bigger transformer</li>
<li>a longer context window</li>
<li>a single neural network</li>
</ul>
<p>AGI is:</p>
<ul>
<li>a system</li>
<li>a loop</li>
<li>an architecture</li>
<li>a process</li>
</ul>
<hr>
<h2 id="-closing-thought">üß† Closing Thought</h2>
<blockquote>
<p>Models think.<br>
Systems act.<br>
Intelligence emerges from action.</p>
</blockquote>
<hr>
<p><em>AGI will not be trained.<br>
It will be engineered.</em></p>
<hr>
<h1 id="-will-agi-happen-a-nerd-level-analysis">ü§ñ Will AGI Happen? (A Nerd-Level Analysis)</h1>
<p>The question</p>
<blockquote>
<p><em>‚ÄúWill AGI happen?‚Äù</em></p>
</blockquote>
<p>is often framed emotionally.</p>
<p>This chapter reframes it <strong>structurally</strong>.</p>
<p>AGI is not magic.<br>
AGI is not destiny.<br>
AGI is a question about <strong>systems, scaling, and limits</strong>.</p>
<hr>
<h2 id="1-first-what-would-agi-happening-even-mean">1Ô∏è‚É£ First: What Would ‚ÄúAGI Happening‚Äù Even Mean?</h2>
<p>AGI does NOT mean:</p>
<ul>
<li>consciousness</li>
<li>emotions</li>
<li>self-awareness</li>
<li>human-like biology</li>
</ul>
<p>AGI means:</p>
<blockquote>
<p>A system that can <strong>learn, reason, and act competently across domains</strong><br>
without task-specific re-engineering.</p>
</blockquote>
<p>Formally:</p>
<p>$$
\forall \mathcal{E}_i,\ \exists\ \pi \text{ such that } \mathbb{E}[R_i(\pi)] \ge \text{human-level}
$$</p>
<hr>
<h2 id="2-the-pro-agi-argument-why-it-should-happen">2Ô∏è‚É£ The Pro-AGI Argument (Why It <em>Should</em> Happen)</h2>
<p>Let‚Äôs be honest.</p>
<p>There are <strong>strong technical reasons</strong> to believe AGI is possible.</p>
<hr>
<h3 id="21-intelligence-is-substrate-independent">2.1 Intelligence Is Substrate-Independent</h3>
<p>Human intelligence emerges from:</p>
<ul>
<li>neurons</li>
<li>chemistry</li>
<li>physics</li>
</ul>
<p>There is no known law stating:</p>
<blockquote>
<p>‚ÄúOnly biological tissue can produce general intelligence.‚Äù</p>
</blockquote>
<p>If cognition is computation:</p>
<p>$$
\text{Intelligence} = f(\text{information}, \text{memory}, \text{learning}, \text{control})
$$</p>
<p>Then artificial substrates are valid candidates.</p>
<hr>
<h3 id="22-scaling-laws-have-not-broken-yet">2.2 Scaling Laws Have Not Broken (Yet)</h3>
<p>Empirically:</p>
<p>$$
\mathcal{L} \propto N^{-\alpha}
$$</p>
<p>Where:</p>
<ul>
<li>N = parameters / data / compute</li>
</ul>
<p>We keep seeing:</p>
<ul>
<li>smoother loss curves</li>
<li>emergent behaviors</li>
<li>better generalization</li>
</ul>
<p>No hard wall has appeared.</p>
<hr>
<h3 id="23-cognitive-functions-are-decomposable">2.3 Cognitive Functions Are Decomposable</h3>
<p>What humans do can be decomposed into:</p>
<ul>
<li>perception</li>
<li>memory</li>
<li>abstraction</li>
<li>planning</li>
<li>learning</li>
</ul>
<p>None of these are theoretically uncomputable.</p>
<p>AGI does not require a mystery component.</p>
<hr>
<h3 id="24-systems-are-catching-up-to-models">2.4 Systems Are Catching Up to Models</h3>
<p>LLMs + tools + memory + planners already form:</p>
<p>$$
\text{proto-agents}
$$</p>
<p>This trajectory is architectural, not speculative.</p>
<hr>
<h2 id="3-the-anti-agi-argument-why-it-might-not-happen">3Ô∏è‚É£ The Anti-AGI Argument (Why It Might <em>Not</em> Happen)</h2>
<p>Now the uncomfortable part.</p>
<hr>
<h3 id="31-generalization-might-be-ill-defined">3.1 Generalization Might Be Ill-Defined</h3>
<p>‚ÄúGeneral intelligence‚Äù may not be a smooth continuum.</p>
<p>It may require:</p>
<ul>
<li>embodiment</li>
<li>social grounding</li>
<li>evolutionary pressure</li>
</ul>
<p>LLMs train on static data.</p>
<p>Reality is not static.</p>
<hr>
<h3 id="32-world-models-might-be-the-hard-wall">3.2 World Models Might Be the Hard Wall</h3>
<p>Language models learn correlations:</p>
<p>$$
P(x_{t+1} \mid x_{\le t})
$$</p>
<p>World models require causality:</p>
<p>$$
P(s_{t+1} \mid s_t, a_t)
$$</p>
<p>Causal learning in open environments is <strong>orders of magnitude harder</strong>.</p>
<hr>
<h3 id="33-self-directed-learning-is-still-weak">3.3 Self-Directed Learning Is Still Weak</h3>
<p>Humans learn by:</p>
<ul>
<li>curiosity</li>
<li>exploration</li>
<li>failure</li>
</ul>
<p>Current systems:</p>
<ul>
<li>optimize predefined losses</li>
<li>lack intrinsic motivation</li>
<li>struggle with long-horizon credit assignment</li>
</ul>
<p>This is not a small gap.</p>
<hr>
<h3 id="34-scaling-might-plateau">3.4 Scaling Might Plateau</h3>
<p>Possible bottlenecks:</p>
<ul>
<li>data exhaustion</li>
<li>compute cost</li>
<li>energy limits</li>
<li>diminishing returns</li>
</ul>
<p>There is no proof scaling continues forever.</p>
<hr>
<h2 id="4-the-real-answer-agi-is-not-binary">4Ô∏è‚É£ The Real Answer: AGI Is Not Binary</h2>
<p>AGI will likely:</p>
<ul>
<li>emerge gradually</li>
<li>be uneven</li>
<li>appear in fragments</li>
</ul>
<p>Not a single moment.
Not a single model.</p>
<hr>
<h2 id="5-agi-as-an-engineering-threshold-not-a-breakthrough">5Ô∏è‚É£ AGI as an Engineering Threshold, Not a Breakthrough</h2>
<p>AGI will ‚Äúhappen‚Äù when:</p>
<p>$$
\text{System Capability} &gt; \text{Human General Competence}
$$</p>
<p>In enough domains.</p>
<p>Not when someone declares it.</p>
<hr>
<h2 id="6-the-most-likely-scenario">6Ô∏è‚É£ The Most Likely Scenario</h2>
<p>The most realistic outcome:</p>
<ul>
<li>no single AGI model</li>
<li>many specialized but composable agents</li>
<li>strong competence without consciousness</li>
<li>uneven performance</li>
<li>brittle edge cases</li>
</ul>
<p>AGI will feel:</p>
<blockquote>
<p>‚Äúannoyingly capable, but not god-like‚Äù</p>
</blockquote>
<hr>
<h2 id="7-what-would-actually-block-agi">7Ô∏è‚É£ What Would <em>Actually</em> Block AGI?</h2>
<p>Only a few things:</p>
<ol>
<li>A fundamental theoretical limit (none known)</li>
<li>Inability to build causal world models</li>
<li>Economic or energy collapse</li>
<li>Societal refusal (regulation, fear)</li>
</ol>
<p>Physics is not the blocker.</p>
<hr>
<h2 id="8-final-nerd-conclusion">8Ô∏è‚É£ Final Nerd Conclusion</h2>
<p>AGI is:</p>
<ul>
<li>not guaranteed</li>
<li>not impossible</li>
<li>not mystical</li>
</ul>
<p>AGI is an <strong>engineering convergence problem</strong>.</p>
<hr>
<h2 id="-final-thought">üß† Final Thought</h2>
<blockquote>
<p>If intelligence is computable,<br>
and if systems can learn from the world,<br>
then AGI is not a question of <em>if</em>,<br>
but of <em>how slowly and how messily</em>.</p>
</blockquote>
<hr>
          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/courses/2026-01-08-daily-knowledge-notes/dk-011-banking-as-a-system/" rel="next">DK-011 ‚Äî Banking as a System</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/courses/2026-01-08-daily-knowledge-notes/dk-009-llm-recap/" rel="prev">DK-009 ‚Äî From Pretraining to MoE and Agentic Systems</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on 2026</p>

          





          




          


  
  



        </div>

      </article>

      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    ¬©2026 Kao Panboonyuen
  </p>
  

  
  






  <p class="powered-by">
    
    Built using <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a> and the <a href="https://github.com/wowchemy/starter-hugo-academic" target="_blank" rel="noopener">Wowchemy academic template</a>. View <a href="https://github.com/kaopanboonyuen/kaopanboonyuen.github.io" target="_blank" rel="noopener">source</a>.
        
  </p>
</footer>

    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/golang.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b36873e4e886c7b03b21e4eb97d9b6d7.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
